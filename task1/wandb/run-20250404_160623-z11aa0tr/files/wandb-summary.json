{"train_runtime":4550.9725,"eval/overall/thresh/f1_pos":0.6932668329177057,"train/grad_norm":0.0051313238218426704,"eval/samples_per_second":315.969,"eval/steps_per_second":39.556,"total_flos":3.523478008958976e+16,"test/loss":0.6308147311210632,"eval/de/thresh/f1_pos":0.5822784810126582,"test/precision_pos":0.683046683046683,"_wandb":{"runtime":4589},"test/samples_per_second":287.114,"eval/precision_pos":0.6400911161731208,"eval/f1_neg":0.967312492571021,"eval/overall/thresh/accuracy":0.9468108108108109,"test/f1_neg":0.9705150976909414,"test/steps_per_second":35.944,"eval/recall_pos":0.7060301507537688,"eval/overall/thresh/precision_pos":0.6881188118811881,"eval/overall/thresh/conf_matrix":{"_latest_artifact_path":"wandb-client-artifact://saqqdm9uoqk0n4s2tskhzan23tzsbp882ydwtifwzt4o8vwtcfdlsvnz1i1og6hk9g8cw1cc6ny7ls8nk5qe13b6fj2mfsa30zy2dwdb23db8gfh8fdbdo7i3flgxg8m:latest/eval/overall/thresh/conf_matrix.table.json","path":"media/table/eval/overall/thresh/conf_matrix_178_86aa29ce29b17c766f0c.table.json","ncols":2,"nrows":2,"_type":"table-file","sha256":"86aa29ce29b17c766f0c82e2298e1d7710f40cccc7972169ee9e1b3e47604190","size":68,"artifact_path":"wandb-client-artifact://d5ulgtuuett18dc3m1ee8xu2fy272tr0j510i4xkc54pg5qjtaqtihfraoduhphmydk87ty7s1v5bkeuzoesqwxpaz0ajnutfdtb3uc5nor7ymt3yukmpzt41o72ao1b/eval/overall/thresh/conf_matrix.table.json"},"eval/ru/thresh/recall_pos":0.6654411764705882,"train_steps_per_second":1.839,"eval/de/thresh/precision_pos":0.5227272727272727,"train_loss":0.12139193941175717,"eval/ru/thresh/accuracy":0.9404494382022472,"eval/accuracy":0.9405405405405406,"train/epoch":7.999641619878151,"eval/ru/thresh/f1_pos":0.6948176583493282,"_runtime":4589.8801254,"eval/overall/thresh/macro_f1_pos_lang":0.674424801538037,"eval/overall/thresh/recall_pos":0.6984924623115578,"train_samples_per_second":58.857,"eval/runtime":14.6375,"eval/fr/thresh/recall_pos":0.8,"test/recall_pos":0.6984924623115578,"eval/en/thresh/accuracy":0.9745011086474501,"eval/en/thresh/f1_pos":0.8130081300813008,"eval/loss":0.8278512358665466,"eval/fr/thresh/accuracy":0.9260143198090692,"train/loss":0.0147,"eval/best_threshold":0.5199999999999998,"test/accuracy":0.9461621621621622,"eval/fr/thresh/f1_pos":0.6075949367088608,"test/f1_pos":0.6906832298136646,"eval/en/thresh/precision_pos":0.8064516129032258,"_timestamp":1.7437801731222327e+09,"test/runtime":16.1086,"_step":178,"eval/ru/thresh/precision_pos":0.7269076305220884,"train/global_step":8368,"eval/f1_pos":0.6714456391875747,"train/learning_rate":6.611570247933884e-08,"eval/de/thresh/recall_pos":0.6571428571428571,"eval/fr/thresh/precision_pos":0.4897959183673469,"eval/de/thresh/accuracy":0.9479495268138801,"eval/best_val_f1_at_threshold":0.6932668329177057,"eval/en/thresh/recall_pos":0.819672131147541}