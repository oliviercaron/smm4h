Loading data...
Data loaded.
Tokenizing data...
Tokenization complete.
Cleaning dataset columns...
Columns before removal: ['id', 'text', 'label', 'file_name', 'origin', 'type', 'language', 'split', 'input_ids', 'attention_mask']
Removing columns: ['text', 'id', 'file_name', 'origin', 'language', 'split', 'type']
Columns after cleaning and rename: ['labels', 'input_ids', 'attention_mask']
Computing class weights...
Class Weights: tensor([0.5426, 6.3621], device='cuda:0')
Loading model...
Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Model loaded.
Setting training arguments...
C:\Users\Olivier\AppData\Local\Temp\ipykernel_24548\3772409379.py:161: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.
  trainer = WeightedTrainer(
Trainer configured.
Starting Training...
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
Training finished.

Evaluating on Development Set (Best Model)...
Evaluation Results:
{'eval_loss': 0.33790481090545654, 'eval_accuracy': 0.9498378378378378, 'eval_f1_pos': 0.7128712871287128, 'eval_precision_pos': 0.7024390243902439, 'eval_recall_pos': 0.7236180904522613, 'eval_f1_neg': 0.9725183605780621, 'eval_runtime': 50.8503, 'eval_samples_per_second': 90.953, 'eval_steps_per_second': 45.486, 'epoch': 5.999358727715788}

Generating predictions and detailed metrics for Dev Set...

--- Detailed Evaluation on Development Set ---

Metrics for language: DE
  Precision-de (Pos): 0.6207
  Recall-de    (Pos): 0.5143
  F1-de        (Pos): 0.5625
  Accuracy-de:        0.9558

Metrics for language: EN
  Precision-en (Pos): 0.7727
  Recall-en    (Pos): 0.8361
  F1-en        (Pos): 0.8031
  Accuracy-en:        0.9723

Metrics for language: FR
  Precision-fr (Pos): 0.7500
  Recall-fr    (Pos): 0.8000
  F1-fr        (Pos): 0.7742
  Accuracy-fr:        0.9666

Metrics for language: RU
  Precision-ru (Pos): 0.6890
  Recall-ru    (Pos): 0.7169
  F1-ru        (Pos): 0.7027
  Accuracy-ru:        0.9382

--- Overall Evaluation Summary (Positive Class Focus) ---
F1-score across all languages (Positive Class): 0.7129  <-- Primary Metric
Macro F1-score across all languages (Pos Class):0.7106
Overall Precision (Positive Class):             0.7024
Overall Recall (Positive Class):                0.7236
Overall Accuracy across all languages:          0.9498

Overall Confusion Matrix (All Languages):
[[TN=4105  FP=122]
 [FN=110  TP=288]]
Metrics logged to WandB.

Saving predictions for submission...
Predictions saved to results_xlmr_large_optimized\predictions_task1.csv
predictions_task1.csv has been zipped into results_xlmr_large_optimized\submission_task1.zip

Script finished.

Evaluating on Development Set (Best Model)...
Evaluation Results (using default 0.5 threshold):
{'eval_loss': 0.33790481090545654, 'eval_accuracy': 0.9498378378378378, 'eval_f1_pos': 0.7128712871287128, 'eval_precision_pos': 0.7024390243902439, 'eval_recall_pos': 0.7236180904522613, 'eval_f1_neg': 0.9725183605780621, 'eval_runtime': 62.4449, 'eval_samples_per_second': 74.065, 'eval_steps_per_second': 37.041, 'epoch': 5.999358727715788}

--- Performing Threshold Tuning on Validation Set ---
Best threshold found: 0.0900
Corresponding F1 Score (Positive Class) on Dev Set: 0.7158
F1 vs Threshold plot saved to results_xlmr_large_optimized\f1_vs_threshold_tuning.png

Generating predictions and detailed metrics for Dev Set using OPTIMAL threshold...

--- Detailed Evaluation on Development Set (Using Threshold: 0.0900) ---

Metrics for language: DE
  Precision-de (Pos): 0.5789
  Recall-de    (Pos): 0.6286
  F1-de        (Pos): 0.6027
  Accuracy-de:       0.9543

Metrics for language: EN
  Precision-en (Pos): 0.7465
  Recall-en    (Pos): 0.8689
  F1-en        (Pos): 0.8030
  Accuracy-en:       0.9712

Metrics for language: FR
  Precision-fr (Pos): 0.7222
  Recall-fr    (Pos): 0.8667
  F1-fr        (Pos): 0.7879
  Accuracy-fr:       0.9666

Metrics for language: RU
  Precision-ru (Pos): 0.6442
  Recall-ru    (Pos): 0.7721
  F1-ru        (Pos): 0.7023
  Accuracy-ru:       0.9333

--- Overall Evaluation Summary (Positive Class Focus - AFTER Tuning) ---
Optimal Threshold Applied: 0.0900
F1-score across all languages (Positive Class): 0.7158  <-- Tuned Primary Metric
Macro F1-score across all languages (Pos Class):0.7240
Overall Precision (Positive Class):            0.6603
Overall Recall (Positive Class):               0.7814
Overall Accuracy across all languages:         0.9466

Overall Confusion Matrix (All Languages - Tuned):
[[TN=4067  FP=160]
 [FN=87  TP=311]]
Tuned Metrics logged to WandB.

Saving predictions for submission (using optimal threshold)...
Predictions saved to results_xlmr_large_optimized\predictions_task1.csv
predictions_task1.csv has been zipped into results_xlmr_large_optimized\submission_task1.zip

Script finished.
Loading data...
Data loaded.
Tokenizing data...
Tokenization complete.
Cleaning dataset columns...
Columns before removal: ['id', 'text', 'label', 'file_name', 'origin', 'type', 'language', 'split', 'input_ids', 'attention_mask']
Removing columns: ['text', 'id', 'file_name', 'origin', 'language', 'split', 'type']
Columns after cleaning and rename: ['labels', 'input_ids', 'attention_mask']
Computing class weights...
Class Weights: tensor([0.5426, 6.3621], device='cuda:0')
Loading model with LoRA...
Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 8,350,722 || all params: 568,022,020 || trainable%: 1.4701
Model loaded.
C:\Users\Olivier\AppData\Local\Temp\ipykernel_24548\240129717.py:173: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.
  trainer = WeightedTrainer(
No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Trainer configured.
Starting Training...
c:\Users\Olivier\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
