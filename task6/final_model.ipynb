{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta v3 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">CUDA available. Using </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">GPU(</span><span style=\"color: #008080; text-decoration-color: #008080\">s</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">. Device: NVIDIA GeForce RTX </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3070</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCUDA available. Using \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mGPU\u001b[0m\u001b[1;36m(\u001b[0m\u001b[36ms\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m. Device: NVIDIA GeForce RTX \u001b[0m\u001b[1;36m3070\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Effective Batch Size: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008080; text-decoration-color: #008080\">, Per-Device Batch Size: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #008080; text-decoration-color: #008080\">, Num GPUs: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\"> =&gt; Gradient Accumulation Steps: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEffective Batch Size: \u001b[0m\u001b[1;36m8\u001b[0m\u001b[36m, Per-Device Batch Size: \u001b[0m\u001b[1;36m8\u001b[0m\u001b[36m, Num GPUs: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m => Gradient Accumulation Steps: \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Importing libraries</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mImporting libraries\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Libraries imported.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Libraries imported.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cleaning Training Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cleaning Training Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training data loaded and cleaned. Total: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2521</span><span style=\"color: #008000; text-decoration-color: #008000\"> examples.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training data loaded and cleaned. Total: \u001b[0m\u001b[1;32m2521\u001b[0m\u001b[32m examples.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training data label distribution:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1372</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1149</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training data label distribution:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1372\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m1149\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Cleaning Holdout Validation Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Cleaning Holdout Validation Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout Validation data loaded and cleaned. Total: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">786</span><span style=\"color: #008000; text-decoration-color: #008000\"> examples.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout Validation data loaded and cleaned. Total: \u001b[0m\u001b[1;32m786\u001b[0m\u001b[32m examples.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Holdout Validation data label distribution:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">366</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Holdout Validation data label distribution:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m420\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m366\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Tokenizer loaded from </span><span style=\"color: #008000; text-decoration-color: #008000\">'microsoft/deberta-v3-base'</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Tokenizer loaded from \u001b[0m\u001b[32m'microsoft/deberta-v3-base'\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> CV Run output will be saved under: <span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m CV Run output will be saved under: \u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────── </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Starting Cross-Validation on Training Data</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────── \u001b[0m\u001b[1;33mStarting Cross-Validation on Training Data\u001b[0m\u001b[92m ────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CV Fold </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────── \u001b[0m\u001b[1;34mCV Fold \u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m5\u001b[0m\u001b[92m ───────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>, Fold Validation Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">505</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Size: \u001b[1;36m2016\u001b[0m, Fold Validation Size: \u001b[1;36m505\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1097</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">919</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1097\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m919\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Validation Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Validation Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m275\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m230\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Calculated class weights for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9188697</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0968444</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Calculated class weights for Fold \u001b[1;36m1\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.9188697\u001b[0m \u001b[1;36m1.0968444\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Safetensors PR exists\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Custom Trainer initialized with class weights </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">stored on CPU</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9188697</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0968444</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCustom Trainer initialized with class weights \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mstored on CPU\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m0.9188697\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m1.0968444\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Training Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Training Fold \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,016\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,512\n",
      "  Number of trainable parameters = 184,423,682\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1512' max='1512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1512/1512 2:16:28, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.349356</td>\n",
       "      <td>0.906542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.430959</td>\n",
       "      <td>0.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>0.251892</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.951579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.240299</td>\n",
       "      <td>0.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.260030</td>\n",
       "      <td>0.951168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-252\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-252\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-252\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-504\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-504\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-504\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-756\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-756\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-756\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-252] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1008\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1008\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1008\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-504] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1260\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1260\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1260\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-756] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1512\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1512\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1512\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1260] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\checkpoint-1008 (score: 0.9515789473684211).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\"> completed after </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">8189.</span><span style=\"color: #008000; text-decoration-color: #008000\">34s.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training Fold \u001b[0m\u001b[1;32m1\u001b[0m\u001b[32m completed after \u001b[0m\u001b[1;32m8189.\u001b[0m\u001b[32m34s.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 score on internal validation set during training: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9516</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m - Best F1 score on internal validation set during training: \u001b[0m\u001b[1;36m0.9516\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Evaluating and finding best threshold for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>using its internal validation split<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Evaluating and finding best threshold for Fold \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0musing its internal validation split\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 505\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Internal Validation Metrics <span style=\"font-weight: bold\">(</span>at threshold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25533491373062134</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_f1'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9515789473684211</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.6471</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.468</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold \u001b[1;36m1\u001b[0m Internal Validation Metrics \u001b[1m(\u001b[0mat threshold \u001b[1;36m0.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'test_loss'\u001b[0m: \u001b[1;36m0.25533491373062134\u001b[0m, \u001b[32m'test_f1'\u001b[0m: \n",
       "\u001b[1;36m0.9515789473684211\u001b[0m, \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m32.6471\u001b[0m, \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m15.468\u001b[0m, \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m0.98\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 on Internal Validation: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9556</span><span style=\"color: #008080; text-decoration-color: #008080\"> @ Optimized Threshold = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8799</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m - Best F1 on Internal Validation: \u001b[0m\u001b[1;36m0.9556\u001b[0m\u001b[36m @ Optimized Threshold = \u001b[0m\u001b[1;36m0.8799\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\n",
      "Configuration saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\config.json\n",
      "Model weights saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\model.safetensors\n",
      "tokenizer config file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Best model for Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Best model for Fold \u001b[0m\u001b[1;32m1\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Optimal threshold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.8799</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\threshold.txt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Optimal threshold \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m0.8799\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\threshold.txt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up temporary checkpoints directory: </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up temporary checkpoints directory: \u001b[0m\n",
       "\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_1'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up memory for fold </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up memory for fold \u001b[0m\u001b[1;2;36m1\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CV Fold </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────── \u001b[0m\u001b[1;34mCV Fold \u001b[0m\u001b[1;34m2\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m5\u001b[0m\u001b[92m ───────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, Fold Validation Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Size: \u001b[1;36m2017\u001b[0m, Fold Validation Size: \u001b[1;36m504\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1098</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">919</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1098\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m919\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Validation Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Validation Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m274\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m230\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Calculated class weights for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span> <span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Calculated class weights for Fold \u001b[1;36m2\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m \u001b[1;36m1.0973885\u001b[0m \u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\pytorch_model.bin\n",
      "Attempting to create safetensors variant\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Custom Trainer initialized with class weights </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">stored on CPU</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCustom Trainer initialized with class weights \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mstored on CPU\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m1.0973885\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Training Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Training Fold \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,017\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,518\n",
      "  Number of trainable parameters = 184,423,682\n",
      "Safetensors PR exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1265' max='1518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1265/1518 21:52 < 04:22, 0.96 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.362900</td>\n",
       "      <td>0.188479</td>\n",
       "      <td>0.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.209172</td>\n",
       "      <td>0.959488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.174820</td>\n",
       "      <td>0.958606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.223853</td>\n",
       "      <td>0.952586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.245156</td>\n",
       "      <td>0.956140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-253\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-253\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-253\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-506\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-506\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-506\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-759\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-759\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-759\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-253] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1012\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1012\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1012\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-759] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1265\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1265\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1265\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-1012] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\checkpoint-506 (score: 0.9594882729211087).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\"> completed after </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1313.</span><span style=\"color: #008000; text-decoration-color: #008000\">16s.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training Fold \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m completed after \u001b[0m\u001b[1;32m1313.\u001b[0m\u001b[32m16s.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 score on internal validation set during training: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9595</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m - Best F1 score on internal validation set during training: \u001b[0m\u001b[1;36m0.9595\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Evaluating and finding best threshold for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> <span style=\"font-weight: bold\">(</span>using its internal validation split<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Evaluating and finding best threshold for Fold \u001b[1;36m2\u001b[0m \u001b[1m(\u001b[0musing its internal validation split\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Internal Validation Metrics <span style=\"font-weight: bold\">(</span>at threshold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2091715931892395</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_f1'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9594882729211087</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.7456</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42.91</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.724</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold \u001b[1;36m2\u001b[0m Internal Validation Metrics \u001b[1m(\u001b[0mat threshold \u001b[1;36m0.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'test_loss'\u001b[0m: \u001b[1;36m0.2091715931892395\u001b[0m, \u001b[32m'test_f1'\u001b[0m: \n",
       "\u001b[1;36m0.9594882729211087\u001b[0m, \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m11.7456\u001b[0m, \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m42.91\u001b[0m, \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m2.724\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 on Internal Validation: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9620</span><span style=\"color: #008080; text-decoration-color: #008080\"> @ Optimized Threshold = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0512</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m - Best F1 on Internal Validation: \u001b[0m\u001b[1;36m0.9620\u001b[0m\u001b[36m @ Optimized Threshold = \u001b[0m\u001b[1;36m0.0512\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\n",
      "Configuration saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\config.json\n",
      "Model weights saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\model.safetensors\n",
      "tokenizer config file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Best model for Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Best model for Fold \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Optimal threshold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0512</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\threshold.txt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Optimal threshold \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m0.0512\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\threshold.txt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up temporary checkpoints directory: </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up temporary checkpoints directory: \u001b[0m\n",
       "\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_2'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up memory for fold </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">2</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up memory for fold \u001b[0m\u001b[1;2;36m2\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CV Fold </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────── \u001b[0m\u001b[1;34mCV Fold \u001b[0m\u001b[1;34m3\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m5\u001b[0m\u001b[92m ───────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, Fold Validation Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Size: \u001b[1;36m2017\u001b[0m, Fold Validation Size: \u001b[1;36m504\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1098</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">919</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1098\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m919\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Validation Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Validation Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m274\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m230\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Calculated class weights for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span> <span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Calculated class weights for Fold \u001b[1;36m3\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m \u001b[1;36m1.0973885\u001b[0m \u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\pytorch_model.bin\n",
      "Attempting to create safetensors variant\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Custom Trainer initialized with class weights </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">stored on CPU</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCustom Trainer initialized with class weights \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mstored on CPU\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m1.0973885\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Training Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Training Fold \u001b[1;36m3\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,017\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,518\n",
      "  Number of trainable parameters = 184,423,682\n",
      "Safetensors PR exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1518' max='1518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1518/1518 20:12, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.211635</td>\n",
       "      <td>0.946004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.159632</td>\n",
       "      <td>0.963753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.258541</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.205654</td>\n",
       "      <td>0.965665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.241276</td>\n",
       "      <td>0.961864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.227276</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-253\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-253\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-253\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-506\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-506\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-506\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-759\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-759\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-759\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-253] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1012\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1012\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1012\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-506] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1265\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1265\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1265\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-759] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1518\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1518\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1518\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1012] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\checkpoint-1518 (score: 0.9659574468085106).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\"> completed after </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1212.</span><span style=\"color: #008000; text-decoration-color: #008000\">78s.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training Fold \u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m completed after \u001b[0m\u001b[1;32m1212.\u001b[0m\u001b[32m78s.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 score on internal validation set during training: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9660</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m - Best F1 score on internal validation set during training: \u001b[0m\u001b[1;36m0.9660\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Evaluating and finding best threshold for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> <span style=\"font-weight: bold\">(</span>using its internal validation split<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Evaluating and finding best threshold for Fold \u001b[1;36m3\u001b[0m \u001b[1m(\u001b[0musing its internal validation split\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> Internal Validation Metrics <span style=\"font-weight: bold\">(</span>at threshold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22727636992931366</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_f1'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9659574468085106</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.546</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.975</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.744</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold \u001b[1;36m3\u001b[0m Internal Validation Metrics \u001b[1m(\u001b[0mat threshold \u001b[1;36m0.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'test_loss'\u001b[0m: \u001b[1;36m0.22727636992931366\u001b[0m, \u001b[32m'test_f1'\u001b[0m: \n",
       "\u001b[1;36m0.9659574468085106\u001b[0m, \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m8.546\u001b[0m, \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m58.975\u001b[0m, \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m3.744\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 on Internal Validation: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9660</span><span style=\"color: #008080; text-decoration-color: #008080\"> @ Optimized Threshold = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5448</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m - Best F1 on Internal Validation: \u001b[0m\u001b[1;36m0.9660\u001b[0m\u001b[36m @ Optimized Threshold = \u001b[0m\u001b[1;36m0.5448\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\n",
      "Configuration saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\config.json\n",
      "Model weights saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\model.safetensors\n",
      "tokenizer config file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Best model for Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Best model for Fold \u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Optimal threshold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.5448</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\threshold.txt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Optimal threshold \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m0.5448\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\threshold.txt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up temporary checkpoints directory: </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up temporary checkpoints directory: \u001b[0m\n",
       "\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_3'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up memory for fold </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">3</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up memory for fold \u001b[0m\u001b[1;2;36m3\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CV Fold </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">4</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────── \u001b[0m\u001b[1;34mCV Fold \u001b[0m\u001b[1;34m4\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m5\u001b[0m\u001b[92m ───────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, Fold Validation Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Size: \u001b[1;36m2017\u001b[0m, Fold Validation Size: \u001b[1;36m504\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1098</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">919</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1098\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m919\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Validation Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">230</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Validation Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m274\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m230\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Calculated class weights for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span> <span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Calculated class weights for Fold \u001b[1;36m4\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m \u001b[1;36m1.0973885\u001b[0m \u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\pytorch_model.bin\n",
      "Attempting to create safetensors variant\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Custom Trainer initialized with class weights </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">stored on CPU</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91848814</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0973885</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCustom Trainer initialized with class weights \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mstored on CPU\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m0.91848814\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m1.0973885\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Training Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Training Fold \u001b[1;36m4\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,017\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,518\n",
      "  Number of trainable parameters = 184,423,682\n",
      "Safetensors PR exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1518' max='1518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1518/1518 24:19, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.262883</td>\n",
       "      <td>0.928425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.245104</td>\n",
       "      <td>0.949367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.407538</td>\n",
       "      <td>0.917836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.238601</td>\n",
       "      <td>0.948936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.265879</td>\n",
       "      <td>0.951168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.334746</td>\n",
       "      <td>0.949580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-253\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-253\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-253\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-506\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-506\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-506\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-759\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-759\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-759\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-253] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1012\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1012\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1012\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-759] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1265\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1265\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1265\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-506] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1518\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1518\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1518\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1012] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\checkpoint-1265 (score: 0.9511677282377919).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> completed after </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1460.</span><span style=\"color: #008000; text-decoration-color: #008000\">18s.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training Fold \u001b[0m\u001b[1;32m4\u001b[0m\u001b[32m completed after \u001b[0m\u001b[1;32m1460.\u001b[0m\u001b[32m18s.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 score on internal validation set during training: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9512</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m4\u001b[0m\u001b[36m - Best F1 score on internal validation set during training: \u001b[0m\u001b[1;36m0.9512\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Evaluating and finding best threshold for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> <span style=\"font-weight: bold\">(</span>using its internal validation split<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Evaluating and finding best threshold for Fold \u001b[1;36m4\u001b[0m \u001b[1m(\u001b[0musing its internal validation split\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> Internal Validation Metrics <span style=\"font-weight: bold\">(</span>at threshold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2658790051937103</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_f1'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9511677282377919</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.1972</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54.799</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.479</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold \u001b[1;36m4\u001b[0m Internal Validation Metrics \u001b[1m(\u001b[0mat threshold \u001b[1;36m0.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'test_loss'\u001b[0m: \u001b[1;36m0.2658790051937103\u001b[0m, \u001b[32m'test_f1'\u001b[0m: \n",
       "\u001b[1;36m0.9511677282377919\u001b[0m, \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m9.1972\u001b[0m, \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m54.799\u001b[0m, \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m3.479\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 on Internal Validation: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9581</span><span style=\"color: #008080; text-decoration-color: #008080\"> @ Optimized Threshold = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9987</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m4\u001b[0m\u001b[36m - Best F1 on Internal Validation: \u001b[0m\u001b[1;36m0.9581\u001b[0m\u001b[36m @ Optimized Threshold = \u001b[0m\u001b[1;36m0.9987\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\n",
      "Configuration saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\config.json\n",
      "Model weights saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\model.safetensors\n",
      "tokenizer config file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Best model for Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Best model for Fold \u001b[0m\u001b[1;32m4\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Optimal threshold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.9987</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\threshold.txt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Optimal threshold \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m0.9987\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\threshold.txt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up temporary checkpoints directory: </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up temporary checkpoints directory: \u001b[0m\n",
       "\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_4'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up memory for fold </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">4</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up memory for fold \u001b[0m\u001b[1;2;36m4\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">CV Fold </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────────── \u001b[0m\u001b[1;34mCV Fold \u001b[0m\u001b[1;34m5\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m5\u001b[0m\u001b[92m ───────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>, Fold Validation Size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Size: \u001b[1;36m2017\u001b[0m, Fold Validation Size: \u001b[1;36m504\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Train Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1097</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">920</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Train Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m1097\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m920\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold Validation Labels:\n",
       "label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229</span>\n",
       "Name: count, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold Validation Labels:\n",
       "label\n",
       "\u001b[1;36m0\u001b[0m    \u001b[1;36m275\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    \u001b[1;36m229\u001b[0m\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Calculated class weights for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9193254</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0961957</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Calculated class weights for Fold \u001b[1;36m5\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.9193254\u001b[0m \u001b[1;36m1.0961957\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Olivier\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base\\snapshots\\8ccc9b6f36199bec6961081d44eb72fb3f7353f3\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Custom Trainer initialized with class weights </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">stored on CPU</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9193254</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0961957</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mCustom Trainer initialized with class weights \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mstored on CPU\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m0.9193254\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m1.0961957\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Training Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Training Fold \u001b[1;36m5\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2,017\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,518\n",
      "  Number of trainable parameters = 184,423,682\n",
      "Attempting to create safetensors variant\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1518' max='1518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1518/1518 26:39, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.521055</td>\n",
       "      <td>0.873077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.247488</td>\n",
       "      <td>0.941935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.213631</td>\n",
       "      <td>0.954839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>0.958606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.263705</td>\n",
       "      <td>0.952991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.287039</td>\n",
       "      <td>0.953191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Safetensors PR exists\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-253\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-253\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-253\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-506\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-506\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-506\\model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-759\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-759\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-759\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-253] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1012\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1012\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1012\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-506] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1265\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1265\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1265\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-759] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1518\n",
      "Configuration saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1518\\config.json\n",
      "Model weights saved in ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1518\\model.safetensors\n",
      "Deleting older checkpoint [models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1265] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\checkpoint-1012 (score: 0.9586056644880174).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Training Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> completed after </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1599.</span><span style=\"color: #008000; text-decoration-color: #008000\">87s.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Training Fold \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m completed after \u001b[0m\u001b[1;32m1599.\u001b[0m\u001b[32m87s.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 score on internal validation set during training: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9586</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m5\u001b[0m\u001b[36m - Best F1 score on internal validation set during training: \u001b[0m\u001b[1;36m0.9586\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Evaluating and finding best threshold for Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> <span style=\"font-weight: bold\">(</span>using its internal validation split<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Evaluating and finding best threshold for Fold \u001b[1;36m5\u001b[0m \u001b[1m(\u001b[0musing its internal validation split\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 504\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> Internal Validation Metrics <span style=\"font-weight: bold\">(</span>at threshold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'test_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2230423092842102</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_f1'</span>: \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9586056644880174</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.5836</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.621</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.024</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fold \u001b[1;36m5\u001b[0m Internal Validation Metrics \u001b[1m(\u001b[0mat threshold \u001b[1;36m0.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'test_loss'\u001b[0m: \u001b[1;36m0.2230423092842102\u001b[0m, \u001b[32m'test_f1'\u001b[0m: \n",
       "\u001b[1;36m0.9586056644880174\u001b[0m, \u001b[32m'test_runtime'\u001b[0m: \u001b[1;36m10.5836\u001b[0m, \u001b[32m'test_samples_per_second'\u001b[0m: \u001b[1;36m47.621\u001b[0m, \u001b[32m'test_steps_per_second'\u001b[0m: \u001b[1;36m3.024\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Fold </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #008080; text-decoration-color: #008080\"> - Best F1 on Internal Validation: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9625</span><span style=\"color: #008080; text-decoration-color: #008080\"> @ Optimized Threshold = </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9936</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFold \u001b[0m\u001b[1;36m5\u001b[0m\u001b[36m - Best F1 on Internal Validation: \u001b[0m\u001b[1;36m0.9625\u001b[0m\u001b[36m @ Optimized Threshold = \u001b[0m\u001b[1;36m0.9936\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\n",
      "Configuration saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\config.json\n",
      "Model weights saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\model.safetensors\n",
      "tokenizer config file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\tokenizer_config.json\n",
      "Special tokens file saved in ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Best model for Fold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Best model for Fold \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Optimal threshold </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.9936</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span><span style=\"color: #008000; text-decoration-color: #008000\"> saved to </span><span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\threshold.txt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Optimal threshold \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m0.9936\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m saved to \u001b[0m\u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\threshold.txt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up temporary checkpoints directory: </span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up temporary checkpoints directory: \u001b[0m\n",
       "\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8\\fold_5'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up memory for fold </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">5</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up memory for fold \u001b[0m\u001b[1;2;36m5\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Cross-Validation Summary (on Internal Validation Splits)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────── \u001b[0m\u001b[1;32mCross-Validation Summary \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mon Internal Validation Splits\u001b[0m\u001b[1;32m)\u001b[0m\u001b[92m ─────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Fold Performance on Internal Validation Splits         </span>\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Fold </span>┃<span style=\"font-weight: bold\"> F1 (Thr=0.5) </span>┃<span style=\"font-weight: bold\"> Optimized F1 </span>┃<span style=\"font-weight: bold\"> Optimal Thr (Internal) </span>┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 1    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9516 </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       0.9556 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                 0.8799 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 2    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9595 </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       0.9620 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                 0.0512 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 3    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9660 </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       0.9660 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                 0.5448 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 4    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9512 </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       0.9581 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                 0.9987 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 5    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.9586 </span>│<span style=\"color: #008000; text-decoration-color: #008000\">       0.9625 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                 0.9936 </span>│\n",
       "└──────┴──────────────┴──────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m        Fold Performance on Internal Validation Splits         \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFold\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mF1 (Thr=0.5)\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOptimized F1\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOptimal Thr (Internal)\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m1   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9516\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      0.9556\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                0.8799\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m2   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9595\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      0.9620\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                0.0512\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m3   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9660\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      0.9660\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                0.5448\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m4   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9512\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      0.9581\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                0.9987\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m5   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9586\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m      0.9625\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                0.9936\u001b[0m\u001b[33m \u001b[0m│\n",
       "└──────┴──────────────┴──────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Avg F1 <span style=\"font-weight: bold\">(</span>Internal Val, <span style=\"color: #808000; text-decoration-color: #808000\">Thr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">0.9574</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> +/- </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">0.0055</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Avg F1 \u001b[1m(\u001b[0mInternal Val, \u001b[33mThr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35m0.9574\u001b[0m\u001b[1;35m +\u001b[0m\u001b[1;35m/\u001b[0m\u001b[1;35m-\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m0.0055\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Avg F1 <span style=\"font-weight: bold\">(</span>Internal Val, Optimized Thr<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.9608</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> +/- </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.0036</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Avg F1 \u001b[1m(\u001b[0mInternal Val, Optimized Thr\u001b[1m)\u001b[0m: \u001b[1;32m0.9608\u001b[0m\u001b[1;32m +\u001b[0m\u001b[1;32m/\u001b[0m\u001b[1;32m-\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0.0036\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Avg Optimal Threshold <span style=\"font-weight: bold\">(</span>Internal<span style=\"font-weight: bold\">)</span>: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.6937</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> +/- </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.3613</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Avg Optimal Threshold \u001b[1m(\u001b[0mInternal\u001b[1m)\u001b[0m: \u001b[1;33m0.6937\u001b[0m\u001b[1;33m +\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m0.3613\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Cleaning up base temporary checkpoint directory: </span><span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mCleaning up base temporary checkpoint directory: \u001b[0m\u001b[2;32m'./models\\_cv_temp_checkpoints_deberta-v3-base_cv_5folds_ep6_bs8'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Final Evaluation on Holdout Set (valid.csv)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────── \u001b[0m\u001b[1;35mFinal Evaluation on Holdout Set \u001b[0m\u001b[1;35m(\u001b[0m\u001b[1;35mvalid.csv\u001b[0m\u001b[1;35m)\u001b[0m\u001b[92m ───────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing holdout validation dataset <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">786</span> samples<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing holdout validation dataset \u001b[1m(\u001b[0m\u001b[1;36m786\u001b[0m samples\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Using </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">786</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> valid ground truth labels from holdout set for final evaluation.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mUsing \u001b[0m\u001b[1;2;36m786\u001b[0m\u001b[2m valid ground truth labels from holdout set for final evaluation.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running ensemble inference on holdout set using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> models<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Running ensemble inference on holdout set using \u001b[1;36m5\u001b[0m models\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Loading model <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #808000; text-decoration-color: #808000\">./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Loading model \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m from \u001b[33m.\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmodels\u001b[0m\u001b[33m\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n",
      "loading configuration file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model\\model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_1\\best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b358b09de94560bbadb6ec564b0db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout predictions collected for model </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout predictions collected for model \u001b[0m\u001b[1;32m1\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Loading model <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #808000; text-decoration-color: #808000\">./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Loading model \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m from \u001b[33m.\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmodels\u001b[0m\u001b[33m\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n",
      "loading configuration file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model\\model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_2\\best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9946a4acfdcf420f89c92e7417135099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout predictions collected for model </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">2</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout predictions collected for model \u001b[0m\u001b[1;32m2\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Loading model <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #808000; text-decoration-color: #808000\">./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Loading model \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m from \u001b[33m.\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmodels\u001b[0m\u001b[33m\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n",
      "loading configuration file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model\\model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_3\\best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5df300095d04f36aec73d8a9c24928c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout predictions collected for model </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout predictions collected for model \u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Loading model <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #808000; text-decoration-color: #808000\">./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Loading model \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m from \u001b[33m.\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmodels\u001b[0m\u001b[33m\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n",
      "loading configuration file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model\\model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_4\\best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0bb8584d3f40c5a6258ef02e61433c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout predictions collected for model </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout predictions collected for model \u001b[0m\u001b[1;32m4\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Loading model <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #808000; text-decoration-color: #808000\">./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Loading model \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m from \u001b[33m.\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmodels\u001b[0m\u001b[33m\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spm.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n",
      "loading configuration file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.50.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model\\model.safetensors\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./models\\deberta-v3-base_cv_5folds_ep6_bs8\\fold_5\\best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f68d9bab0a040e9aa20b6a58c7d4e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Holdout predictions collected for model </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Holdout predictions collected for model \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Combining holdout probabilities from </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> models (using nanmean)...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36mCombining holdout probabilities from \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;36m models \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36musing nanmean\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Optimizing final threshold directly on holdout ensemble probabilities </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">targeting F1 for class </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mOptimizing final threshold directly on holdout ensemble probabilities \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mtargeting F1 for class \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Optimal threshold for holdout set (Class </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> F1): </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.8147</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> (yielding F1 score: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.9656</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Optimal threshold for holdout set \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32mClass \u001b[0m\u001b[1;32m1\u001b[0m\u001b[1;32m F1\u001b[0m\u001b[1;32m)\u001b[0m\u001b[1;32m: \u001b[0m\u001b[1;32m0.8147\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32myielding F1 score: \u001b[0m\u001b[1;32m0.9656\u001b[0m\u001b[1;32m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Final Ensemble Performance on Holdout Set (valid.csv) with Optimized Threshold</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────── \u001b[0m\u001b[1;35mFinal Ensemble Performance on Holdout Set \u001b[0m\u001b[1;35m(\u001b[0m\u001b[1;35mvalid.csv\u001b[0m\u001b[1;35m)\u001b[0m\u001b[1;35m with Optimized Threshold\u001b[0m\u001b[92m ──────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating on <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">786</span> holdout samples with valid labels.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluating on \u001b[1;36m786\u001b[0m holdout samples with valid labels.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                          \n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Class        </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Precision </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Recall </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> F1-Score </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Support </span> \n",
       " ──────────────────────────────────────────────────────── \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0            </span>     0.9647   0.9762     <span style=\"font-weight: bold\">0.9704</span>       420  \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1            </span>     0.9723   0.9590     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.9656</span>       366  \n",
       "                                                          \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">macro Avg</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    </span>     0.9685   0.9676     0.9680       786  \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">weighted Avg</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span>     0.9682   0.9682     0.9682       786  \n",
       "                                                          \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">Accuracy</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">     </span>                         <span style=\"font-weight: bold\">0.9682</span>       786  \n",
       "                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                          \n",
       " \u001b[1;35m \u001b[0m\u001b[1;35mClass       \u001b[0m\u001b[1;35m \u001b[0m \u001b[1;35m \u001b[0m\u001b[1;35mPrecision\u001b[0m\u001b[1;35m \u001b[0m \u001b[1;35m \u001b[0m\u001b[1;35mRecall\u001b[0m\u001b[1;35m \u001b[0m \u001b[1;35m \u001b[0m\u001b[1;35mF1-Score\u001b[0m\u001b[1;35m \u001b[0m \u001b[1;35m \u001b[0m\u001b[1;35mSupport\u001b[0m\u001b[1;35m \u001b[0m \n",
       " ──────────────────────────────────────────────────────── \n",
       " \u001b[2m \u001b[0m\u001b[2m0           \u001b[0m\u001b[2m \u001b[0m     0.9647   0.9762     \u001b[1m0.9704\u001b[0m       420  \n",
       " \u001b[2m \u001b[0m\u001b[2m1           \u001b[0m\u001b[2m \u001b[0m     0.9723   0.9590     \u001b[1;32m0.9656\u001b[0m       366  \n",
       "                                                          \n",
       " \u001b[2m \u001b[0m\u001b[1;2mmacro Avg\u001b[0m\u001b[2m   \u001b[0m\u001b[2m \u001b[0m     0.9685   0.9676     0.9680       786  \n",
       " \u001b[2m \u001b[0m\u001b[1;2mweighted Avg\u001b[0m\u001b[2m \u001b[0m     0.9682   0.9682     0.9682       786  \n",
       "                                                          \n",
       " \u001b[2m \u001b[0m\u001b[1;2mAccuracy\u001b[0m\u001b[2m    \u001b[0m\u001b[2m \u001b[0m                         \u001b[1m0.9682\u001b[0m       786  \n",
       "                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "🎯 <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Holdout Confusion Matrix</span> <span style=\"font-weight: bold\">(</span>using optimized threshold<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "🎯 \u001b[1;34mHoldout Confusion Matrix\u001b[0m \u001b[1m(\u001b[0musing optimized threshold\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">      True \\ Predicted      </span>\n",
       "                            \n",
       " <span style=\"font-weight: bold\">        </span> <span style=\"font-weight: bold\"> Pred 0 </span> <span style=\"font-weight: bold\"> Pred 1 </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> True 0 </span>   410       10    \n",
       " <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> True 1 </span>    15      351    \n",
       "                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m      True \\ Predicted      \u001b[0m\n",
       "                            \n",
       " \u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mPred 0\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mPred 1\u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " \u001b[2m \u001b[0m\u001b[2mTrue 0\u001b[0m\u001b[2m \u001b[0m   410       10    \n",
       " \u001b[2m \u001b[0m\u001b[2mTrue 1\u001b[0m\u001b[2m \u001b[0m    15      351    \n",
       "                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────── Target Check ────────────────────────────╮\n",
       "│ 🚀 <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Success!</span> F1 score for Class 1 (0.9656) is above the 0.96 target! │\n",
       "╰─────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────── Target Check ────────────────────────────╮\n",
       "│ 🚀 \u001b[1;32mSuccess!\u001b[0m F1 score for Class 1 (0.9656) is above the 0.96 target! │\n",
       "╰─────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> CV completed. Best models saved under <span style=\"color: #008000; text-decoration-color: #008000\">'./models\\deberta-v3-base_cv_5folds_ep6_bs8'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m CV completed. Best models saved under \u001b[32m'./models\\deberta-v3-base_cv_5folds_ep6_bs8'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Each fold's best model is in <span style=\"color: #008000; text-decoration-color: #008000\">'fold_X/best_model/'</span> including <span style=\"color: #008000; text-decoration-color: #008000\">'threshold.txt'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Each fold's best model is in \u001b[32m'fold_X/best_model/'\u001b[0m including \u001b[32m'threshold.txt'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Final evaluation performed on <span style=\"color: #008000; text-decoration-color: #008000\">'valid.csv'</span> using an ensemble and a threshold optimized directly on holdout \n",
       "probabilities.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Final evaluation performed on \u001b[32m'valid.csv'\u001b[0m using an ensemble and a threshold optimized directly on holdout \n",
       "probabilities.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🏁 Script finished.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m🏁 Script finished.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep lightweight imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # Needed for custom loss\n",
    "import os\n",
    "import shutil\n",
    "import sys # For exit on critical errors\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import gc\n",
    "# Defer heavy imports\n",
    "# from transformers import ...\n",
    "# from sklearn.metrics import ...\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration (MODIFIED)\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "N_SPLITS = 5\n",
    "MAX_LENGTH = 512\n",
    "EFFECTIVE_BATCH_SIZE = 8\n",
    "PER_DEVICE_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 6\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "WEIGHT_DECAY = 0.01\n",
    "# This will create a subfolder in BASE_OUTPUT_DIR\n",
    "RUN_NAME = f\"{MODEL_NAME.split('/')[-1]}_cv_{N_SPLITS}folds_ep{EPOCHS}_bs{EFFECTIVE_BATCH_SIZE}\"\n",
    "\n",
    "# Output directory for CV models and results\n",
    "BASE_OUTPUT_DIR = \"./models\" # Base directory where run folders will be created\n",
    "DATA_DIR = \"./data\" # Directory containing train.csv and valid.csv\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    NUM_GPUS = torch.cuda.device_count()\n",
    "    console.print(f\"[cyan]CUDA available. Using {NUM_GPUS} GPU(s). Device: {torch.cuda.get_device_name(0)}[/]\")\n",
    "else:\n",
    "    NUM_GPUS = 1 # Assume 1 for calculation if CPU\n",
    "    console.print(\"[yellow]⚠️ CUDA not available. Training on CPU (will be very slow).[/]\")\n",
    "\n",
    "# Calculate Gradient Accumulation Steps\n",
    "GRADIENT_ACCUMULATION_STEPS = max(1, EFFECTIVE_BATCH_SIZE // (PER_DEVICE_BATCH_SIZE * NUM_GPUS))\n",
    "console.print(f\"[cyan]Effective Batch Size: {EFFECTIVE_BATCH_SIZE}, Per-Device Batch Size: {PER_DEVICE_BATCH_SIZE}, Num GPUs: {NUM_GPUS} => Gradient Accumulation Steps: {GRADIENT_ACCUMULATION_STEPS}[/]\")\n",
    "\n",
    "\n",
    "# --- Defer heavy library imports ---\n",
    "console.print(\"[dim]Importing libraries...[/]\")\n",
    "try:\n",
    "    from transformers import (\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "        Trainer,\n",
    "        TrainingArguments,\n",
    "        EarlyStoppingCallback\n",
    "    )\n",
    "    from sklearn.metrics import f1_score, precision_recall_curve, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "    from rich.panel import Panel\n",
    "    from rich import box\n",
    "    from rich.progress import track\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from transformers import TrainerCallback # Needed for custom trainer loss\n",
    "except ImportError as e:\n",
    "    console.print(f\"[bold red]Error: Missing required library -> {e}[/]\")\n",
    "    console.print(\"[yellow]Please install all necessary libraries (pandas, torch, transformers[accelerate], scikit-learn, rich, tqdm).[/]\")\n",
    "    sys.exit(1)\n",
    "console.print(\"[green]✓ Libraries imported.[/]\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Data (Separately!)\n",
    "# -------------------------------\n",
    "train_csv_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "valid_csv_path = os.path.join(DATA_DIR, \"valid.csv\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    holdout_valid_df = pd.read_csv(valid_csv_path) # Load original valid set separately\n",
    "\n",
    "    # --- Data Cleaning Function ---\n",
    "    def clean_dataframe(df, name):\n",
    "        console.print(f\"Cleaning {name} Data...\")\n",
    "        initial_count = len(df)\n",
    "        # Standardize column names (handle potential variations)\n",
    "        df.columns = [col.lower().strip() for col in df.columns]\n",
    "        if 'labels' in df.columns and 'label' not in df.columns:\n",
    "            df = df.rename(columns={\"labels\": \"label\"})\n",
    "\n",
    "        # Check required columns\n",
    "        required_cols = ['text', 'label']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            missing = [col for col in required_cols if col not in df.columns]\n",
    "            raise KeyError(f\"Missing required columns in {name}: {missing}\")\n",
    "\n",
    "        # Add 'id' column if not present (using index)\n",
    "        if 'id' not in df.columns:\n",
    "             console.print(f\"[dim]Adding 'id' column based on index to {name} data.[/]\")\n",
    "             df['id'] = df.index\n",
    "\n",
    "        # Drop rows with NaNs in text or label\n",
    "        nan_rows = df['text'].isnull() | df['label'].isnull()\n",
    "        if nan_rows.any():\n",
    "            console.print(f\"[yellow]⚠️ NaNs found in {name} data. Dropping {nan_rows.sum()} rows...[/]\")\n",
    "            df = df[~nan_rows].copy()\n",
    "\n",
    "        # Ensure label is numeric and then integer\n",
    "        df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
    "        label_nan_rows = df['label'].isnull()\n",
    "        if label_nan_rows.any():\n",
    "            console.print(f\"[yellow]⚠️ Non-numeric labels found after coercion in {name}. Dropping {label_nan_rows.sum()} rows...[/]\")\n",
    "            df = df[~label_nan_rows].copy()\n",
    "\n",
    "        df['label'] = df['label'].astype(int)\n",
    "\n",
    "        # Ensure text is string\n",
    "        df['text'] = df['text'].astype(str)\n",
    "\n",
    "        cleaned_count = len(df)\n",
    "        if cleaned_count < initial_count:\n",
    "            console.print(f\"[dim]Dropped {initial_count - cleaned_count} rows from {name}.[/]\")\n",
    "\n",
    "        # Check for valid labels (0 and 1)\n",
    "        valid_labels = {0, 1}\n",
    "        if not set(df['label'].unique()).issubset(valid_labels):\n",
    "            invalid_labels = set(df['label'].unique()) - valid_labels\n",
    "            console.print(f\"[yellow]⚠️ Invalid labels found in {name}: {invalid_labels}. Keeping only 0 and 1.[/]\")\n",
    "            df = df[df['label'].isin(valid_labels)].copy()\n",
    "            if len(df) < cleaned_count:\n",
    "                 console.print(f\"[dim]Dropped {cleaned_count - len(df)} rows with invalid labels.[/]\")\n",
    "\n",
    "\n",
    "        console.print(f\"[green]✓ {name} data loaded and cleaned. Total: {len(df)} examples.[/]\")\n",
    "        # Check label distribution\n",
    "        label_counts = df['label'].value_counts()\n",
    "        console.print(f\"{name} data label distribution:\\n{label_counts}\")\n",
    "        if len(label_counts) < 2 and name == \"Training\":\n",
    "             console.print(\"[bold red]Error: Training data must contain both labels 0 and 1 for stratified splitting.[/]\")\n",
    "             sys.exit(1)\n",
    "        return df.reset_index(drop=True) # Reset index after cleaning\n",
    "\n",
    "    train_df = clean_dataframe(train_df, \"Training\")\n",
    "    holdout_valid_df = clean_dataframe(holdout_valid_df, \"Holdout Validation\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    console.print(f\"[bold red]Error: CSV file not found - {e}. Check paths '{train_csv_path}' and '{valid_csv_path}'.[/]\")\n",
    "    sys.exit(1)\n",
    "except KeyError as e:\n",
    "    console.print(f\"[bold red]Error: Missing expected column in CSV - {e}. Ensure 'text' and 'label' (or 'labels') exist.[/]\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    console.print(f\"[bold red]Unexpected error loading/cleaning data: {e}[/]\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define Dataset Class (No changes needed here, uses MAX_LENGTH from config)\n",
    "# -------------------------------\n",
    "class VaccineDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, ids=None, tokenizer=None, max_length=512, is_inference=False):\n",
    "        if tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer must be provided.\")\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.ids = ids # Store IDs if provided\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_inference = (labels is None)\n",
    "\n",
    "        if not self.is_inference and (self.labels is None or len(texts) != len(labels)):\n",
    "            raise ValueError(\"Texts and Labels must be provided and have the same length for training/evaluation.\")\n",
    "        if self.ids is not None and len(texts) != len(self.ids):\n",
    "             raise ValueError(\"Texts and IDs must have the same length if IDs are provided.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx]) if idx < len(self.texts) and self.texts[idx] is not None else \"\"\n",
    "        item_id = self.ids[idx] if self.ids is not None and idx < len(self.ids) else idx # Use index as fallback ID\n",
    "\n",
    "        try:\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "\n",
    "            if not self.is_inference:\n",
    "                if idx < len(self.labels):\n",
    "                    label = self.labels[idx]\n",
    "                    item['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "                else:\n",
    "                     item['labels'] = torch.tensor(-1, dtype=torch.long) # Should not happen\n",
    "\n",
    "            if self.ids is not None:\n",
    "                item['id'] = item_id # Keep ID as is (numeric or string)\n",
    "\n",
    "            return item\n",
    "\n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]Error in __getitem__ at index {idx} (ID: {item_id}): {e}[/]\")\n",
    "            dummy_item = {\n",
    "                'input_ids': torch.zeros(self.max_length, dtype=torch.long),\n",
    "                'attention_mask': torch.zeros(self.max_length, dtype=torch.long),\n",
    "            }\n",
    "            if not self.is_inference:\n",
    "                dummy_item['labels'] = torch.tensor(-1, dtype=torch.long)\n",
    "            if self.ids is not None:\n",
    "                dummy_item['id'] = item_id # Return the original ID even for dummy item\n",
    "            return dummy_item\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Load Tokenizer (once)\n",
    "# -------------------------------\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    console.print(f\"[green]✓ Tokenizer loaded from '{MODEL_NAME}'.[/]\")\n",
    "except Exception as e:\n",
    "    console.print(f\"[bold red]Error loading tokenizer '{MODEL_NAME}': {e}[/]\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Metric Function (for Trainer, based on argmax)\n",
    "# -------------------------------\n",
    "def compute_metrics_for_trainer(eval_pred):\n",
    "    \"\"\"Calculates F1 based on argmax for checkpoint selection during training.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    valid_indices = labels != -1 # Filter out potential errors from __getitem__\n",
    "    labels = labels[valid_indices]\n",
    "    logits = logits[valid_indices]\n",
    "\n",
    "    if len(labels) == 0: return {\"f1\": 0.0} # No valid labels to compute\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    # Calculate F1 for class 1 specifically, as requested\n",
    "    f1 = f1_score(labels, preds, average='binary', pos_label=1, zero_division=0)\n",
    "    return {\"f1\": f1} # Trainer uses this metric key\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. Threshold Optimization Function (MODIFIED: Target Class 1 F1)\n",
    "# -----------------------------------\n",
    "def find_optimal_threshold(labels, probs, target_label=1):\n",
    "    \"\"\"Finds the threshold that maximizes the F1 score for the target_label.\"\"\"\n",
    "    valid_indices = labels != -1\n",
    "    labels = labels[valid_indices]\n",
    "    probs = probs[valid_indices]\n",
    "\n",
    "    if len(labels) == 0 or len(np.unique(labels)) < 2:\n",
    "         console.print(\"[yellow]⚠️ Not enough valid data or classes for threshold optimization. Returning default 0.5.[/]\")\n",
    "         return 0.5, 0.0\n",
    "\n",
    "    # Ensure probs are for the positive class (target_label)\n",
    "    # Assuming probs are already P(class=1) as calculated later\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, probs, pos_label=target_label)\n",
    "\n",
    "    # Calculate F1 score, avoiding division by zero\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "    f1_scores = f1_scores[:-1] # Drop last value corresponding to no prediction\n",
    "    thresholds = thresholds[:len(f1_scores)] # Align thresholds with scores\n",
    "\n",
    "    f1_scores = np.nan_to_num(f1_scores) # Handle potential NaNs if precision/recall are zero\n",
    "\n",
    "    if len(f1_scores) == 0:\n",
    "         console.print(\"[yellow]⚠️ No valid F1 scores computed during threshold search. Returning default 0.5.[/]\")\n",
    "         return 0.5, 0.0\n",
    "\n",
    "    best_f1_idx = np.argmax(f1_scores)\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "    best_thresh = thresholds[best_f1_idx]\n",
    "\n",
    "    # Sanity check against 0.5 threshold F1 for the target class\n",
    "    preds_at_05 = (probs >= 0.5).astype(int)\n",
    "    f1_at_05 = f1_score(labels, preds_at_05, pos_label=target_label, zero_division=0)\n",
    "\n",
    "    # Optionally uncomment to see comparison\n",
    "    # console.print(f\"[dim]Threshold search: Best F1={best_f1:.4f} @ Thr={best_thresh:.4f} vs F1={f1_at_05:.4f} @ Thr=0.5[/]\")\n",
    "\n",
    "    # No need to force 0.5, let the optimization decide\n",
    "    return best_thresh, best_f1\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Custom Trainer for Weighted Loss (CORRECTED)\n",
    "# -------------------------------\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Store weights on CPU initially, move to device in compute_loss\n",
    "        self.class_weights_cpu = class_weights.cpu() if class_weights is not None else None\n",
    "        if self.class_weights_cpu is not None:\n",
    "            console.print(f\"[cyan]Custom Trainer initialized with class weights (stored on CPU): {self.class_weights_cpu.numpy()}[/]\")\n",
    "        else:\n",
    "            console.print(\"[yellow]⚠️ Custom Trainer initialized WITHOUT class weights (will use standard CE loss).[/]\")\n",
    "\n",
    "    # Modify signature to accept **kwargs\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the loss using class weights if provided, otherwise falls back\n",
    "        to the default Trainer loss computation.\n",
    "        Accepts **kwargs to handle potential extra arguments passed by the Trainer internals.\n",
    "        \"\"\"\n",
    "        if self.class_weights_cpu is None:\n",
    "            # No class weights provided, fall back to the default Hugging Face loss.\n",
    "            # Pass along any extra kwargs received.\n",
    "            # console.print(\"[dim]Using default compute_loss (no weights).[/dim]\") # Optional debug print\n",
    "            return super().compute_loss(model, inputs, return_outputs=return_outputs, **kwargs)\n",
    "        else:\n",
    "            # Class weights are provided, compute custom weighted loss.\n",
    "            if \"labels\" not in inputs:\n",
    "                raise ValueError(\"Inputs must contain 'labels' for custom loss calculation.\")\n",
    "\n",
    "            labels = inputs.pop(\"labels\") # Remove labels from inputs to avoid passing them to the model directly if not needed\n",
    "            outputs = model(**inputs)     # Pass remaining inputs to the model\n",
    "            logits = outputs.get(\"logits\")\n",
    "\n",
    "            if logits is None:\n",
    "                 # Handle cases where the model output format might be different\n",
    "                 # If your model returns loss directly, you might need to adjust\n",
    "                 console.print(\"[yellow]⚠️ Model outputs did not contain 'logits'. Falling back to default loss calculation if possible.[/]\")\n",
    "                 # Re-add labels for the potential fallback\n",
    "                 inputs[\"labels\"] = labels\n",
    "                 return super().compute_loss(model, inputs, return_outputs=return_outputs, **kwargs)\n",
    "\n",
    "            # --- Custom Loss Calculation ---\n",
    "            # Move weights to the same device as logits just-in-time\n",
    "            class_weights_on_device = self.class_weights_cpu.to(logits.device)\n",
    "            # console.print(f\"[dim]Using weighted loss on device {logits.device} with weights {class_weights_on_device.cpu().numpy()}.[/dim]\") # Optional debug print\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=class_weights_on_device)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "            # --- End Custom Loss Calculation ---\n",
    "\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Cross-Validation Loop (on train_df ONLY) (MODIFIED PATHS)\n",
    "# -------------------------------\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_results = []\n",
    "best_model_paths = [] # Store paths to best model dir (e.g., ./models/RUN_NAME/fold_X/best_model)\n",
    "\n",
    "# --- Create the main output directory for this run ---\n",
    "RUN_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, RUN_NAME)\n",
    "os.makedirs(RUN_OUTPUT_DIR, exist_ok=True)\n",
    "console.print(f\"[INFO] CV Run output will be saved under: '{RUN_OUTPUT_DIR}'\")\n",
    "# --- Create a directory for temporary checkpoints ---\n",
    "TEMP_CHECKPOINT_BASE_DIR = os.path.join(BASE_OUTPUT_DIR, f\"_cv_temp_checkpoints_{RUN_NAME}\")\n",
    "os.makedirs(TEMP_CHECKPOINT_BASE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "console.rule(\"[bold yellow]Starting Cross-Validation on Training Data[/]\")\n",
    "\n",
    "# Use train_df for splitting\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df['text'], train_df['label'])):\n",
    "    current_fold = fold + 1\n",
    "    console.rule(f\"[bold blue]CV Fold {current_fold}/{N_SPLITS}[/]\")\n",
    "\n",
    "    # --- Get fold data from train_df ---\n",
    "    train_fold_df = train_df.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    fold_valid_df = train_df.iloc[val_idx].copy().reset_index(drop=True) # Validation set FOR THIS FOLD\n",
    "\n",
    "    console.print(f\"Fold Train Size: {len(train_fold_df)}, Fold Validation Size: {len(fold_valid_df)}\")\n",
    "    train_fold_labels_dist = train_fold_df['label'].value_counts(dropna=False).sort_index()\n",
    "    valid_fold_labels_dist = fold_valid_df['label'].value_counts(dropna=False).sort_index()\n",
    "    console.print(f\"Fold Train Labels:\\n{train_fold_labels_dist}\")\n",
    "    console.print(f\"Fold Validation Labels:\\n{valid_fold_labels_dist}\")\n",
    "\n",
    "    if len(train_fold_labels_dist) < 2:\n",
    "        console.print(f\"[bold red]Error: Fold {current_fold} training data only has one class after splitting. Skipping fold.[/]\")\n",
    "        continue\n",
    "\n",
    "    # --- Calculate Class Weights for this fold's training data ---\n",
    "    try:\n",
    "        n_samples = len(train_fold_df)\n",
    "        n_classes = 2\n",
    "        class_counts = train_fold_labels_dist.to_dict()\n",
    "        # Ensure both 0 and 1 counts exist, default to 1 if missing (to avoid div by zero, though split should prevent this)\n",
    "        count0 = class_counts.get(0, 1)\n",
    "        count1 = class_counts.get(1, 1)\n",
    "\n",
    "        # Inverse frequency weighting: weight = total_samples / (n_classes * count_for_class)\n",
    "        weight0 = n_samples / (n_classes * count0)\n",
    "        weight1 = n_samples / (n_classes * count1)\n",
    "\n",
    "        class_weights_tensor = torch.tensor([weight0, weight1], dtype=torch.float)\n",
    "        console.print(f\"Calculated class weights for Fold {current_fold}: {class_weights_tensor.numpy()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error calculating class weights for fold {current_fold}: {e}. Proceeding without weights.[/]\")\n",
    "        class_weights_tensor = None # Fallback\n",
    "\n",
    "    # --- Create fold datasets ---\n",
    "    try:\n",
    "        train_dataset = VaccineDataset(\n",
    "            texts=train_fold_df['text'].tolist(),\n",
    "            labels=train_fold_df['label'].tolist(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=MAX_LENGTH\n",
    "        )\n",
    "        fold_eval_dataset = VaccineDataset(\n",
    "            texts=fold_valid_df['text'].tolist(),\n",
    "            labels=fold_valid_df['label'].tolist(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=MAX_LENGTH\n",
    "        )\n",
    "        if len(train_dataset) == 0 or len(fold_eval_dataset) == 0:\n",
    "             console.print(f\"[bold red]Error: Empty dataset for fold {current_fold}. Skipping fold.[/]\")\n",
    "             continue\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error creating datasets for fold {current_fold}: {e}[/]\")\n",
    "        continue\n",
    "\n",
    "    # --- Load fresh model ---\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error loading model for fold {current_fold}: {e}[/]\")\n",
    "        continue\n",
    "\n",
    "    # --- Define Training Paths (MODIFIED STRUCTURE) ---\n",
    "    # Temporary directory for checkpoints during this fold's training\n",
    "    fold_temp_checkpoint_dir = os.path.join(TEMP_CHECKPOINT_BASE_DIR, f\"fold_{current_fold}\")\n",
    "    # Final directory structure for the *best* saved model of this fold\n",
    "    final_fold_output_basedir = os.path.join(RUN_OUTPUT_DIR, f\"fold_{current_fold}\")\n",
    "    final_best_model_dir = os.path.join(final_fold_output_basedir, \"best_model\") # <<< CHANGED STRUCTURE\n",
    "\n",
    "    # --- Training Arguments ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=fold_temp_checkpoint_dir,    # <<< Use temporary dir for checkpoints\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=PER_DEVICE_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=PER_DEVICE_BATCH_SIZE * 2,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        disable_tqdm=False,\n",
    "        load_best_model_at_end=True,            # Crucial for getting the best model\n",
    "        metric_for_best_model=\"f1\",             # Use F1 on fold's validation set\n",
    "        greater_is_better=True,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_steps=max(10, len(train_dataset) // (EFFECTIVE_BATCH_SIZE * 4)),\n",
    "        log_level=\"info\",\n",
    "        save_total_limit=2,                     # Limit checkpoints saved in temp dir\n",
    "        seed=SEED + fold,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=[],\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=torch.cuda.is_available(),\n",
    "        optim=\"adamw_torch\",\n",
    "    )\n",
    "\n",
    "    # --- Trainer Setup ---\n",
    "    trainer = WeightedLossTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=fold_eval_dataset,\n",
    "        compute_metrics=compute_metrics_for_trainer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "                                         early_stopping_threshold=0.001)],\n",
    "        class_weights=class_weights_tensor\n",
    "    )\n",
    "\n",
    "    # --- Train ---\n",
    "    console.print(f\"🚀 Training Fold {current_fold}...\")\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        console.print(f\"[green]✓ Training Fold {current_fold} completed after {train_result.metrics.get('train_runtime', 0):.2f}s.[/]\")\n",
    "        best_metric_val = trainer.state.best_metric\n",
    "        if best_metric_val:\n",
    "             console.print(f\"[cyan]Fold {current_fold} - Best F1 score on internal validation set during training: {best_metric_val:.4f}[/]\")\n",
    "        else:\n",
    "             console.print(\"[yellow]Could not retrieve best metric from trainer state.[/]\")\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error during training for fold {current_fold}: {e}[/]\")\n",
    "        del model, trainer, train_dataset, fold_eval_dataset; gc.collect(); torch.cuda.empty_cache()\n",
    "        continue # Skip to next fold\n",
    "\n",
    "    # --- Evaluate on Fold's Validation Set & Find Optimal Threshold for THIS fold ---\n",
    "    console.print(f\"🔍 Evaluating and finding best threshold for Fold {current_fold} (using its internal validation split)...\")\n",
    "    try:\n",
    "        predictions_output = trainer.predict(fold_eval_dataset)\n",
    "        logits = predictions_output.predictions\n",
    "        labels = predictions_output.label_ids\n",
    "        internal_val_metrics = predictions_output.metrics\n",
    "\n",
    "        console.print(f\"Fold {current_fold} Internal Validation Metrics (at threshold 0.5): {internal_val_metrics}\")\n",
    "\n",
    "        if logits is not None and labels is not None:\n",
    "            # Calculate probabilities for the positive class (1)\n",
    "            if logits.shape[1] >= 2:\n",
    "                probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "            elif logits.shape[1] == 1:\n",
    "                 probs = torch.sigmoid(torch.tensor(logits)).squeeze(-1).numpy()\n",
    "            else:\n",
    "                 probs = np.array([])\n",
    "                 console.print(f\"[yellow]⚠️ Unexpected logits shape in fold {current_fold}: {logits.shape}. Cannot calculate probs.[/]\")\n",
    "\n",
    "            if probs.size > 0:\n",
    "                # Find optimal threshold based on this fold's validation split, targeting class 1\n",
    "                optimal_thresh_fold, best_f1_fold_val = find_optimal_threshold(labels, probs, target_label=1)\n",
    "\n",
    "                console.print(f\"[cyan]Fold {current_fold} - Best F1 on Internal Validation: {best_f1_fold_val:.4f} @ Optimized Threshold = {optimal_thresh_fold:.4f}[/]\")\n",
    "                fold_results.append({\n",
    "                    \"fold\": current_fold,\n",
    "                    \"best_f1_internal_val_optimized\": best_f1_fold_val,\n",
    "                    \"optimal_threshold_internal\": optimal_thresh_fold,\n",
    "                    \"f1_internal_val_0.5\": internal_val_metrics.get('test_f1', 0.0)\n",
    "                })\n",
    "\n",
    "                # --- Save Best Model for Ensemble (MODIFIED PATH & FILENAME) ---\n",
    "                try:\n",
    "                    # Create the specific final directory structure: RUN_OUTPUT_DIR/fold_X/best_model/\n",
    "                    os.makedirs(final_best_model_dir, exist_ok=True) # <<< ENSURE FINAL DIR EXISTS\n",
    "                    trainer.save_model(final_best_model_dir) # Save model files here\n",
    "                    tokenizer.save_pretrained(final_best_model_dir) # Save tokenizer here\n",
    "                    best_model_paths.append(final_best_model_dir) # Store path for later ensemble\n",
    "                    console.print(f\"[green]✓ Best model for Fold {current_fold} saved to '{final_best_model_dir}'[/]\")\n",
    "\n",
    "                    # --- Save the optimal threshold file (MODIFIED FILENAME) ---\n",
    "                    threshold_file_path = os.path.join(final_best_model_dir, \"threshold.txt\") # <<< CHANGED FILENAME\n",
    "                    with open(threshold_file_path, \"w\") as f: f.write(f\"{optimal_thresh_fold:.4f}\")\n",
    "                    console.print(f\"[green]✓ Optimal threshold ({optimal_thresh_fold:.4f}) saved to '{threshold_file_path}'[/]\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    console.print(f\"[bold red]Error saving best model or threshold for fold {current_fold}: {e}[/]\")\n",
    "                    best_checkpoint_path = trainer.state.best_model_checkpoint\n",
    "                    if best_checkpoint_path and os.path.isdir(best_checkpoint_path):\n",
    "                         console.print(f\"[yellow]Best checkpoint was at: {best_checkpoint_path}. Consider manually copying.[/]\")\n",
    "                    else:\n",
    "                         console.print(f\"[yellow]⚠️ No best model path found for fold {current_fold}. Cannot use for ensemble.[/]\")\n",
    "\n",
    "            else:\n",
    "                 console.print(f\"[yellow]⚠️ No probabilities calculated for fold {current_fold}. Cannot optimize threshold.[/]\")\n",
    "                 # Try to save the model anyway if training completed, but without threshold\n",
    "                 try:\n",
    "                     os.makedirs(final_best_model_dir, exist_ok=True)\n",
    "                     trainer.save_model(final_best_model_dir)\n",
    "                     tokenizer.save_pretrained(final_best_model_dir)\n",
    "                     best_model_paths.append(final_best_model_dir)\n",
    "                     console.print(f\"[yellow]✓ Model saved to '{final_best_model_dir}' despite probability calculation issue (NO threshold file saved).[/]\")\n",
    "                 except Exception as e_save:\n",
    "                     console.print(f\"[bold red]Error saving model for fold {current_fold} after probability issue: {e_save}[/]\")\n",
    "\n",
    "        else:\n",
    "            console.print(f\"[yellow]⚠️ Prediction output missing logits or labels for fold {current_fold}. Cannot evaluate or save best model.[/]\")\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error during evaluation/optimization/saving for fold {current_fold}: {e}[/]\")\n",
    "        del model, trainer, train_dataset, fold_eval_dataset; gc.collect(); torch.cuda.empty_cache()\n",
    "        continue # Skip to next fold\n",
    "\n",
    "    # --- Clean Temporary Checkpoints (MODIFIED PATH) ---\n",
    "    console.print(f\"[dim]Cleaning up temporary checkpoints directory: '{fold_temp_checkpoint_dir}'[/]\")\n",
    "    try:\n",
    "        shutil.rmtree(fold_temp_checkpoint_dir) # <<< Use correct temp path\n",
    "    except OSError as e:\n",
    "        console.print(f\"[yellow]⚠️ Error deleting checkpoint directory {fold_temp_checkpoint_dir}: {e}[/]\")\n",
    "\n",
    "\n",
    "    # --- Free memory after fold completion ---\n",
    "    console.print(f\"[dim]Cleaning up memory for fold {current_fold}...[/dim]\")\n",
    "    del model, trainer, train_dataset, fold_eval_dataset, predictions_output, logits, labels, probs\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# --- End of CV Loop ---\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Display CV Summary\n",
    "# -------------------------------\n",
    "console.rule(\"[bold green]Cross-Validation Summary (on Internal Validation Splits)[/]\")\n",
    "if fold_results:\n",
    "    results_table = Table(title=\"Fold Performance on Internal Validation Splits\")\n",
    "    results_table.add_column(\"Fold\", style=\"cyan\")\n",
    "    results_table.add_column(\"F1 (Thr=0.5)\", style=\"magenta\", justify=\"right\")\n",
    "    results_table.add_column(\"Optimized F1\", style=\"green\", justify=\"right\")\n",
    "    results_table.add_column(\"Optimal Thr (Internal)\", style=\"yellow\", justify=\"right\")\n",
    "\n",
    "    all_f1s_opt = [res[\"best_f1_internal_val_optimized\"] for res in fold_results]\n",
    "    all_f1s_05 = [res[\"f1_internal_val_0.5\"] for res in fold_results]\n",
    "    all_thresholds = [res[\"optimal_threshold_internal\"] for res in fold_results]\n",
    "\n",
    "    for res in fold_results:\n",
    "        results_table.add_row(\n",
    "            str(res[\"fold\"]),\n",
    "            f\"{res['f1_internal_val_0.5']:.4f}\",\n",
    "            f\"{res['best_f1_internal_val_optimized']:.4f}\",\n",
    "            f\"{res['optimal_threshold_internal']:.4f}\"\n",
    "        )\n",
    "    console.print(results_table)\n",
    "\n",
    "    avg_f1_opt = np.mean(all_f1s_opt)\n",
    "    std_f1_opt = np.std(all_f1s_opt)\n",
    "    avg_f1_05 = np.mean(all_f1s_05)\n",
    "    std_f1_05 = np.std(all_f1s_05)\n",
    "    avg_thresh = np.mean(all_thresholds)\n",
    "    std_thresh = np.std(all_thresholds)\n",
    "\n",
    "    console.print(f\"\\nAvg F1 (Internal Val, Thr=0.5): [bold magenta]{avg_f1_05:.4f} +/- {std_f1_05:.4f}[/]\")\n",
    "    console.print(f\"Avg F1 (Internal Val, Optimized Thr): [bold green]{avg_f1_opt:.4f} +/- {std_f1_opt:.4f}[/]\")\n",
    "    console.print(f\"Avg Optimal Threshold (Internal): [bold yellow]{avg_thresh:.4f} +/- {std_thresh:.4f}[/]\")\n",
    "\n",
    "    if len(best_model_paths) != N_SPLITS:\n",
    "         console.print(f\"[yellow]⚠️ Found {len(best_model_paths)} best models, expected {N_SPLITS}. Ensemble evaluation might be affected.[/]\")\n",
    "\n",
    "else:\n",
    "    console.print(\"[yellow]No fold results recorded. Check for errors during training/evaluation.[/]\")\n",
    "\n",
    "# --- Cleanup Overall Temp Checkpoint Dir ---\n",
    "console.print(f\"[dim]Cleaning up base temporary checkpoint directory: '{TEMP_CHECKPOINT_BASE_DIR}'[/]\")\n",
    "try:\n",
    "    shutil.rmtree(TEMP_CHECKPOINT_BASE_DIR)\n",
    "except OSError as e:\n",
    "    console.print(f\"[yellow]⚠️ Error deleting base temp checkpoint directory {TEMP_CHECKPOINT_BASE_DIR}: {e}[/]\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 9. FINAL EVALUATION ON HOLDOUT VALIDATION SET (valid.csv)\n",
    "# Using Ensemble of Best Fold Models\n",
    "# Optimize Threshold DIRECTLY on Holdout Set\n",
    "# -----------------------------------------------------\n",
    "console.rule(\"[bold magenta]Final Evaluation on Holdout Set (valid.csv)[/]\")\n",
    "\n",
    "if not best_model_paths:\n",
    "    console.print(\"[bold red]❌ No best models saved from CV folds. Cannot perform final evaluation.[/]\")\n",
    "    sys.exit(1)\n",
    "if len(holdout_valid_df) == 0:\n",
    "    console.print(\"[bold red]❌ Holdout validation data ('valid.csv') is empty. Cannot perform final evaluation.[/]\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# --- Create Dataset & Loader for Holdout Set ---\n",
    "console.print(f\"Preparing holdout validation dataset ({len(holdout_valid_df)} samples)...\")\n",
    "try:\n",
    "    # Include IDs and labels for evaluation\n",
    "    holdout_dataset = VaccineDataset(\n",
    "        texts=holdout_valid_df['text'].tolist(),\n",
    "        labels=holdout_valid_df['label'].tolist(), # Include true labels\n",
    "        ids=holdout_valid_df['id'].tolist(),       # Include IDs\n",
    "        tokenizer=tokenizer, # Use the globally loaded tokenizer\n",
    "        max_length=MAX_LENGTH,\n",
    "        is_inference=False # We have labels for evaluation\n",
    "    )\n",
    "    holdout_loader = DataLoader(holdout_dataset, batch_size=PER_DEVICE_BATCH_SIZE * 2, shuffle=False, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "    # Get true labels in the correct order, filtering any potential -1 from dataset errors\n",
    "    holdout_y_true_raw = np.array(holdout_valid_df['label'].tolist())\n",
    "    valid_true_indices = holdout_y_true_raw != -1\n",
    "    holdout_y_true = holdout_y_true_raw[valid_true_indices]\n",
    "    console.print(f\"[dim]Using {len(holdout_y_true)} valid ground truth labels from holdout set for final evaluation.[/]\")\n",
    "\n",
    "except Exception as e:\n",
    "     console.print(f\"[bold red]❌ Error creating holdout dataset/loader: {e}. Cannot perform final evaluation.[/]\")\n",
    "     sys.exit(1)\n",
    "\n",
    "\n",
    "# --- Ensemble Inference on Holdout Set ---\n",
    "console.print(f\"Running ensemble inference on holdout set using {len(best_model_paths)} models...\")\n",
    "all_holdout_probs_np = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Ensure device is set\n",
    "\n",
    "for i, model_p in enumerate(best_model_paths):\n",
    "    console.print(f\"--- Loading model {i+1}/{len(best_model_paths)} from [yellow]{model_p}[/] ---\") # Print full path now\n",
    "    try:\n",
    "        # Load model AND tokenizer specific to that fold (best practice)\n",
    "        # Although we saved the global tokenizer, loading from the model dir ensures consistency if needed\n",
    "        fold_tokenizer = AutoTokenizer.from_pretrained(model_p)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_p).to(device).eval()\n",
    "        # Re-create dataset/loader with fold-specific tokenizer? Could be more robust but slower.\n",
    "        # Let's stick to the global tokenizer for inference speed, assuming compatibility.\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]❌ Error loading model {model_p}: {e}. Skipping this model for ensemble.[/]\")\n",
    "        continue\n",
    "\n",
    "    fold_holdout_probs_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in track(holdout_loader, description=f\"Predicting (Holdout, Model {i+1})...\", console=console, transient=False):\n",
    "            input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "            batch_labels = batch.get(\"labels\", torch.tensor([-1]*len(input_ids))) # Get labels if present\n",
    "\n",
    "            # Identify valid items in the batch (label != -1, which our Dataset uses for errors)\n",
    "            valid_batch_indices_mask = (batch_labels != -1).cpu()\n",
    "            valid_input_ids = input_ids[valid_batch_indices_mask]\n",
    "            valid_attention_mask = attention_mask[valid_batch_indices_mask]\n",
    "\n",
    "            # Skip batch if no valid items (e.g., all errored in __getitem__)\n",
    "            if valid_input_ids.shape[0] == 0:\n",
    "                 # Append placeholder NaNs for invalid items\n",
    "                 batch_probs = np.full(len(input_ids), np.nan)\n",
    "                 fold_holdout_probs_list.extend(batch_probs)\n",
    "                 continue\n",
    "\n",
    "            try:\n",
    "                outputs = model(input_ids=valid_input_ids, attention_mask=valid_attention_mask)\n",
    "                logits = outputs.logits\n",
    "                if logits.shape[1] >= 2:\n",
    "                    probs = torch.softmax(logits, dim=1)[:, 1] # Prob for class 1\n",
    "                elif logits.shape[1] == 1:\n",
    "                    probs = torch.sigmoid(logits).squeeze(-1)\n",
    "                else:\n",
    "                    probs = torch.full((valid_input_ids.shape[0],), 0.5, device=device) # Fallback guess\n",
    "\n",
    "                # Place probabilities back into the original batch structure using NaN for invalid items\n",
    "                batch_probs = np.full(len(input_ids), np.nan) # Initialize with NaNs\n",
    "                batch_probs[valid_batch_indices_mask.numpy()] = probs.cpu().numpy()\n",
    "                fold_holdout_probs_list.extend(batch_probs)\n",
    "\n",
    "\n",
    "            except Exception as pred_e:\n",
    "                console.print(f\"\\n[bold red]❌ Error during holdout prediction batch with model {i+1}: {pred_e}[/]\")\n",
    "                 # Add NaNs for the failed batch to maintain length and indicate failure\n",
    "                fold_holdout_probs_list.extend(np.full(len(input_ids), np.nan))\n",
    "\n",
    "\n",
    "    # Convert list of batch arrays to a single numpy array for the fold\n",
    "    fold_holdout_probs = np.array(fold_holdout_probs_list)\n",
    "\n",
    "    # Ensure length matches dataset size, pad with NaNs if needed (shouldn't happen with current logic)\n",
    "    if len(fold_holdout_probs) != len(holdout_dataset):\n",
    "         console.print(f\"[yellow]⚠️ Length mismatch for fold {i+1} predictions ({len(fold_holdout_probs)}) vs dataset ({len(holdout_dataset)}). Padding with NaN.[/]\")\n",
    "         fold_holdout_probs = np.pad(fold_holdout_probs, (0, len(holdout_dataset) - len(fold_holdout_probs)), constant_values=np.nan)\n",
    "\n",
    "    all_holdout_probs_np.append(fold_holdout_probs[:len(holdout_dataset)]) # Ensure correct length\n",
    "    console.print(f\"[green]✓ Holdout predictions collected for model {i+1}.[/]\")\n",
    "\n",
    "    # Free memory\n",
    "    del model, outputs, logits, probs, fold_tokenizer; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# --- Aggregate and Evaluate Holdout Predictions ---\n",
    "if not all_holdout_probs_np:\n",
    "    console.print(\"[bold red]❌ No predictions generated for the holdout set by any valid model.[/]\")\n",
    "else:\n",
    "    num_ensemble_models = len(all_holdout_probs_np)\n",
    "    console.print(f\"\\n[bold cyan]Combining holdout probabilities from {num_ensemble_models} models (using nanmean)...[/]\")\n",
    "    # Use nanmean to average probabilities, ignoring NaNs from failed predictions/invalid data\n",
    "    holdout_avg_probs_raw = np.nanmean(np.array(all_holdout_probs_np), axis=0)\n",
    "\n",
    "    # Filter probabilities corresponding to valid true labels\n",
    "    holdout_avg_probs = holdout_avg_probs_raw[valid_true_indices]\n",
    "\n",
    "    # Check if we have valid probabilities and labels to work with\n",
    "    if len(holdout_avg_probs) == 0 or np.all(np.isnan(holdout_avg_probs)):\n",
    "        console.print(\"[bold red]❌ No valid averaged probabilities obtained for the holdout set. Cannot optimize threshold or evaluate.[/]\")\n",
    "    elif len(holdout_y_true) == 0:\n",
    "         console.print(\"[bold red]❌ No valid ground truth labels found in the holdout set. Cannot optimize threshold or evaluate.[/]\")\n",
    "    else:\n",
    "        # --- Optimize Threshold Directly on Holdout Ensemble Probs ---\n",
    "        console.print(\"[cyan]Optimizing final threshold directly on holdout ensemble probabilities (targeting F1 for class 1)...[/]\")\n",
    "        final_holdout_threshold, best_f1_on_holdout = find_optimal_threshold(holdout_y_true, holdout_avg_probs, target_label=1)\n",
    "        console.print(f\"[bold green]✓ Optimal threshold for holdout set (Class 1 F1): {final_holdout_threshold:.4f} (yielding F1 score: {best_f1_on_holdout:.4f})[/]\")\n",
    "\n",
    "        # Apply this optimal threshold\n",
    "        holdout_predictions = (holdout_avg_probs >= final_holdout_threshold).astype(int)\n",
    "\n",
    "        # --- Final Report on Holdout Set ---\n",
    "        console.rule(\"[bold magenta]Final Ensemble Performance on Holdout Set (valid.csv) with Optimized Threshold[/]\")\n",
    "        try:\n",
    "            # We already filtered labels (holdout_y_true) and predictions (holdout_predictions)\n",
    "            console.print(f\"Evaluating on {len(holdout_y_true)} holdout samples with valid labels.\")\n",
    "            report = classification_report(holdout_y_true, holdout_predictions, output_dict=True, digits=4, zero_division=0)\n",
    "\n",
    "            # Display Report Table\n",
    "            report_table = Table(show_header=True, header_style=\"bold magenta\", box=box.SIMPLE)\n",
    "            report_table.add_column(\"Class\", style=\"dim\", width=12)\n",
    "            report_table.add_column(\"Precision\", justify=\"right\")\n",
    "            report_table.add_column(\"Recall\", justify=\"right\")\n",
    "            report_table.add_column(\"F1-Score\", justify=\"right\")\n",
    "            report_table.add_column(\"Support\", justify=\"right\")\n",
    "\n",
    "            labels_in_report = [label for label in sorted(report.keys()) if label not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "            for label in labels_in_report:\n",
    "                 metrics = report[label]\n",
    "                 style = \"green\" if label == '1' and metrics['f1-score'] > 0.96 else \"\"\n",
    "                 report_table.add_row(str(label), f\"{metrics['precision']:.4f}\", f\"{metrics['recall']:.4f}\", f\"[bold {style}]{metrics['f1-score']:.4f}[/]\", f\"{int(metrics['support'])}\")\n",
    "\n",
    "            report_table.add_section()\n",
    "            for avg_type in [\"macro avg\", \"weighted avg\"]:\n",
    "                 if avg_type in report:\n",
    "                     metrics = report[avg_type]\n",
    "                     name = avg_type.replace(\" avg\", \" Avg\")\n",
    "                     report_table.add_row(f\"[bold]{name}[/]\", f\"{metrics['precision']:.4f}\", f\"{metrics['recall']:.4f}\", f\"{metrics['f1-score']:.4f}\", f\"{int(metrics['support'])}\")\n",
    "\n",
    "            if \"accuracy\" in report:\n",
    "                 accuracy = report[\"accuracy\"]\n",
    "                 total_support = int(report[\"weighted avg\"][\"support\"]) if \"weighted avg\" in report else len(holdout_y_true)\n",
    "                 report_table.add_section()\n",
    "                 report_table.add_row(\"[bold]Accuracy[/]\", \"\", \"\", f\"[bold]{accuracy:.4f}[/]\", f\"{total_support}\")\n",
    "\n",
    "            console.print(report_table)\n",
    "\n",
    "            # Display Confusion Matrix\n",
    "            console.print(\"\\n🎯 [bold blue]Holdout Confusion Matrix[/bold blue] (using optimized threshold)\\n\")\n",
    "            cm_labels = sorted(list(set(holdout_y_true) | set(holdout_predictions)))\n",
    "            if not cm_labels: cm_labels = [0, 1] # Default if only one class predicted/present\n",
    "            elif len(cm_labels) == 1: cm_labels = [0, 1] # Ensure both 0 and 1 are columns if only one exists\n",
    "\n",
    "            cm = confusion_matrix(holdout_y_true, holdout_predictions, labels=cm_labels)\n",
    "            cm_table = Table(title=\"True \\\\ Predicted\", box=box.SIMPLE_HEAVY, show_header=True, header_style=\"bold\")\n",
    "            cm_table.add_column(\"\", justify=\"center\", style=\"dim\") # Empty top-left corner\n",
    "            for label in cm_labels:\n",
    "                cm_table.add_column(f\"Pred {label}\", justify=\"center\")\n",
    "\n",
    "            for i, true_label in enumerate(cm_labels):\n",
    "                row_data = [f\"True {true_label}\"] + [str(cm[i, j]) for j in range(len(cm_labels))]\n",
    "                cm_table.add_row(*row_data)\n",
    "            console.print(cm_table)\n",
    "\n",
    "            # Explicitly check the target F1 score\n",
    "            f1_class_1 = report.get('1', {}).get('f1-score', 0.0)\n",
    "            if f1_class_1 > 0.96:\n",
    "                 console.print(Panel(f\"🚀 [bold green]Success![/] F1 score for Class 1 ({f1_class_1:.4f}) is above the 0.96 target!\", title=\"Target Check\", expand=False))\n",
    "            else:\n",
    "                 console.print(Panel(f\"⚠️ [bold yellow]Target Not Met.[/] F1 score for Class 1 ({f1_class_1:.4f}) is below 0.96.\", title=\"Target Check\", expand=False))\n",
    "\n",
    "\n",
    "        except Exception as report_e:\n",
    "            console.print(f\"[bold red]❌ Error generating final holdout report: {report_e}[/]\")\n",
    "\n",
    "\n",
    "console.print(f\"\\n[INFO] CV completed. Best models saved under '{RUN_OUTPUT_DIR}'.\") # <-- MODIFIED Log Message\n",
    "console.print(\"[INFO] Each fold's best model is in 'fold_X/best_model/' including 'threshold.txt'.\")\n",
    "console.print(\"[INFO] Final evaluation performed on 'valid.csv' using an ensemble and a threshold optimized directly on holdout probabilities.\")\n",
    "console.print(\"[bold green]🏁 Script finished.[/]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
