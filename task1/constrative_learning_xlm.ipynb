{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- Initial Data Loading and Cleaning ---\n",
      "Loaded 31187 train and 4625 dev examples.\n",
      "Text cleaning complete.\n",
      "\n",
      "--- Phase 1: Starting SimCSE Pre-training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: caron-olivier-80 (caron-olivier-80-universit-paris-dauphine-psl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250404_001135-sbe5imm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/sbe5imm2' target=\"_blank\">simcse_meanpool_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/sbe5imm2' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/sbe5imm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created SimCSE dataset with 35812 examples.\n",
      "Loading tokenizer xlm-roberta-base for SimCSE phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e48da53d3d485da7e498a388c75ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE dataset tokenized.\n",
      "SimCSE base model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_22972\\1962037920.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimCSETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SimCSE training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4477' max='4477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4477/4477 19:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE training finished.\n",
      "SimCSE pre-trained model and tokenizer saved to results_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▁▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>4711181956153344.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>4477</td></tr><tr><td>train/grad_norm</td><td>0.01307</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0001</td></tr><tr><td>train_loss</td><td>0.0395</td></tr><tr><td>train_runtime</td><td>1185.0057</td></tr><tr><td>train_samples_per_second</td><td>30.221</td></tr><tr><td>train_steps_per_second</td><td>3.778</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">simcse_meanpool_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/sbe5imm2' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/sbe5imm2</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250404_001135-sbe5imm2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: SimCSE Pre-training Complete ---\n",
      "\n",
      "--- Phase 2: Starting Classification Fine-tuning ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250404_003142-qpl4ypom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/qpl4ypom' target=\"_blank\">classify_ft_on_simcse_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/qpl4ypom' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/qpl4ypom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets created.\n",
      "Loading tokenizer for classification phase from: results_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bafde74f9d494c9f9274e711694edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a9d7f2a610467193a6036b07e3ac5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets tokenized.\n",
      "Computing class weights for classification...\n",
      "Detected 2 distinct labels in training data: [0 1]\n",
      "Class Weights (for classes [0 1]): [0.5426468 6.3620973]\n",
      "Loading model for classification from: results_simcse_xlmr_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at results_simcse_xlmr_base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_22972\\1962037920.py:314: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedClassificationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Trainer configured.\n",
      "Starting classification fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7792' max='7792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7792/7792 1:13:37, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Pos</th>\n",
       "      <th>Precision Pos</th>\n",
       "      <th>Recall Pos</th>\n",
       "      <th>F1 Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.394511</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.536269</td>\n",
       "      <td>0.553476</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.957773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.336146</td>\n",
       "      <td>0.886054</td>\n",
       "      <td>0.555274</td>\n",
       "      <td>0.418043</td>\n",
       "      <td>0.826633</td>\n",
       "      <td>0.934656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.344501</td>\n",
       "      <td>0.924541</td>\n",
       "      <td>0.636837</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.957896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.636081</td>\n",
       "      <td>0.946595</td>\n",
       "      <td>0.673712</td>\n",
       "      <td>0.710306</td>\n",
       "      <td>0.640704</td>\n",
       "      <td>0.970917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.789361</td>\n",
       "      <td>0.942054</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.968299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.773144</td>\n",
       "      <td>0.941189</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.967719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.846988</td>\n",
       "      <td>0.944649</td>\n",
       "      <td>0.688564</td>\n",
       "      <td>0.667453</td>\n",
       "      <td>0.711055</td>\n",
       "      <td>0.969625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.986162</td>\n",
       "      <td>0.944865</td>\n",
       "      <td>0.675985</td>\n",
       "      <td>0.683805</td>\n",
       "      <td>0.668342</td>\n",
       "      <td>0.969869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification fine-tuning finished.\n",
      "Best classification model and tokenizer saved to results_classifier_finetuned_on_simcse\\best_model\n",
      "\n",
      "--- Detailed Evaluation and Submission File Generation ---\n",
      "\n",
      "Generating predictions for Threshold Adjustment and Detailed Metrics...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best threshold on validation set based on Overall F1-Positive...\n",
      "\n",
      "Best threshold found: 0.11 with Overall F1-Pos: 0.6919\n",
      "\n",
      "--- Detailed Evaluation on Development Set (Final Predictions) ---\n",
      "--- (Using Threshold = 0.11) ---\n",
      "\n",
      "Metrics for language: DE (Support: {0: 599, 1: 35})\n",
      "  Precision (Pos/1): 0.5385\n",
      "  Recall    (Pos/1): 0.6000\n",
      "  F1        (Pos/1): 0.5676\n",
      "  Accuracy:          0.9495\n",
      "\n",
      "Metrics for language: EN (Support: {0: 841, 1: 61})\n",
      "  Precision (Pos/1): 0.7391\n",
      "  Recall    (Pos/1): 0.8361\n",
      "  F1        (Pos/1): 0.7846\n",
      "  Accuracy:          0.9690\n",
      "\n",
      "Metrics for language: FR (Support: {0: 389, 1: 30})\n",
      "  Precision (Pos/1): 0.5610\n",
      "  Recall    (Pos/1): 0.7667\n",
      "  F1        (Pos/1): 0.6479\n",
      "  Accuracy:          0.9403\n",
      "\n",
      "Metrics for language: RU (Support: {0: 2398, 1: 272})\n",
      "  Precision (Pos/1): 0.6600\n",
      "  Recall    (Pos/1): 0.7279\n",
      "  F1        (Pos/1): 0.6923\n",
      "  Accuracy:          0.9341\n",
      "\n",
      "--- Overall Evaluation Summary (Final Predictions) ---\n",
      "Overall F1-score (Positive Class): 0.6919  <-- Primary Metric\n",
      "Macro F1-score (Pos Class / Lang): 0.6731\n",
      "Overall Precision (Positive Class):0.6526\n",
      "Overall Recall (Positive Class):   0.7362\n",
      "Overall Accuracy:                  0.9436\n",
      "\n",
      "Overall Confusion Matrix (Final):\n",
      "Predicted Labels: [0 1]\n",
      "True Labels\n",
      "[[4071  156]\n",
      " [ 105  293]]\n",
      "\n",
      "Saving predictions for submission...\n",
      "Predictions saved to results_classifier_finetuned_on_simcse\\predictions_task1_simcse_finetuned_thresh0.11.csv\n",
      "predictions_task1_simcse_finetuned_thresh0.11.csv has been zipped into results_classifier_finetuned_on_simcse\\submission_task1_simcse_finetuned_thresh0.11.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅▁▅█▇▇██</td></tr><tr><td>eval/best_threshold</td><td>▁</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>▁</td></tr><tr><td>eval/de/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/f1_neg</td><td>▅▁▅█▇▇██</td></tr><tr><td>eval/f1_pos</td><td>▁▂▆▇▇▇█▇</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/loss</td><td>▂▁▁▄▆▆▇█</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>▁</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/precision_pos</td><td>▄▁▄█▇▇▇▇</td></tr><tr><td>eval/recall_pos</td><td>▁█▇▄▄▅▅▄</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁█▂▂▇▇▆▂</td></tr><tr><td>eval/samples_per_second</td><td>█▁▇▇▂▂▃▇</td></tr><tr><td>eval/steps_per_second</td><td>█▁▇▇▂▂▃▇</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1_neg</td><td>▁</td></tr><tr><td>test/f1_pos</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision_pos</td><td>▁</td></tr><tr><td>test/recall_pos</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▂▂▃▂▂▂▃▁▂▆▅▁█▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▄▅███▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>███▇▇▇▇▅▅▅▄▄▅▄▄▄▃▃▃▄▂▂▃▂▃▃▃▂▂▃▂▂▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.94486</td></tr><tr><td>eval/best_threshold</td><td>0.11</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>0.69185</td></tr><tr><td>eval/de/thresh/accuracy</td><td>0.94953</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>0.56757</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>0.53846</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>0.6</td></tr><tr><td>eval/en/thresh/accuracy</td><td>0.96896</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>0.78462</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>0.73913</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>0.83607</td></tr><tr><td>eval/f1_neg</td><td>0.96987</td></tr><tr><td>eval/f1_pos</td><td>0.67598</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>0.94033</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>0.64789</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>0.56098</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>0.76667</td></tr><tr><td>eval/loss</td><td>0.98616</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>0.94357</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>0.69185</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>0.67309</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>0.65256</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>0.73618</td></tr><tr><td>eval/precision_pos</td><td>0.6838</td></tr><tr><td>eval/recall_pos</td><td>0.66834</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>0.93408</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>0.69231</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>0.66</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>0.72794</td></tr><tr><td>eval/runtime</td><td>14.6214</td></tr><tr><td>eval/samples_per_second</td><td>316.317</td></tr><tr><td>eval/steps_per_second</td><td>39.6</td></tr><tr><td>test/accuracy</td><td>0.94465</td></tr><tr><td>test/f1_neg</td><td>0.96963</td></tr><tr><td>test/f1_pos</td><td>0.68856</td></tr><tr><td>test/loss</td><td>0.84699</td></tr><tr><td>test/precision_pos</td><td>0.66745</td></tr><tr><td>test/recall_pos</td><td>0.71106</td></tr><tr><td>test/runtime</td><td>14.8091</td></tr><tr><td>test/samples_per_second</td><td>312.307</td></tr><tr><td>test/steps_per_second</td><td>39.097</td></tr><tr><td>total_flos</td><td>3.281363215816704e+16</td></tr><tr><td>train/epoch</td><td>7.99936</td></tr><tr><td>train/global_step</td><td>7792</td></tr><tr><td>train/grad_norm</td><td>0.00787</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0308</td></tr><tr><td>train_loss</td><td>0.1494</td></tr><tr><td>train_runtime</td><td>4418.3916</td></tr><tr><td>train_samples_per_second</td><td>56.468</td></tr><tr><td>train_steps_per_second</td><td>1.764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classify_ft_on_simcse_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/qpl4ypom' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune/runs/qpl4ypom</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-simcse-finetune</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250404_003142-qpl4ypom\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "import math\n",
    "import gc\n",
    "\n",
    "# --- Configuration Générale ---\n",
    "BASE_MODEL_NAME = \"xlm-roberta-base\"\n",
    "TRAIN_CSV = \"data/train_data_SMM4H_2025_Task_1.csv\"\n",
    "DEV_CSV = \"data/dev_data_SMM4H_2025_Task_1.csv\"\n",
    "# ATTENTION: max_length=256 peut être gourmand en VRAM (8Go limite). Réduire à 192 ou 128 si OOM.\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# --- Configuration Phase 1: SimCSE Pré-entraînement ---\n",
    "DO_SIMCSE_PRETRAINING = True\n",
    "SIMCSE_OUTPUT_DIR = \"results_simcse_xlmr_base\"\n",
    "SIMCSE_NUM_EPOCHS = 1\n",
    "# ATTENTION: batch_size=16 double en mémoire (2 passes SimCSE). Réduire à 12 ou 8 si OOM sur 8Go VRAM.\n",
    "SIMCSE_BATCH_SIZE = 8\n",
    "SIMCSE_LEARNING_RATE = 3e-5\n",
    "SIMCSE_TEMP = 0.05\n",
    "SIMCSE_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Option pour le pooling SimCSE\n",
    "SIMCSE_USE_MEAN_POOLING = True # Mettre à False pour utiliser le CLS token pooling\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "SIMCSE_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Configuration Phase 2: Classification Fine-tuning ---\n",
    "CLASSIFICATION_OUTPUT_DIR = \"results_classifier_finetuned_on_simcse\"\n",
    "CLASSIFICATION_NUM_EPOCHS = 8\n",
    "# ATTENTION: batch_size=8 * grad_accum=4 => effectif 32. Peut être lourd. Réduire si OOM.\n",
    "CLASSIFICATION_BATCH_SIZE = 4\n",
    "CLASSIFICATION_GRAD_ACCUM_STEPS = 8\n",
    "CLASSIFICATION_LEARNING_RATE = 2e-5\n",
    "CLASSIFICATION_EARLY_STOPPING_PATIENCE = 3\n",
    "CLASSIFICATION_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "CLASSIFICATION_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Initialisation WandB Globale ---\n",
    "WANDB_PROJECT_NAME = \"ade-classification-simcse-finetune\"\n",
    "\n",
    "# --- Fonction de Nettoyage de Texte (inchangée) ---\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'@[\\w_]+', '[USER_MENTION]', text)\n",
    "    text = text.replace('<user>', '[USER_MENTION]')\n",
    "    text = text.replace('<tuser>', '[USER_MENTION]')\n",
    "    text = text.replace('<url>', '[URL]')\n",
    "    text = text.replace('<email>', '[EMAIL]')\n",
    "    text = text.replace('HTTPURL________________', '[URL]')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# --- Fonction Mean Pooling (pour SimCSE optionnel) ---\n",
    "def mean_pooling(hidden_state, attention_mask):\n",
    "    \"\"\"Applique le mean pooling en ignorant les tokens de padding.\"\"\"\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
    "    sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9) # Évite division par zéro\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# --- 1. Chargement et Préparation Initiale des Données ---\n",
    "print(\"--- Initial Data Loading and Cleaning ---\")\n",
    "try:\n",
    "    train_df_full = pd.read_csv(TRAIN_CSV).dropna(subset=['text'])\n",
    "    dev_df_full = pd.read_csv(DEV_CSV).dropna(subset=['text'])\n",
    "    print(f\"Loaded {len(train_df_full)} train and {len(dev_df_full)} dev examples.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit()\n",
    "\n",
    "train_df_full['text'] = train_df_full['text'].apply(clean_text)\n",
    "dev_df_full['text'] = dev_df_full['text'].apply(clean_text)\n",
    "print(\"Text cleaning complete.\")\n",
    "\n",
    "# --- PHASE 1: SIMCSE PRE-TRAINING ---\n",
    "\n",
    "# Définition du Trainer Personnalisé pour SimCSE (modifié)\n",
    "class SimCSETrainer(Trainer):\n",
    "    def __init__(self, *args, temperature=0.05, use_mean_pooling=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.use_mean_pooling = use_mean_pooling # Stocker l'option de pooling\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        attention_mask = inputs.get(\"attention_mask\")\n",
    "\n",
    "        # Deux passes avec dropout (implicite dans le modèle en mode train)\n",
    "        outputs1 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        outputs2 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\n",
    "        # --- MODIFIÉ: Choix entre Mean Pooling et CLS Pooling ---\n",
    "        if self.use_mean_pooling:\n",
    "            pooler_output1 = mean_pooling(outputs1.last_hidden_state, attention_mask)\n",
    "            pooler_output2 = mean_pooling(outputs2.last_hidden_state, attention_mask)\n",
    "        else: # Utiliser CLS token\n",
    "            pooler_output1 = outputs1.last_hidden_state[:, 0]\n",
    "            pooler_output2 = outputs2.last_hidden_state[:, 0]\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        # Concaténer et normaliser les embeddings\n",
    "        embeddings = torch.cat([pooler_output1, pooler_output2], dim=0)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1) # L2 Normalization\n",
    "\n",
    "        # Calculer la similarité cosinus\n",
    "        cos_sim = torch.mm(embeddings, embeddings.t()) # Shape: (2*batch_size, 2*batch_size)\n",
    "\n",
    "        # Masquer la diagonale (chaque embedding avec lui-même)\n",
    "        batch_size = pooler_output1.size(0)\n",
    "        mask_diag = torch.eye(2 * batch_size, device=embeddings.device, dtype=torch.bool)\n",
    "        cos_sim = cos_sim.masked_fill(mask_diag, -9e15) # Remplacer par un très petit nombre\n",
    "\n",
    "        # Appliquer la température\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # Créer les labels pour InfoNCE loss\n",
    "        labels = torch.arange(batch_size, device=embeddings.device)\n",
    "        labels_z1 = labels + batch_size # Indices des z2 correspondants\n",
    "        labels_z2 = labels             # Indices des z1 correspondants\n",
    "\n",
    "        # Extraire les logits pour chaque partie\n",
    "        logits_z1 = cos_sim[:batch_size, :] # Logits pour les embeddings de la 1ère passe\n",
    "        logits_z2 = cos_sim[batch_size:, :] # Logits pour les embeddings de la 2ème passe\n",
    "\n",
    "        # Calculer la perte CrossEntropy\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss_z1 = loss_fct(logits_z1, labels_z1)\n",
    "        loss_z2 = loss_fct(logits_z2, labels_z2)\n",
    "\n",
    "        # Perte finale = moyenne des deux\n",
    "        loss = (loss_z1 + loss_z2) / 2\n",
    "\n",
    "        return (loss, {\"embeddings1\": pooler_output1, \"embeddings2\": pooler_output2}) if return_outputs else loss\n",
    "\n",
    "model_load_path = BASE_MODEL_NAME # Default path if SimCSE is skipped\n",
    "\n",
    "if DO_SIMCSE_PRETRAINING:\n",
    "    print(\"\\n--- Phase 1: Starting SimCSE Pre-training ---\")\n",
    "    run_name_simcse = f\"simcse_{'meanpool_' if SIMCSE_USE_MEAN_POOLING else 'cls_'}{BASE_MODEL_NAME}\"\n",
    "    try:\n",
    "        wandb.init(project=WANDB_PROJECT_NAME, name=run_name_simcse, reinit=True)\n",
    "        wandb.config.update({ # Log config SimCSE\n",
    "            \"simcse_model\": BASE_MODEL_NAME,\n",
    "            \"simcse_epochs\": SIMCSE_NUM_EPOCHS,\n",
    "            \"simcse_batch_size\": SIMCSE_BATCH_SIZE,\n",
    "            \"simcse_lr\": SIMCSE_LEARNING_RATE,\n",
    "            \"simcse_temp\": SIMCSE_TEMP,\n",
    "            \"simcse_pooling\": \"mean\" if SIMCSE_USE_MEAN_POOLING else \"cls\",\n",
    "            \"simcse_warmup_ratio\": SIMCSE_WARMUP_RATIO,\n",
    "            \"max_length\": MAX_LENGTH\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"WandB initialization failed for SimCSE phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "    # Préparer le dataset SimCSE (train + dev)\n",
    "    all_texts_df = pd.concat([train_df_full[['text']], dev_df_full[['text']]], ignore_index=True)\n",
    "    simcse_dataset = Dataset.from_pandas(all_texts_df)\n",
    "    print(f\"Created SimCSE dataset with {len(simcse_dataset)} examples.\")\n",
    "\n",
    "    # Tokenizer (Charger ici pour la phase 1)\n",
    "    print(f\"Loading tokenizer {BASE_MODEL_NAME} for SimCSE phase...\")\n",
    "    tokenizer_simcse = AutoTokenizer.from_pretrained(BASE_MODEL_NAME) # Utiliser une variable spécifique\n",
    "\n",
    "    def tokenize_simcse(examples):\n",
    "        # Utiliser tokenizer_simcse défini dans cette portée\n",
    "        return tokenizer_simcse(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    tokenized_simcse_dataset = simcse_dataset.map(tokenize_simcse, batched=True, remove_columns=[\"text\"], num_proc=1) # Utiliser plus de procs si possible\n",
    "    tokenized_simcse_dataset.set_format(\"torch\")\n",
    "    print(\"SimCSE dataset tokenized.\")\n",
    "\n",
    "    # Charger le modèle AutoModel (sans tête)\n",
    "    simcse_model = AutoModel.from_pretrained(BASE_MODEL_NAME)\n",
    "    print(\"SimCSE base model loaded.\")\n",
    "\n",
    "    # Arguments d'entraînement SimCSE (avec warmup)\n",
    "    simcse_training_args = TrainingArguments(\n",
    "        output_dir=SIMCSE_OUTPUT_DIR,\n",
    "        num_train_epochs=SIMCSE_NUM_EPOCHS,\n",
    "        per_device_train_batch_size=SIMCSE_BATCH_SIZE,\n",
    "        learning_rate=SIMCSE_LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{SIMCSE_OUTPUT_DIR}/logs',\n",
    "        logging_steps=SIMCSE_LOGGING_STEPS,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "        fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "        warmup_ratio=SIMCSE_WARMUP_RATIO, # NOUVEAU: Ajout du warmup\n",
    "    )\n",
    "\n",
    "    # Instancier le SimCSE Trainer (avec l'option pooling)\n",
    "    simcse_trainer = SimCSETrainer(\n",
    "        model=simcse_model,\n",
    "        args=simcse_training_args,\n",
    "        train_dataset=tokenized_simcse_dataset,\n",
    "        tokenizer=tokenizer_simcse, # Passer le tokenizer spécifique\n",
    "        temperature=SIMCSE_TEMP,\n",
    "        use_mean_pooling=SIMCSE_USE_MEAN_POOLING # NOUVEAU: Passer l'option\n",
    "    )\n",
    "\n",
    "    # Lancer l'entraînement\n",
    "    print(\"Starting SimCSE training...\")\n",
    "    simcse_trainer.train()\n",
    "    print(\"SimCSE training finished.\")\n",
    "\n",
    "    # Sauvegarder\n",
    "    simcse_trainer.save_model(SIMCSE_OUTPUT_DIR)\n",
    "    tokenizer_simcse.save_pretrained(SIMCSE_OUTPUT_DIR) # Sauver le tokenizer utilisé\n",
    "    print(f\"SimCSE pre-trained model and tokenizer saved to {SIMCSE_OUTPUT_DIR}\")\n",
    "\n",
    "    # Nettoyer\n",
    "    model_load_path = SIMCSE_OUTPUT_DIR # Mettre à jour le chemin pour la phase 2\n",
    "    del simcse_model, simcse_trainer, tokenized_simcse_dataset, simcse_dataset, all_texts_df, tokenizer_simcse\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    print(\"--- Phase 1: SimCSE Pre-training Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Phase 1: Skipping SimCSE Pre-training ---\")\n",
    "    # model_load_path reste BASE_MODEL_NAME (défini plus haut)\n",
    "\n",
    "\n",
    "# --- PHASE 2: CLASSIFICATION FINE-TUNING ---\n",
    "print(\"\\n--- Phase 2: Starting Classification Fine-tuning ---\")\n",
    "run_name_classify = f\"classify_ft_on_{'simcse' if DO_SIMCSE_PRETRAINING else 'base'}_{BASE_MODEL_NAME}\"\n",
    "try:\n",
    "    wandb.init(project=WANDB_PROJECT_NAME, name=run_name_classify, reinit=True)\n",
    "    wandb.config.update({ # Log config Classification\n",
    "        \"base_model_for_ft\": model_load_path,\n",
    "        \"classify_epochs\": CLASSIFICATION_NUM_EPOCHS,\n",
    "        \"classify_batch_size\": CLASSIFICATION_BATCH_SIZE,\n",
    "        \"classify_grad_accum\": CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_effective_batch\": CLASSIFICATION_BATCH_SIZE * CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_lr\": CLASSIFICATION_LEARNING_RATE,\n",
    "        \"classify_warmup_ratio\": CLASSIFICATION_WARMUP_RATIO,\n",
    "        \"classify_early_stopping\": CLASSIFICATION_EARLY_STOPPING_PATIENCE,\n",
    "        \"max_length\": MAX_LENGTH\n",
    "    })\n",
    "except Exception as e:\n",
    "        print(f\"WandB initialization failed for Classification phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "# Préparer les datasets classification\n",
    "train_dataset_cls = Dataset.from_pandas(train_df_full)\n",
    "dev_dataset_cls = Dataset.from_pandas(dev_df_full)\n",
    "dataset_dict_cls = DatasetDict({'train': train_dataset_cls, 'validation': dev_dataset_cls})\n",
    "print(\"Classification datasets created.\")\n",
    "\n",
    "# --- CORRECTIF: Charger systématiquement le tokenizer pour la Phase 2 ---\n",
    "# Charger le tokenizer correspondant au modèle que nous allons fine-tuner\n",
    "# (soit celui de SimCSE si Phase 1 a tourné, soit celui du modèle de base)\n",
    "print(f\"Loading tokenizer for classification phase from: {model_load_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_load_path)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def tokenize_classification(examples):\n",
    "    # Utilise le 'tokenizer' défini juste au-dessus\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "tokenized_datasets_cls = dataset_dict_cls.map(tokenize_classification, batched=True, remove_columns=[\"text\", \"id\", \"file_name\", \"origin\", \"language\", \"split\", \"type\"], num_proc=1)\n",
    "tokenized_datasets_cls.set_format(\"torch\")\n",
    "tokenized_datasets_cls = tokenized_datasets_cls.rename_column(\"label\", \"labels\")\n",
    "print(\"Classification datasets tokenized.\")\n",
    "\n",
    "# Calculer poids de classe\n",
    "print(\"Computing class weights for classification...\")\n",
    "labels_train_cls = train_df_full['label'].values\n",
    "class_weights_tensor_cls = None\n",
    "unique_labels_cls = np.unique(labels_train_cls)\n",
    "num_distinct_labels = len(unique_labels_cls)\n",
    "print(f\"Detected {num_distinct_labels} distinct labels in training data: {unique_labels_cls}\")\n",
    "\n",
    "if num_distinct_labels > 1:\n",
    "    class_weights_cls = compute_class_weight(class_weight='balanced', classes=unique_labels_cls, y=labels_train_cls)\n",
    "    # Ensure weights are ordered according to label index (0, 1, ...)\n",
    "    ordered_weights_dict = {label: weight for label, weight in zip(unique_labels_cls, class_weights_cls)}\n",
    "    # Utiliser num_distinct_labels pour déterminer la taille du tenseur\n",
    "    ordered_weights_cls = np.array([ordered_weights_dict.get(i, 0) for i in unique_labels_cls]) # Assigner poids aux labels existants\n",
    "\n",
    "    class_weights_tensor_cls = torch.tensor(ordered_weights_cls, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Class Weights (for classes {unique_labels_cls}): {class_weights_tensor_cls.cpu().numpy()}\")\n",
    "    if wandb.run: wandb.config.update({\"class_weights\": class_weights_tensor_cls.cpu().numpy().tolist()})\n",
    "else:\n",
    "    print(\"Warning: Only one class found in training data. Cannot compute class weights.\")\n",
    "\n",
    "\n",
    "# Trainer Personnalisé Classification avec Poids\n",
    "class WeightedClassificationTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "         super().__init__(*args, **kwargs)\n",
    "         # Déplacer les poids sur le bon device une seule fois si possible\n",
    "         self.class_weights = class_weights.to(self.args.device) if class_weights is not None else None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Utiliser les poids stockés et déjà sur le bon device\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss() # No weights\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Charger le modèle pour Classification\n",
    "print(f\"Loading model for classification from: {model_load_path}\")\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_load_path,\n",
    "    num_labels=num_distinct_labels, # Utiliser le nombre détecté\n",
    "    ignore_mismatched_sizes=True # Crucial si chargement depuis AutoModel (SimCSE)\n",
    ")\n",
    "print(\"Classification model loaded.\")\n",
    "\n",
    "# Fonction compute_metrics\n",
    "def compute_metrics_cls(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    metric_labels = unique_labels_cls # Utiliser les labels détectés\n",
    "    if num_distinct_labels == 2:\n",
    "        # Calcul spécifique pour binaire (Pos = 1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0, 1], zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_pos': f1[1] if len(f1) > 1 else 0,\n",
    "            'precision_pos': precision[1] if len(precision) > 1 else 0,\n",
    "            'recall_pos': recall[1] if len(recall) > 1 else 0,\n",
    "            'f1_neg': f1[0] if len(f1) > 0 else 0,\n",
    "        }\n",
    "    else:\n",
    "        # Calcul macro/weighted pour multiclasse\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', labels=metric_labels, zero_division=0)\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(labels, preds, average='weighted', labels=metric_labels, zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "        }\n",
    "        # Optionnel: ajouter f1 par classe si besoin\n",
    "        # _, _, f1_per_class, _ = precision_recall_fscore_support(labels, preds, average=None, labels=metric_labels, zero_division=0)\n",
    "        # for i, label in enumerate(metric_labels):\n",
    "        #     metrics[f'f1_class_{label}'] = f1_per_class[i]\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Arguments d'entraînement Classification (avec warmup)\n",
    "classification_training_args = TrainingArguments(\n",
    "    output_dir=CLASSIFICATION_OUTPUT_DIR,\n",
    "    num_train_epochs=CLASSIFICATION_NUM_EPOCHS,\n",
    "    per_device_train_batch_size=CLASSIFICATION_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=CLASSIFICATION_BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "    learning_rate=CLASSIFICATION_LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Choisir la métrique pertinente pour load_best_model_at_end\n",
    "    metric_for_best_model=\"f1_pos\" if num_distinct_labels == 2 else \"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=f'{CLASSIFICATION_OUTPUT_DIR}/logs',\n",
    "    logging_steps=CLASSIFICATION_LOGGING_STEPS,\n",
    "    report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "    fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "    warmup_ratio=CLASSIFICATION_WARMUP_RATIO,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Instancier le Trainer Classification (passer les poids ici)\n",
    "classification_trainer = WeightedClassificationTrainer(\n",
    "    model=classification_model,\n",
    "    args=classification_training_args,\n",
    "    train_dataset=tokenized_datasets_cls[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_cls[\"validation\"],\n",
    "    tokenizer=tokenizer, # Utiliser le tokenizer chargé pour la phase 2\n",
    "    compute_metrics=compute_metrics_cls,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=CLASSIFICATION_EARLY_STOPPING_PATIENCE)],\n",
    "    class_weights=class_weights_tensor_cls # Passer le tenseur de poids\n",
    ")\n",
    "print(\"Classification Trainer configured.\")\n",
    "\n",
    "# Lancer le fine-tuning\n",
    "print(\"Starting classification fine-tuning...\")\n",
    "classification_trainer.train()\n",
    "print(\"Classification fine-tuning finished.\")\n",
    "\n",
    "# Sauvegarder le meilleur modèle explicitement\n",
    "best_model_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, \"best_model\")\n",
    "classification_trainer.save_model(best_model_path)\n",
    "tokenizer.save_pretrained(best_model_path) # Sauver le tokenizer avec le meilleur modèle\n",
    "print(f\"Best classification model and tokenizer saved to {best_model_path}\")\n",
    "\n",
    "# --- Évaluation Détaillée et Soumission (Utilise le meilleur modèle chargé) ---\n",
    "print(\"\\n--- Detailed Evaluation and Submission File Generation ---\")\n",
    "print(\"\\nGenerating predictions for Threshold Adjustment and Detailed Metrics...\")\n",
    "\n",
    "predictions_output = classification_trainer.predict(tokenized_datasets_cls[\"validation\"])\n",
    "logits = predictions_output.predictions\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "if logits.shape[-1] != num_distinct_labels:\n",
    "    print(f\"Error: Logits shape {logits.shape} unexpected for {num_distinct_labels} labels.\")\n",
    "    exit()\n",
    "\n",
    "probabilities = None\n",
    "predicted_labels_final = None\n",
    "best_threshold = None\n",
    "\n",
    "if num_distinct_labels == 2:\n",
    "    probabilities = softmax(logits, axis=-1)[:, 1] # Proba classe positive (index 1)\n",
    "    print(\"\\nFinding best threshold on validation set based on Overall F1-Positive...\")\n",
    "    best_f1 = -1\n",
    "    best_threshold = 0.5 # Default\n",
    "    thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "    f1_scores_thresh = []\n",
    "    for threshold in thresholds:\n",
    "        predicted_labels_thresh = (probabilities >= threshold).astype(int)\n",
    "        precision_thresh, recall_thresh, f1_thresh, _ = precision_recall_fscore_support(\n",
    "            true_labels, predicted_labels_thresh, average='binary', pos_label=1, zero_division=0)\n",
    "        f1_scores_thresh.append(f1_thresh)\n",
    "        if f1_thresh > best_f1:\n",
    "            best_f1 = f1_thresh\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"\\nBest threshold found: {best_threshold:.2f} with Overall F1-Pos: {best_f1:.4f}\")\n",
    "    if wandb.run: wandb.log({\"eval/best_threshold\": best_threshold, \"eval/best_val_f1_at_threshold\": best_f1})\n",
    "    predicted_labels_final = (probabilities >= best_threshold).astype(int)\n",
    "else:\n",
    "    print(\"Multi-class classification detected (>2). Using argmax for final predictions.\")\n",
    "    predicted_labels_final = logits.argmax(-1)\n",
    "    # best_threshold reste None\n",
    "\n",
    "# Préparer le DataFrame pour l'évaluation détaillée\n",
    "dev_df_eval = dev_df_full.reset_index(drop=True)\n",
    "if len(dev_df_eval) == len(predicted_labels_final):\n",
    "    dev_df_eval['predicted_label'] = predicted_labels_final\n",
    "    if probabilities is not None:\n",
    "         dev_df_eval['probability_positive'] = probabilities\n",
    "else:\n",
    "    print(f\"Error: Length mismatch between dev_df {len(dev_df_eval)} and predictions {len(predicted_labels_final)}!\")\n",
    "    exit()\n",
    "\n",
    "dev_df_eval[\"language\"] = dev_df_full[\"id\"].apply(lambda x: str(x).split(\"_\")[0] if isinstance(x, str) and \"_\" in x else \"unknown\")\n",
    "\n",
    "languages = sorted(dev_df_eval['language'].unique())\n",
    "language_f1_scores_pos = [] # Pour Macro F1 binaire\n",
    "wandb_logs_eval = {}\n",
    "print(f\"\\n--- Detailed Evaluation on Development Set (Final Predictions) ---\")\n",
    "if best_threshold is not None:\n",
    "     print(f\"--- (Using Threshold = {best_threshold:.2f}) ---\")\n",
    "\n",
    "for lang in languages:\n",
    "    if lang == \"unknown\": continue\n",
    "    lang_mask = dev_df_eval['language'] == lang\n",
    "    y_true_lang = dev_df_eval.loc[lang_mask, 'label'].tolist()\n",
    "    y_pred_lang_final = dev_df_eval.loc[lang_mask, 'predicted_label'].tolist()\n",
    "    if len(y_true_lang) == 0: continue\n",
    "\n",
    "    # Utiliser les labels détectés pour le calcul des métriques\n",
    "    metric_labels = unique_labels_cls\n",
    "    precision_lang, recall_lang, f1_lang, support_lang = precision_recall_fscore_support(\n",
    "        y_true_lang, y_pred_lang_final, average=None, labels=metric_labels, zero_division=0)\n",
    "    accuracy_lang = accuracy_score(y_true_lang, y_pred_lang_final)\n",
    "\n",
    "    print(f\"\\nMetrics for language: {lang.upper()} (Support: {dict(zip(metric_labels, support_lang))})\")\n",
    "    # Clé WandB dynamique basée sur seuil/argmax\n",
    "    wandb_key_prefix = f\"eval/{lang}\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "    if num_distinct_labels == 2:\n",
    "        f1_pos_lang = f1_lang[1] # Index 1 correspond au label 1 (Positif)\n",
    "        language_f1_scores_pos.append(f1_pos_lang)\n",
    "        print(f\"  Precision (Pos/1): {precision_lang[1]:.4f}\")\n",
    "        print(f\"  Recall    (Pos/1): {recall_lang[1]:.4f}\")\n",
    "        print(f\"  F1        (Pos/1): {f1_pos_lang:.4f}\")\n",
    "        print(f\"  Accuracy:          {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/precision_pos\"] = precision_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/recall_pos\"] = recall_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_pos\"] = f1_pos_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "    else:\n",
    "        f1_macro_lang = np.mean(f1_lang) # F1 macro simple\n",
    "        print(f\"  F1-Macro:         {f1_macro_lang:.4f}\")\n",
    "        print(f\"  Accuracy:         {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_macro\"] = f1_macro_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "        # Logguer F1 par classe si besoin\n",
    "        for i, label in enumerate(metric_labels):\n",
    "             wandb_logs_eval[f\"{wandb_key_prefix}/f1_class_{label}\"] = f1_lang[i]\n",
    "\n",
    "\n",
    "# Calcul des métriques globales finales\n",
    "cm_overall_final = confusion_matrix(true_labels, predicted_labels_final, labels=unique_labels_cls)\n",
    "overall_accuracy_final = accuracy_score(true_labels, predicted_labels_final)\n",
    "wandb_key_prefix_overall = \"eval/overall\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "print(f\"\\n--- Overall Evaluation Summary (Final Predictions) ---\")\n",
    "if num_distinct_labels == 2:\n",
    "    # Assurer que cm a bien 4 éléments (cas binaire)\n",
    "    if cm_overall_final.size == 4:\n",
    "      tn, fp, fn, tp = cm_overall_final.ravel()\n",
    "    else: # Gérer cas où une classe n'est pas prédite/présente dans l'éval\n",
    "      tn, fp, fn, tp = 0, 0, 0, 0\n",
    "      print(\"Warning: Confusion matrix size indicates potential missing classes in evaluation.\")\n",
    "      # Logique pour reconstruire TN/FP/FN/TP si nécessaire basée sur les labels uniques\n",
    "      if 0 in unique_labels_cls and 1 in unique_labels_cls:\n",
    "          tn = cm_overall_final[0, 0]\n",
    "          fp = cm_overall_final[0, 1]\n",
    "          fn = cm_overall_final[1, 0]\n",
    "          tp = cm_overall_final[1, 1]\n",
    "\n",
    "    overall_precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    overall_recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    overall_f1_pos = 2 * (overall_precision_pos * overall_recall_pos) / (overall_precision_pos + overall_recall_pos) if (overall_precision_pos + overall_recall_pos) > 0 else 0\n",
    "    macro_f1_pos = np.mean(language_f1_scores_pos) if language_f1_scores_pos else 0 # Moyenne des F1-pos par langue\n",
    "\n",
    "    print(f\"Overall F1-score (Positive Class): {overall_f1_pos:.4f}  <-- Primary Metric\")\n",
    "    print(f\"Macro F1-score (Pos Class / Lang): {macro_f1_pos:.4f}\")\n",
    "    print(f\"Overall Precision (Positive Class):{overall_precision_pos:.4f}\")\n",
    "    print(f\"Overall Recall (Positive Class):   {overall_recall_pos:.4f}\")\n",
    "    print(f\"Overall Accuracy:                  {overall_accuracy_final:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_pos\"] = overall_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/macro_f1_pos_lang\"] = macro_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/precision_pos\"] = overall_precision_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/recall_pos\"] = overall_recall_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "else: # Métriques globales pour multiclasse\n",
    "    overall_prec_macro, overall_recall_macro, overall_f1_macro, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='macro', labels=unique_labels_cls, zero_division=0)\n",
    "    overall_prec_weighted, overall_recall_weighted, overall_f1_weighted, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='weighted', labels=unique_labels_cls, zero_division=0)\n",
    "    print(f\"Overall Accuracy:     {overall_accuracy_final:.4f}\")\n",
    "    print(f\"Overall F1 (Macro):   {overall_f1_macro:.4f}\")\n",
    "    print(f\"Overall F1 (Weighted):{overall_f1_weighted:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_macro\"] = overall_f1_macro\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_weighted\"] = overall_f1_weighted\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "# Log all detailed eval metrics\n",
    "if wandb.run: wandb.log(wandb_logs_eval)\n",
    "\n",
    "# --- Sauvegarde du fichier de soumission ---\n",
    "print(\"\\nSaving predictions for submission...\")\n",
    "os.makedirs(CLASSIFICATION_OUTPUT_DIR, exist_ok=True)\n",
    "submission_df = dev_df_eval[['id', 'predicted_label']]\n",
    "suffix = \"simcse_finetuned\" if DO_SIMCSE_PRETRAINING else \"base_finetuned\"\n",
    "thresh_suffix = f\"_thresh{best_threshold:.2f}\" if best_threshold is not None else \"_argmax\"\n",
    "csv_filename = f\"predictions_task1_{suffix}{thresh_suffix}.csv\"\n",
    "zip_filename = f\"submission_task1_{suffix}{thresh_suffix}.zip\"\n",
    "csv_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, csv_filename)\n",
    "zip_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, zip_filename)\n",
    "\n",
    "submission_df.to_csv(csv_path, index=False)\n",
    "print(f\"Predictions saved to {csv_path}\")\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(csv_path, arcname=csv_filename)\n",
    "    print(f\"{csv_filename} has been zipped into {zip_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error zipping the file: {e}\")\n",
    "\n",
    "\n",
    "if wandb.run is not None and wandb.run.step > 0: # Check if wandb was used and logged something\n",
    "    wandb.finish()\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUGMENTED DATA but same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- Initial Data Loading and Cleaning ---\n",
      "Loaded 33482 train and 4625 dev examples.\n",
      "Text cleaning complete.\n",
      "\n",
      "--- Phase 1: Starting SimCSE Pre-training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: caron-olivier-80 (caron-olivier-80-universit-paris-dauphine-psl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250404_154315-ctddo9zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/ctddo9zz' target=\"_blank\">simcse_meanpool_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/ctddo9zz' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/ctddo9zz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created SimCSE dataset with 38107 examples.\n",
      "Loading tokenizer xlm-roberta-base for SimCSE phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed43fa0763854cdeb86da3b0dcf7576b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE dataset tokenized.\n",
      "SimCSE base model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_6344\\1382072799.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimCSETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SimCSE training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4764' max='4764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4764/4764 22:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE training finished.\n",
      "SimCSE pre-trained model and tokenizer saved to results_augmented_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▅▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▃▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>5013096470544384.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>4764</td></tr><tr><td>train/grad_norm</td><td>0.00779</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0</td></tr><tr><td>train_loss</td><td>0.03722</td></tr><tr><td>train_runtime</td><td>1375.759</td></tr><tr><td>train_samples_per_second</td><td>27.699</td></tr><tr><td>train_steps_per_second</td><td>3.463</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">simcse_meanpool_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/ctddo9zz' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/ctddo9zz</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250404_154315-ctddo9zz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: SimCSE Pre-training Complete ---\n",
      "\n",
      "--- Phase 2: Starting Classification Fine-tuning ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250404_160623-z11aa0tr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/z11aa0tr' target=\"_blank\">classify_ft_on_simcse_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/z11aa0tr' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/z11aa0tr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets created.\n",
      "Loading tokenizer for classification phase from: results_augmented_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2916eb0a1b841448e00e27f59005e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fe05b5c3984aeda36419cdc443d9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets tokenized.\n",
      "Computing class weights for classification...\n",
      "Detected 2 distinct labels in training data: [0 1]\n",
      "Class Weights (for classes [0 1]): [0.5825793 3.5273914]\n",
      "Loading model for classification from: results_augmented_simcse_xlmr_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at results_augmented_simcse_xlmr_base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_6344\\1382072799.py:314: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedClassificationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Trainer configured.\n",
      "Starting classification fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8368' max='8368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8368/8368 1:15:50, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Pos</th>\n",
       "      <th>Precision Pos</th>\n",
       "      <th>Recall Pos</th>\n",
       "      <th>F1 Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>0.850811</td>\n",
       "      <td>0.487370</td>\n",
       "      <td>0.345992</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.912702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.435832</td>\n",
       "      <td>0.929946</td>\n",
       "      <td>0.625866</td>\n",
       "      <td>0.579060</td>\n",
       "      <td>0.680905</td>\n",
       "      <td>0.961355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.356035</td>\n",
       "      <td>0.940108</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.639723</td>\n",
       "      <td>0.695980</td>\n",
       "      <td>0.967098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.508999</td>\n",
       "      <td>0.939676</td>\n",
       "      <td>0.654275</td>\n",
       "      <td>0.645477</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.966955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.521542</td>\n",
       "      <td>0.932108</td>\n",
       "      <td>0.647982</td>\n",
       "      <td>0.585020</td>\n",
       "      <td>0.726131</td>\n",
       "      <td>0.962431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.630815</td>\n",
       "      <td>0.946162</td>\n",
       "      <td>0.690683</td>\n",
       "      <td>0.683047</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.970515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.778755</td>\n",
       "      <td>0.942703</td>\n",
       "      <td>0.679565</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>0.706030</td>\n",
       "      <td>0.968539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.827851</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.640091</td>\n",
       "      <td>0.706030</td>\n",
       "      <td>0.967312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification fine-tuning finished.\n",
      "Best classification model and tokenizer saved to results_augmented_data_classifier_finetuned_on_simcse\\best_model\n",
      "\n",
      "--- Detailed Evaluation and Submission File Generation ---\n",
      "\n",
      "Generating predictions for Threshold Adjustment and Detailed Metrics...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best threshold on validation set based on Overall F1-Positive...\n",
      "\n",
      "Best threshold found: 0.52 with Overall F1-Pos: 0.6933\n",
      "\n",
      "--- Detailed Evaluation on Development Set (Final Predictions) ---\n",
      "--- (Using Threshold = 0.52) ---\n",
      "\n",
      "Metrics for language: DE (Support: {0: 599, 1: 35})\n",
      "  Precision (Pos/1): 0.5227\n",
      "  Recall    (Pos/1): 0.6571\n",
      "  F1        (Pos/1): 0.5823\n",
      "  Accuracy:          0.9479\n",
      "\n",
      "Metrics for language: EN (Support: {0: 841, 1: 61})\n",
      "  Precision (Pos/1): 0.8065\n",
      "  Recall    (Pos/1): 0.8197\n",
      "  F1        (Pos/1): 0.8130\n",
      "  Accuracy:          0.9745\n",
      "\n",
      "Metrics for language: FR (Support: {0: 389, 1: 30})\n",
      "  Precision (Pos/1): 0.4898\n",
      "  Recall    (Pos/1): 0.8000\n",
      "  F1        (Pos/1): 0.6076\n",
      "  Accuracy:          0.9260\n",
      "\n",
      "Metrics for language: RU (Support: {0: 2398, 1: 272})\n",
      "  Precision (Pos/1): 0.7269\n",
      "  Recall    (Pos/1): 0.6654\n",
      "  F1        (Pos/1): 0.6948\n",
      "  Accuracy:          0.9404\n",
      "\n",
      "--- Overall Evaluation Summary (Final Predictions) ---\n",
      "Overall F1-score (Positive Class): 0.6933  <-- Primary Metric\n",
      "Macro F1-score (Pos Class / Lang): 0.6744\n",
      "Overall Precision (Positive Class):0.6881\n",
      "Overall Recall (Positive Class):   0.6985\n",
      "Overall Accuracy:                  0.9468\n",
      "\n",
      "Overall Confusion Matrix (Final):\n",
      "Predicted Labels: [0 1]\n",
      "True Labels\n",
      "[[4101  126]\n",
      " [ 120  278]]\n",
      "\n",
      "Saving predictions for submission...\n",
      "Predictions saved to results_augmented_data_classifier_finetuned_on_simcse\\predictions_task1_simcse_finetuned_thresh0.52.csv\n",
      "predictions_task1_simcse_finetuned_thresh0.52.csv has been zipped into results_augmented_data_classifier_finetuned_on_simcse\\submission_task1_simcse_finetuned_thresh0.52.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▇███</td></tr><tr><td>eval/best_threshold</td><td>▁</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>▁</td></tr><tr><td>eval/de/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/f1_neg</td><td>▁▇██▇███</td></tr><tr><td>eval/f1_pos</td><td>▁▆▇▇▇██▇</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁▂▁▃▃▅▇█</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>▁</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/precision_pos</td><td>▁▆▇▇▆█▇▇</td></tr><tr><td>eval/recall_pos</td><td>█▂▂▁▄▃▃▃</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▄▅▁▁▁█▄▅</td></tr><tr><td>eval/samples_per_second</td><td>▅▄▇█▇▁▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▅▄▇█▇▁▅▄</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1_neg</td><td>▁</td></tr><tr><td>test/f1_pos</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision_pos</td><td>▁</td></tr><tr><td>test/recall_pos</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▃▂▃▄▄▆▂▃▄▂▃▁▂▂▃▁▁▃▁█▁▃▁▁▁▁▃▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▆▄▄▄▄▄▃▃▄▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.94054</td></tr><tr><td>eval/best_threshold</td><td>0.52</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>0.69327</td></tr><tr><td>eval/de/thresh/accuracy</td><td>0.94795</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>0.58228</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>0.52273</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>0.65714</td></tr><tr><td>eval/en/thresh/accuracy</td><td>0.9745</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>0.81301</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>0.80645</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>0.81967</td></tr><tr><td>eval/f1_neg</td><td>0.96731</td></tr><tr><td>eval/f1_pos</td><td>0.67145</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>0.92601</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>0.60759</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>0.4898</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>0.8</td></tr><tr><td>eval/loss</td><td>0.82785</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>0.94681</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>0.69327</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>0.67442</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>0.68812</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>0.69849</td></tr><tr><td>eval/precision_pos</td><td>0.64009</td></tr><tr><td>eval/recall_pos</td><td>0.70603</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>0.94045</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>0.69482</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>0.72691</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>0.66544</td></tr><tr><td>eval/runtime</td><td>14.6375</td></tr><tr><td>eval/samples_per_second</td><td>315.969</td></tr><tr><td>eval/steps_per_second</td><td>39.556</td></tr><tr><td>test/accuracy</td><td>0.94616</td></tr><tr><td>test/f1_neg</td><td>0.97052</td></tr><tr><td>test/f1_pos</td><td>0.69068</td></tr><tr><td>test/loss</td><td>0.63081</td></tr><tr><td>test/precision_pos</td><td>0.68305</td></tr><tr><td>test/recall_pos</td><td>0.69849</td></tr><tr><td>test/runtime</td><td>16.1086</td></tr><tr><td>test/samples_per_second</td><td>287.114</td></tr><tr><td>test/steps_per_second</td><td>35.944</td></tr><tr><td>total_flos</td><td>3.523478008958976e+16</td></tr><tr><td>train/epoch</td><td>7.99964</td></tr><tr><td>train/global_step</td><td>8368</td></tr><tr><td>train/grad_norm</td><td>0.00513</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0147</td></tr><tr><td>train_loss</td><td>0.12139</td></tr><tr><td>train_runtime</td><td>4550.9725</td></tr><tr><td>train_samples_per_second</td><td>58.857</td></tr><tr><td>train_steps_per_second</td><td>1.839</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classify_ft_on_simcse_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/z11aa0tr' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune/runs/z11aa0tr</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-augmented-simcse-finetune</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250404_160623-z11aa0tr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "import math\n",
    "import gc\n",
    "\n",
    "# --- Configuration Générale ---\n",
    "BASE_MODEL_NAME = \"xlm-roberta-base\"\n",
    "TRAIN_CSV = \"data/train_data_augmented_no_text_clean.csv\"\n",
    "DEV_CSV = \"data/dev_data_SMM4H_2025_Task_1.csv\"\n",
    "# ATTENTION: max_length=256 peut être gourmand en VRAM (8Go limite). Réduire à 192 ou 128 si OOM.\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# --- Configuration Phase 1: SimCSE Pré-entraînement ---\n",
    "DO_SIMCSE_PRETRAINING = True\n",
    "SIMCSE_OUTPUT_DIR = \"results_augmented_simcse_xlmr_base\"\n",
    "SIMCSE_NUM_EPOCHS = 1\n",
    "# ATTENTION: batch_size=16 double en mémoire (2 passes SimCSE). Réduire à 12 ou 8 si OOM sur 8Go VRAM.\n",
    "SIMCSE_BATCH_SIZE = 8\n",
    "SIMCSE_LEARNING_RATE = 3e-5\n",
    "SIMCSE_TEMP = 0.05\n",
    "SIMCSE_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Option pour le pooling SimCSE\n",
    "SIMCSE_USE_MEAN_POOLING = True # Mettre à False pour utiliser le CLS token pooling\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "SIMCSE_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Configuration Phase 2: Classification Fine-tuning ---\n",
    "CLASSIFICATION_OUTPUT_DIR = \"results_augmented_data_classifier_finetuned_on_simcse\"\n",
    "CLASSIFICATION_NUM_EPOCHS = 8\n",
    "# ATTENTION: batch_size=8 * grad_accum=4 => effectif 32. Peut être lourd. Réduire si OOM.\n",
    "CLASSIFICATION_BATCH_SIZE = 4\n",
    "CLASSIFICATION_GRAD_ACCUM_STEPS = 8\n",
    "CLASSIFICATION_LEARNING_RATE = 2e-5\n",
    "CLASSIFICATION_EARLY_STOPPING_PATIENCE = 3\n",
    "CLASSIFICATION_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "CLASSIFICATION_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Initialisation WandB Globale ---\n",
    "WANDB_PROJECT_NAME = \"ade-classification-augmented-simcse-finetune\"\n",
    "\n",
    "# --- Fonction de Nettoyage de Texte (inchangée) ---\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'@[\\w_]+', '[USER_MENTION]', text)\n",
    "    text = text.replace('<user>', '[USER_MENTION]')\n",
    "    text = text.replace('<tuser>', '[USER_MENTION]')\n",
    "    text = text.replace('<url>', '[URL]')\n",
    "    text = text.replace('<email>', '[EMAIL]')\n",
    "    text = text.replace('HTTPURL________________', '[URL]')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# --- Fonction Mean Pooling (pour SimCSE optionnel) ---\n",
    "def mean_pooling(hidden_state, attention_mask):\n",
    "    \"\"\"Applique le mean pooling en ignorant les tokens de padding.\"\"\"\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
    "    sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9) # Évite division par zéro\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# --- 1. Chargement et Préparation Initiale des Données ---\n",
    "print(\"--- Initial Data Loading and Cleaning ---\")\n",
    "try:\n",
    "    train_df_full = pd.read_csv(TRAIN_CSV).dropna(subset=['text'])\n",
    "    dev_df_full = pd.read_csv(DEV_CSV).dropna(subset=['text'])\n",
    "    print(f\"Loaded {len(train_df_full)} train and {len(dev_df_full)} dev examples.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit()\n",
    "\n",
    "train_df_full['text'] = train_df_full['text'].apply(clean_text)\n",
    "dev_df_full['text'] = dev_df_full['text'].apply(clean_text)\n",
    "print(\"Text cleaning complete.\")\n",
    "\n",
    "# --- PHASE 1: SIMCSE PRE-TRAINING ---\n",
    "\n",
    "# Définition du Trainer Personnalisé pour SimCSE (modifié)\n",
    "class SimCSETrainer(Trainer):\n",
    "    def __init__(self, *args, temperature=0.05, use_mean_pooling=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.use_mean_pooling = use_mean_pooling # Stocker l'option de pooling\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        attention_mask = inputs.get(\"attention_mask\")\n",
    "\n",
    "        # Deux passes avec dropout (implicite dans le modèle en mode train)\n",
    "        outputs1 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        outputs2 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\n",
    "        # --- MODIFIÉ: Choix entre Mean Pooling et CLS Pooling ---\n",
    "        if self.use_mean_pooling:\n",
    "            pooler_output1 = mean_pooling(outputs1.last_hidden_state, attention_mask)\n",
    "            pooler_output2 = mean_pooling(outputs2.last_hidden_state, attention_mask)\n",
    "        else: # Utiliser CLS token\n",
    "            pooler_output1 = outputs1.last_hidden_state[:, 0]\n",
    "            pooler_output2 = outputs2.last_hidden_state[:, 0]\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        # Concaténer et normaliser les embeddings\n",
    "        embeddings = torch.cat([pooler_output1, pooler_output2], dim=0)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1) # L2 Normalization\n",
    "\n",
    "        # Calculer la similarité cosinus\n",
    "        cos_sim = torch.mm(embeddings, embeddings.t()) # Shape: (2*batch_size, 2*batch_size)\n",
    "\n",
    "        # Masquer la diagonale (chaque embedding avec lui-même)\n",
    "        batch_size = pooler_output1.size(0)\n",
    "        mask_diag = torch.eye(2 * batch_size, device=embeddings.device, dtype=torch.bool)\n",
    "        cos_sim = cos_sim.masked_fill(mask_diag, -9e15) # Remplacer par un très petit nombre\n",
    "\n",
    "        # Appliquer la température\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # Créer les labels pour InfoNCE loss\n",
    "        labels = torch.arange(batch_size, device=embeddings.device)\n",
    "        labels_z1 = labels + batch_size # Indices des z2 correspondants\n",
    "        labels_z2 = labels             # Indices des z1 correspondants\n",
    "\n",
    "        # Extraire les logits pour chaque partie\n",
    "        logits_z1 = cos_sim[:batch_size, :] # Logits pour les embeddings de la 1ère passe\n",
    "        logits_z2 = cos_sim[batch_size:, :] # Logits pour les embeddings de la 2ème passe\n",
    "\n",
    "        # Calculer la perte CrossEntropy\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss_z1 = loss_fct(logits_z1, labels_z1)\n",
    "        loss_z2 = loss_fct(logits_z2, labels_z2)\n",
    "\n",
    "        # Perte finale = moyenne des deux\n",
    "        loss = (loss_z1 + loss_z2) / 2\n",
    "\n",
    "        return (loss, {\"embeddings1\": pooler_output1, \"embeddings2\": pooler_output2}) if return_outputs else loss\n",
    "\n",
    "model_load_path = BASE_MODEL_NAME # Default path if SimCSE is skipped\n",
    "\n",
    "if DO_SIMCSE_PRETRAINING:\n",
    "    print(\"\\n--- Phase 1: Starting SimCSE Pre-training ---\")\n",
    "    run_name_simcse = f\"simcse_{'meanpool_' if SIMCSE_USE_MEAN_POOLING else 'cls_'}{BASE_MODEL_NAME}\"\n",
    "    try:\n",
    "        wandb.init(project=WANDB_PROJECT_NAME, name=run_name_simcse, reinit=True)\n",
    "        wandb.config.update({ # Log config SimCSE\n",
    "            \"simcse_model\": BASE_MODEL_NAME,\n",
    "            \"simcse_epochs\": SIMCSE_NUM_EPOCHS,\n",
    "            \"simcse_batch_size\": SIMCSE_BATCH_SIZE,\n",
    "            \"simcse_lr\": SIMCSE_LEARNING_RATE,\n",
    "            \"simcse_temp\": SIMCSE_TEMP,\n",
    "            \"simcse_pooling\": \"mean\" if SIMCSE_USE_MEAN_POOLING else \"cls\",\n",
    "            \"simcse_warmup_ratio\": SIMCSE_WARMUP_RATIO,\n",
    "            \"max_length\": MAX_LENGTH\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"WandB initialization failed for SimCSE phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "    # Préparer le dataset SimCSE (train + dev)\n",
    "    all_texts_df = pd.concat([train_df_full[['text']], dev_df_full[['text']]], ignore_index=True)\n",
    "    simcse_dataset = Dataset.from_pandas(all_texts_df)\n",
    "    print(f\"Created SimCSE dataset with {len(simcse_dataset)} examples.\")\n",
    "\n",
    "    # Tokenizer (Charger ici pour la phase 1)\n",
    "    print(f\"Loading tokenizer {BASE_MODEL_NAME} for SimCSE phase...\")\n",
    "    tokenizer_simcse = AutoTokenizer.from_pretrained(BASE_MODEL_NAME) # Utiliser une variable spécifique\n",
    "\n",
    "    def tokenize_simcse(examples):\n",
    "        # Utiliser tokenizer_simcse défini dans cette portée\n",
    "        return tokenizer_simcse(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    tokenized_simcse_dataset = simcse_dataset.map(tokenize_simcse, batched=True, remove_columns=[\"text\"], num_proc=1) # Utiliser plus de procs si possible\n",
    "    tokenized_simcse_dataset.set_format(\"torch\")\n",
    "    print(\"SimCSE dataset tokenized.\")\n",
    "\n",
    "    # Charger le modèle AutoModel (sans tête)\n",
    "    simcse_model = AutoModel.from_pretrained(BASE_MODEL_NAME)\n",
    "    print(\"SimCSE base model loaded.\")\n",
    "\n",
    "    # Arguments d'entraînement SimCSE (avec warmup)\n",
    "    simcse_training_args = TrainingArguments(\n",
    "        output_dir=SIMCSE_OUTPUT_DIR,\n",
    "        num_train_epochs=SIMCSE_NUM_EPOCHS,\n",
    "        per_device_train_batch_size=SIMCSE_BATCH_SIZE,\n",
    "        learning_rate=SIMCSE_LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{SIMCSE_OUTPUT_DIR}/logs',\n",
    "        logging_steps=SIMCSE_LOGGING_STEPS,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "        fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "        warmup_ratio=SIMCSE_WARMUP_RATIO, # NOUVEAU: Ajout du warmup\n",
    "    )\n",
    "\n",
    "    # Instancier le SimCSE Trainer (avec l'option pooling)\n",
    "    simcse_trainer = SimCSETrainer(\n",
    "        model=simcse_model,\n",
    "        args=simcse_training_args,\n",
    "        train_dataset=tokenized_simcse_dataset,\n",
    "        tokenizer=tokenizer_simcse, # Passer le tokenizer spécifique\n",
    "        temperature=SIMCSE_TEMP,\n",
    "        use_mean_pooling=SIMCSE_USE_MEAN_POOLING # NOUVEAU: Passer l'option\n",
    "    )\n",
    "\n",
    "    # Lancer l'entraînement\n",
    "    print(\"Starting SimCSE training...\")\n",
    "    simcse_trainer.train()\n",
    "    print(\"SimCSE training finished.\")\n",
    "\n",
    "    # Sauvegarder\n",
    "    simcse_trainer.save_model(SIMCSE_OUTPUT_DIR)\n",
    "    tokenizer_simcse.save_pretrained(SIMCSE_OUTPUT_DIR) # Sauver le tokenizer utilisé\n",
    "    print(f\"SimCSE pre-trained model and tokenizer saved to {SIMCSE_OUTPUT_DIR}\")\n",
    "\n",
    "    # Nettoyer\n",
    "    model_load_path = SIMCSE_OUTPUT_DIR # Mettre à jour le chemin pour la phase 2\n",
    "    del simcse_model, simcse_trainer, tokenized_simcse_dataset, simcse_dataset, all_texts_df, tokenizer_simcse\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    print(\"--- Phase 1: SimCSE Pre-training Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Phase 1: Skipping SimCSE Pre-training ---\")\n",
    "    # model_load_path reste BASE_MODEL_NAME (défini plus haut)\n",
    "\n",
    "\n",
    "# --- PHASE 2: CLASSIFICATION FINE-TUNING ---\n",
    "print(\"\\n--- Phase 2: Starting Classification Fine-tuning ---\")\n",
    "run_name_classify = f\"classify_ft_on_{'simcse' if DO_SIMCSE_PRETRAINING else 'base'}_{BASE_MODEL_NAME}\"\n",
    "try:\n",
    "    wandb.init(project=WANDB_PROJECT_NAME, name=run_name_classify, reinit=True)\n",
    "    wandb.config.update({ # Log config Classification\n",
    "        \"base_model_for_ft\": model_load_path,\n",
    "        \"classify_epochs\": CLASSIFICATION_NUM_EPOCHS,\n",
    "        \"classify_batch_size\": CLASSIFICATION_BATCH_SIZE,\n",
    "        \"classify_grad_accum\": CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_effective_batch\": CLASSIFICATION_BATCH_SIZE * CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_lr\": CLASSIFICATION_LEARNING_RATE,\n",
    "        \"classify_warmup_ratio\": CLASSIFICATION_WARMUP_RATIO,\n",
    "        \"classify_early_stopping\": CLASSIFICATION_EARLY_STOPPING_PATIENCE,\n",
    "        \"max_length\": MAX_LENGTH\n",
    "    })\n",
    "except Exception as e:\n",
    "        print(f\"WandB initialization failed for Classification phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "# Préparer les datasets classification\n",
    "train_dataset_cls = Dataset.from_pandas(train_df_full)\n",
    "dev_dataset_cls = Dataset.from_pandas(dev_df_full)\n",
    "dataset_dict_cls = DatasetDict({'train': train_dataset_cls, 'validation': dev_dataset_cls})\n",
    "print(\"Classification datasets created.\")\n",
    "\n",
    "# --- CORRECTIF: Charger systématiquement le tokenizer pour la Phase 2 ---\n",
    "# Charger le tokenizer correspondant au modèle que nous allons fine-tuner\n",
    "# (soit celui de SimCSE si Phase 1 a tourné, soit celui du modèle de base)\n",
    "print(f\"Loading tokenizer for classification phase from: {model_load_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_load_path)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def tokenize_classification(examples):\n",
    "    # Utilise le 'tokenizer' défini juste au-dessus\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "tokenized_datasets_cls = dataset_dict_cls.map(tokenize_classification, batched=True, remove_columns=[\"text\", \"id\", \"file_name\", \"origin\", \"language\", \"split\", \"type\"], num_proc=1)\n",
    "tokenized_datasets_cls.set_format(\"torch\")\n",
    "tokenized_datasets_cls = tokenized_datasets_cls.rename_column(\"label\", \"labels\")\n",
    "print(\"Classification datasets tokenized.\")\n",
    "\n",
    "# Calculer poids de classe\n",
    "print(\"Computing class weights for classification...\")\n",
    "labels_train_cls = train_df_full['label'].values\n",
    "class_weights_tensor_cls = None\n",
    "unique_labels_cls = np.unique(labels_train_cls)\n",
    "num_distinct_labels = len(unique_labels_cls)\n",
    "print(f\"Detected {num_distinct_labels} distinct labels in training data: {unique_labels_cls}\")\n",
    "\n",
    "if num_distinct_labels > 1:\n",
    "    class_weights_cls = compute_class_weight(class_weight='balanced', classes=unique_labels_cls, y=labels_train_cls)\n",
    "    # Ensure weights are ordered according to label index (0, 1, ...)\n",
    "    ordered_weights_dict = {label: weight for label, weight in zip(unique_labels_cls, class_weights_cls)}\n",
    "    # Utiliser num_distinct_labels pour déterminer la taille du tenseur\n",
    "    ordered_weights_cls = np.array([ordered_weights_dict.get(i, 0) for i in unique_labels_cls]) # Assigner poids aux labels existants\n",
    "\n",
    "    class_weights_tensor_cls = torch.tensor(ordered_weights_cls, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Class Weights (for classes {unique_labels_cls}): {class_weights_tensor_cls.cpu().numpy()}\")\n",
    "    if wandb.run: wandb.config.update({\"class_weights\": class_weights_tensor_cls.cpu().numpy().tolist()})\n",
    "else:\n",
    "    print(\"Warning: Only one class found in training data. Cannot compute class weights.\")\n",
    "\n",
    "\n",
    "# Trainer Personnalisé Classification avec Poids\n",
    "class WeightedClassificationTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "         super().__init__(*args, **kwargs)\n",
    "         # Déplacer les poids sur le bon device une seule fois si possible\n",
    "         self.class_weights = class_weights.to(self.args.device) if class_weights is not None else None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Utiliser les poids stockés et déjà sur le bon device\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss() # No weights\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Charger le modèle pour Classification\n",
    "print(f\"Loading model for classification from: {model_load_path}\")\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_load_path,\n",
    "    num_labels=num_distinct_labels, # Utiliser le nombre détecté\n",
    "    ignore_mismatched_sizes=True # Crucial si chargement depuis AutoModel (SimCSE)\n",
    ")\n",
    "print(\"Classification model loaded.\")\n",
    "\n",
    "# Fonction compute_metrics\n",
    "def compute_metrics_cls(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    metric_labels = unique_labels_cls # Utiliser les labels détectés\n",
    "    if num_distinct_labels == 2:\n",
    "        # Calcul spécifique pour binaire (Pos = 1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0, 1], zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_pos': f1[1] if len(f1) > 1 else 0,\n",
    "            'precision_pos': precision[1] if len(precision) > 1 else 0,\n",
    "            'recall_pos': recall[1] if len(recall) > 1 else 0,\n",
    "            'f1_neg': f1[0] if len(f1) > 0 else 0,\n",
    "        }\n",
    "    else:\n",
    "        # Calcul macro/weighted pour multiclasse\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', labels=metric_labels, zero_division=0)\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(labels, preds, average='weighted', labels=metric_labels, zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "        }\n",
    "        # Optionnel: ajouter f1 par classe si besoin\n",
    "        # _, _, f1_per_class, _ = precision_recall_fscore_support(labels, preds, average=None, labels=metric_labels, zero_division=0)\n",
    "        # for i, label in enumerate(metric_labels):\n",
    "        #     metrics[f'f1_class_{label}'] = f1_per_class[i]\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Arguments d'entraînement Classification (avec warmup)\n",
    "classification_training_args = TrainingArguments(\n",
    "    output_dir=CLASSIFICATION_OUTPUT_DIR,\n",
    "    num_train_epochs=CLASSIFICATION_NUM_EPOCHS,\n",
    "    per_device_train_batch_size=CLASSIFICATION_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=CLASSIFICATION_BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "    learning_rate=CLASSIFICATION_LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Choisir la métrique pertinente pour load_best_model_at_end\n",
    "    metric_for_best_model=\"f1_pos\" if num_distinct_labels == 2 else \"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=f'{CLASSIFICATION_OUTPUT_DIR}/logs',\n",
    "    logging_steps=CLASSIFICATION_LOGGING_STEPS,\n",
    "    report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "    fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "    warmup_ratio=CLASSIFICATION_WARMUP_RATIO,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Instancier le Trainer Classification (passer les poids ici)\n",
    "classification_trainer = WeightedClassificationTrainer(\n",
    "    model=classification_model,\n",
    "    args=classification_training_args,\n",
    "    train_dataset=tokenized_datasets_cls[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_cls[\"validation\"],\n",
    "    tokenizer=tokenizer, # Utiliser le tokenizer chargé pour la phase 2\n",
    "    compute_metrics=compute_metrics_cls,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=CLASSIFICATION_EARLY_STOPPING_PATIENCE)],\n",
    "    class_weights=class_weights_tensor_cls # Passer le tenseur de poids\n",
    ")\n",
    "print(\"Classification Trainer configured.\")\n",
    "\n",
    "# Lancer le fine-tuning\n",
    "print(\"Starting classification fine-tuning...\")\n",
    "classification_trainer.train()\n",
    "print(\"Classification fine-tuning finished.\")\n",
    "\n",
    "# Sauvegarder le meilleur modèle explicitement\n",
    "best_model_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, \"best_model\")\n",
    "classification_trainer.save_model(best_model_path)\n",
    "tokenizer.save_pretrained(best_model_path) # Sauver le tokenizer avec le meilleur modèle\n",
    "print(f\"Best classification model and tokenizer saved to {best_model_path}\")\n",
    "\n",
    "# --- Évaluation Détaillée et Soumission (Utilise le meilleur modèle chargé) ---\n",
    "print(\"\\n--- Detailed Evaluation and Submission File Generation ---\")\n",
    "print(\"\\nGenerating predictions for Threshold Adjustment and Detailed Metrics...\")\n",
    "\n",
    "predictions_output = classification_trainer.predict(tokenized_datasets_cls[\"validation\"])\n",
    "logits = predictions_output.predictions\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "if logits.shape[-1] != num_distinct_labels:\n",
    "    print(f\"Error: Logits shape {logits.shape} unexpected for {num_distinct_labels} labels.\")\n",
    "    exit()\n",
    "\n",
    "probabilities = None\n",
    "predicted_labels_final = None\n",
    "best_threshold = None\n",
    "\n",
    "if num_distinct_labels == 2:\n",
    "    probabilities = softmax(logits, axis=-1)[:, 1] # Proba classe positive (index 1)\n",
    "    print(\"\\nFinding best threshold on validation set based on Overall F1-Positive...\")\n",
    "    best_f1 = -1\n",
    "    best_threshold = 0.5 # Default\n",
    "    thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "    f1_scores_thresh = []\n",
    "    for threshold in thresholds:\n",
    "        predicted_labels_thresh = (probabilities >= threshold).astype(int)\n",
    "        precision_thresh, recall_thresh, f1_thresh, _ = precision_recall_fscore_support(\n",
    "            true_labels, predicted_labels_thresh, average='binary', pos_label=1, zero_division=0)\n",
    "        f1_scores_thresh.append(f1_thresh)\n",
    "        if f1_thresh > best_f1:\n",
    "            best_f1 = f1_thresh\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"\\nBest threshold found: {best_threshold:.2f} with Overall F1-Pos: {best_f1:.4f}\")\n",
    "    if wandb.run: wandb.log({\"eval/best_threshold\": best_threshold, \"eval/best_val_f1_at_threshold\": best_f1})\n",
    "    predicted_labels_final = (probabilities >= best_threshold).astype(int)\n",
    "else:\n",
    "    print(\"Multi-class classification detected (>2). Using argmax for final predictions.\")\n",
    "    predicted_labels_final = logits.argmax(-1)\n",
    "    # best_threshold reste None\n",
    "\n",
    "# Préparer le DataFrame pour l'évaluation détaillée\n",
    "dev_df_eval = dev_df_full.reset_index(drop=True)\n",
    "if len(dev_df_eval) == len(predicted_labels_final):\n",
    "    dev_df_eval['predicted_label'] = predicted_labels_final\n",
    "    if probabilities is not None:\n",
    "         dev_df_eval['probability_positive'] = probabilities\n",
    "else:\n",
    "    print(f\"Error: Length mismatch between dev_df {len(dev_df_eval)} and predictions {len(predicted_labels_final)}!\")\n",
    "    exit()\n",
    "\n",
    "dev_df_eval[\"language\"] = dev_df_full[\"id\"].apply(lambda x: str(x).split(\"_\")[0] if isinstance(x, str) and \"_\" in x else \"unknown\")\n",
    "\n",
    "languages = sorted(dev_df_eval['language'].unique())\n",
    "language_f1_scores_pos = [] # Pour Macro F1 binaire\n",
    "wandb_logs_eval = {}\n",
    "print(f\"\\n--- Detailed Evaluation on Development Set (Final Predictions) ---\")\n",
    "if best_threshold is not None:\n",
    "     print(f\"--- (Using Threshold = {best_threshold:.2f}) ---\")\n",
    "\n",
    "for lang in languages:\n",
    "    if lang == \"unknown\": continue\n",
    "    lang_mask = dev_df_eval['language'] == lang\n",
    "    y_true_lang = dev_df_eval.loc[lang_mask, 'label'].tolist()\n",
    "    y_pred_lang_final = dev_df_eval.loc[lang_mask, 'predicted_label'].tolist()\n",
    "    if len(y_true_lang) == 0: continue\n",
    "\n",
    "    # Utiliser les labels détectés pour le calcul des métriques\n",
    "    metric_labels = unique_labels_cls\n",
    "    precision_lang, recall_lang, f1_lang, support_lang = precision_recall_fscore_support(\n",
    "        y_true_lang, y_pred_lang_final, average=None, labels=metric_labels, zero_division=0)\n",
    "    accuracy_lang = accuracy_score(y_true_lang, y_pred_lang_final)\n",
    "\n",
    "    print(f\"\\nMetrics for language: {lang.upper()} (Support: {dict(zip(metric_labels, support_lang))})\")\n",
    "    # Clé WandB dynamique basée sur seuil/argmax\n",
    "    wandb_key_prefix = f\"eval/{lang}\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "    if num_distinct_labels == 2:\n",
    "        f1_pos_lang = f1_lang[1] # Index 1 correspond au label 1 (Positif)\n",
    "        language_f1_scores_pos.append(f1_pos_lang)\n",
    "        print(f\"  Precision (Pos/1): {precision_lang[1]:.4f}\")\n",
    "        print(f\"  Recall    (Pos/1): {recall_lang[1]:.4f}\")\n",
    "        print(f\"  F1        (Pos/1): {f1_pos_lang:.4f}\")\n",
    "        print(f\"  Accuracy:          {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/precision_pos\"] = precision_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/recall_pos\"] = recall_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_pos\"] = f1_pos_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "    else:\n",
    "        f1_macro_lang = np.mean(f1_lang) # F1 macro simple\n",
    "        print(f\"  F1-Macro:         {f1_macro_lang:.4f}\")\n",
    "        print(f\"  Accuracy:         {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_macro\"] = f1_macro_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "        # Logguer F1 par classe si besoin\n",
    "        for i, label in enumerate(metric_labels):\n",
    "             wandb_logs_eval[f\"{wandb_key_prefix}/f1_class_{label}\"] = f1_lang[i]\n",
    "\n",
    "\n",
    "# Calcul des métriques globales finales\n",
    "cm_overall_final = confusion_matrix(true_labels, predicted_labels_final, labels=unique_labels_cls)\n",
    "overall_accuracy_final = accuracy_score(true_labels, predicted_labels_final)\n",
    "wandb_key_prefix_overall = \"eval/overall\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "print(f\"\\n--- Overall Evaluation Summary (Final Predictions) ---\")\n",
    "if num_distinct_labels == 2:\n",
    "    # Assurer que cm a bien 4 éléments (cas binaire)\n",
    "    if cm_overall_final.size == 4:\n",
    "      tn, fp, fn, tp = cm_overall_final.ravel()\n",
    "    else: # Gérer cas où une classe n'est pas prédite/présente dans l'éval\n",
    "      tn, fp, fn, tp = 0, 0, 0, 0\n",
    "      print(\"Warning: Confusion matrix size indicates potential missing classes in evaluation.\")\n",
    "      # Logique pour reconstruire TN/FP/FN/TP si nécessaire basée sur les labels uniques\n",
    "      if 0 in unique_labels_cls and 1 in unique_labels_cls:\n",
    "          tn = cm_overall_final[0, 0]\n",
    "          fp = cm_overall_final[0, 1]\n",
    "          fn = cm_overall_final[1, 0]\n",
    "          tp = cm_overall_final[1, 1]\n",
    "\n",
    "    overall_precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    overall_recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    overall_f1_pos = 2 * (overall_precision_pos * overall_recall_pos) / (overall_precision_pos + overall_recall_pos) if (overall_precision_pos + overall_recall_pos) > 0 else 0\n",
    "    macro_f1_pos = np.mean(language_f1_scores_pos) if language_f1_scores_pos else 0 # Moyenne des F1-pos par langue\n",
    "\n",
    "    print(f\"Overall F1-score (Positive Class): {overall_f1_pos:.4f}  <-- Primary Metric\")\n",
    "    print(f\"Macro F1-score (Pos Class / Lang): {macro_f1_pos:.4f}\")\n",
    "    print(f\"Overall Precision (Positive Class):{overall_precision_pos:.4f}\")\n",
    "    print(f\"Overall Recall (Positive Class):   {overall_recall_pos:.4f}\")\n",
    "    print(f\"Overall Accuracy:                  {overall_accuracy_final:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_pos\"] = overall_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/macro_f1_pos_lang\"] = macro_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/precision_pos\"] = overall_precision_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/recall_pos\"] = overall_recall_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "else: # Métriques globales pour multiclasse\n",
    "    overall_prec_macro, overall_recall_macro, overall_f1_macro, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='macro', labels=unique_labels_cls, zero_division=0)\n",
    "    overall_prec_weighted, overall_recall_weighted, overall_f1_weighted, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='weighted', labels=unique_labels_cls, zero_division=0)\n",
    "    print(f\"Overall Accuracy:     {overall_accuracy_final:.4f}\")\n",
    "    print(f\"Overall F1 (Macro):   {overall_f1_macro:.4f}\")\n",
    "    print(f\"Overall F1 (Weighted):{overall_f1_weighted:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_macro\"] = overall_f1_macro\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_weighted\"] = overall_f1_weighted\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "# Log all detailed eval metrics\n",
    "if wandb.run: wandb.log(wandb_logs_eval)\n",
    "\n",
    "# --- Sauvegarde du fichier de soumission ---\n",
    "print(\"\\nSaving predictions for submission...\")\n",
    "os.makedirs(CLASSIFICATION_OUTPUT_DIR, exist_ok=True)\n",
    "submission_df = dev_df_eval[['id', 'predicted_label']]\n",
    "suffix = \"simcse_finetuned\" if DO_SIMCSE_PRETRAINING else \"base_finetuned\"\n",
    "thresh_suffix = f\"_thresh{best_threshold:.2f}\" if best_threshold is not None else \"_argmax\"\n",
    "csv_filename = f\"predictions_task1_{suffix}{thresh_suffix}.csv\"\n",
    "zip_filename = f\"submission_task1_{suffix}{thresh_suffix}.zip\"\n",
    "csv_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, csv_filename)\n",
    "zip_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, zip_filename)\n",
    "\n",
    "submission_df.to_csv(csv_path, index=False)\n",
    "print(f\"Predictions saved to {csv_path}\")\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(csv_path, arcname=csv_filename)\n",
    "    print(f\"{csv_filename} has been zipped into {zip_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error zipping the file: {e}\")\n",
    "\n",
    "\n",
    "if wandb.run is not None and wandb.run.step > 0: # Check if wandb was used and logged something\n",
    "    wandb.finish()\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO SimSCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: caron-olivier-80 (caron-olivier-80-universit-paris-dauphine-psl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250404_172838-05pneq0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr/runs/05pneq0q' target=\"_blank\">royal-dew-4</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr/runs/05pneq0q' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-xlmr/runs/05pneq0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n",
      "Tokenizing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c60592ad1411382e50a5004b283cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f094aeabf6472faf83edbae1f69d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "Cleaning dataset columns...\n",
      "Columns before removal: ['id', 'text', 'label', 'file_name', 'origin', 'type', 'language', 'split', 'input_ids', 'attention_mask']\n",
      "Removing columns: ['text', 'id', 'file_name', 'origin', 'language', 'split', 'type']\n",
      "Columns after cleaning and rename: ['labels', 'input_ids', 'attention_mask']\n",
      "Computing class weights...\n",
      "Class Weights: tensor([0.5826, 3.5274], device='cuda:0')\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Setting training arguments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_25784\\3646678359.py:140: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer configured.\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8368' max='8368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8368/8368 57:13, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Pos</th>\n",
       "      <th>Precision Pos</th>\n",
       "      <th>Recall Pos</th>\n",
       "      <th>F1 Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.340643</td>\n",
       "      <td>0.917189</td>\n",
       "      <td>0.577729</td>\n",
       "      <td>0.514735</td>\n",
       "      <td>0.658291</td>\n",
       "      <td>0.954093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.422801</td>\n",
       "      <td>0.905514</td>\n",
       "      <td>0.588124</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.946636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.507462</td>\n",
       "      <td>0.942270</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.968666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.477409</td>\n",
       "      <td>0.924757</td>\n",
       "      <td>0.640496</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.778894</td>\n",
       "      <td>0.957981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.633990</td>\n",
       "      <td>0.940324</td>\n",
       "      <td>0.658416</td>\n",
       "      <td>0.648780</td>\n",
       "      <td>0.668342</td>\n",
       "      <td>0.967306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.874420</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.704420</td>\n",
       "      <td>0.640704</td>\n",
       "      <td>0.970554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.924574</td>\n",
       "      <td>0.941838</td>\n",
       "      <td>0.672351</td>\n",
       "      <td>0.652482</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.968086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n",
      "Evaluating on Development Set (Best Model)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "{'eval_loss': 0.9245741367340088, 'eval_accuracy': 0.9418378378378378, 'eval_f1_pos': 0.6723507917174177, 'eval_precision_pos': 0.6524822695035462, 'eval_recall_pos': 0.6934673366834171, 'eval_f1_neg': 0.9680863684897378, 'eval_runtime': 10.1814, 'eval_samples_per_second': 454.259, 'eval_steps_per_second': 28.483, 'epoch': 7.992833253702819}\n",
      "\n",
      "Generating predictions and detailed metrics for Dev Set...\n",
      "\n",
      "--- Detailed Evaluation on Development Set ---\n",
      "\n",
      "Metrics for language: DE\n",
      "  Precision-de (Pos): 0.4889\n",
      "  Recall-de    (Pos): 0.6286\n",
      "  F1-de        (Pos): 0.5500\n",
      "  Accuracy-de:        0.9432\n",
      "\n",
      "Metrics for language: EN\n",
      "  Precision-en (Pos): 0.7385\n",
      "  Recall-en    (Pos): 0.7869\n",
      "  F1-en        (Pos): 0.7619\n",
      "  Accuracy-en:        0.9667\n",
      "\n",
      "Metrics for language: FR\n",
      "  Precision-fr (Pos): 0.4894\n",
      "  Recall-fr    (Pos): 0.7667\n",
      "  F1-fr        (Pos): 0.5974\n",
      "  Accuracy-fr:        0.9260\n",
      "\n",
      "Metrics for language: RU\n",
      "  Precision-ru (Pos): 0.6880\n",
      "  Recall-ru    (Pos): 0.6728\n",
      "  F1-ru        (Pos): 0.6803\n",
      "  Accuracy-ru:        0.9356\n",
      "\n",
      "--- Overall Evaluation Summary (Positive Class Focus) ---\n",
      "F1-score across all languages (Positive Class): 0.6724  <-- Primary Metric\n",
      "Macro F1-score across all languages (Pos Class):0.6474\n",
      "Overall Precision (Positive Class):             0.6525\n",
      "Overall Recall (Positive Class):                0.6935\n",
      "Overall Accuracy across all languages:          0.9418\n",
      "\n",
      "Overall Confusion Matrix (All Languages):\n",
      "[[TN=4080  FP=147]\n",
      " [FN=122  TP=276]]\n",
      "Metrics logged to WandB.\n",
      "\n",
      "Saving predictions for submission...\n",
      "Predictions saved to results_xlmr_augmented_longer_train\\predictions_task1.csv\n",
      "predictions_task1.csv has been zipped into results_xlmr_augmented_longer_train\\submission_task1.zip\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback # Importer le callback pour l'arrêt précoce\n",
    ")\n",
    "# Assurez-vous que wandb est initialisé si vous l'utilisez, sinon commentez/supprimez les lignes wandb.log\n",
    "import wandb\n",
    "wandb.init(project=\"ade-classification-xlmr\") # Exemple d'initialisation\n",
    "\n",
    "# CORRECTION ICI: Ajout de precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "import zipfile # Pour la sauvegarde finale\n",
    "import os # Pour la sauvegarde finale\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "TRAIN_CSV = \"data/train_data_augmented_no_text_clean.csv\" # Nouveau fichier d'entraînement\n",
    "DEV_CSV = \"data/dev_data_SMM4H_2025_Task_1.csv\"\n",
    "OUTPUT_DIR = \"results_xlmr_augmented_longer_train\" # Nouveau répertoire de sortie\n",
    "NUM_EPOCHS = 8 # Augmenté le nombre d'époques\n",
    "BATCH_SIZE = 8 # Gardé petit pour la mémoire GPU\n",
    "LEARNING_RATE = 2e-5\n",
    "GRADIENT_ACCUMULATION_STEPS = 4 # Accumuler les gradients (batch effectif = 8*4=32)\n",
    "EARLY_STOPPING_PATIENCE = 3 # Patience pour l'arrêt précoce\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV).dropna(subset=['text'])\n",
    "    dev_df = pd.read_csv(DEV_CSV).dropna(subset=['text'])\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "dataset_dict = DatasetDict({'train': train_dataset, 'validation': dev_dataset})\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# --- 2. Tokenization ---\n",
    "print(\"Tokenizing data...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# --- Clean up columns ---\n",
    "print(\"Cleaning dataset columns...\")\n",
    "print(\"Columns before removal:\", tokenized_datasets['train'].column_names)\n",
    "columns_to_remove = [\"text\", \"id\", \"file_name\", \"origin\", \"language\", \"split\", \"type\"]\n",
    "actual_columns_to_remove = [col for col in columns_to_remove if col in tokenized_datasets['train'].column_names]\n",
    "print(\"Removing columns:\", actual_columns_to_remove)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(actual_columns_to_remove)\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Rename 'label' to 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "print(\"Columns after cleaning and rename:\", tokenized_datasets['train'].column_names)\n",
    "\n",
    "# --- 3. Compute Class Weights ---\n",
    "print(\"Computing class weights...\")\n",
    "labels_train = train_df['label'].values\n",
    "if len(np.unique(labels_train)) > 1: # Ensure there are at least two classes\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels_train), y=labels_train)\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Class Weights: {class_weights_tensor}\")\n",
    "else:\n",
    "    print(\"Warning: Only one class found in training data. Cannot compute class weights.\")\n",
    "    class_weights_tensor = None # Handle this case in the loss function if needed\n",
    "\n",
    "# --- Custom Trainer for Weighted Loss ---\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Use weights only if they were computed\n",
    "        if class_weights_tensor is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss() # Default unweighted loss\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# --- 4. Model & Metrics ---\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Fonction compute_metrics qui utilise la fonction importée\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # Utilisation de precision_recall_fscore_support\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0, 1], zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_pos': f1[1], # F1 for class 1\n",
    "        'precision_pos': precision[1],\n",
    "        'recall_pos': recall[1],\n",
    "        'f1_neg': f1[0], # F1 for class 0 (for info)\n",
    "    }\n",
    "\n",
    "# --- 5. Training Arguments ---\n",
    "print(\"Setting training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,                 # Augmenté\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE*2,     # Peut souvent être plus grand pour l'évaluation\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS, # Ajouté\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,                # Important avec Early Stopping\n",
    "    metric_for_best_model=\"f1_pos\",             # Métrique à surveiller\n",
    "    greater_is_better=True,                     # On veut maximiser le F1\n",
    "    # early_stopping_patience=EARLY_STOPPING_PATIENCE, # Activé via Callback\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    report_to=\"wandb\" if \"wandb\" in locals() else \"none\", # Log to wandb if initialized\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=2, # Garde seulement les 2 meilleurs checkpoints + le dernier\n",
    ")\n",
    "\n",
    "# --- 6. Trainer ---\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # Ajout du Callback pour Early Stopping\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)]\n",
    ")\n",
    "print(\"Trainer configured.\")\n",
    "\n",
    "# --- 7. Train ---\n",
    "print(\"Starting Training...\")\n",
    "train_result = trainer.train()\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Log training metrics\n",
    "# trainer.log_metrics(\"train\", train_result.metrics) # Décommenter si besoin\n",
    "# trainer.save_metrics(\"train\", train_result.metrics) # Décommenter si besoin\n",
    "# trainer.save_state() # Sauvegarde l'état du Trainer\n",
    "\n",
    "# --- 8. Evaluate on Dev Set (using the best model loaded) ---\n",
    "print(\"\\nEvaluating on Development Set (Best Model)...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\")\n",
    "print(eval_results)\n",
    "# trainer.log_metrics(\"eval\", eval_results) # Décommenter si besoin\n",
    "# trainer.save_metrics(\"eval\", eval_results) # Décommenter si besoin\n",
    "\n",
    "# --- 9. Detailed Evaluation and Submission File Generation ---\n",
    "print(\"\\nGenerating predictions and detailed metrics for Dev Set...\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "predicted_labels = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Add predictions to the dev dataframe (ensure index alignment if necessary)\n",
    "# If dev_df was filtered by dropna, indices might not match directly. Resetting index helps.\n",
    "dev_df_eval = dev_df.reset_index(drop=True)\n",
    "# Check lengths match before assigning\n",
    "if len(dev_df_eval) == len(predicted_labels):\n",
    "    dev_df_eval['predicted_label'] = predicted_labels\n",
    "else:\n",
    "    print(f\"Error: Length mismatch! Dev DF has {len(dev_df_eval)} rows, Predictions have {len(predicted_labels)} entries.\")\n",
    "    # Handle error appropriately, maybe skip detailed eval or investigate dropna impact\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Re-extract language (assuming ID format 'lang_...') - Be careful if IDs differ\n",
    "dev_df_eval[\"language\"] = dev_df_eval[\"id\"].apply(lambda x: str(x).split(\"_\")[0] if isinstance(x, str) and \"_\" in x else \"unknown\")\n",
    "\n",
    "# --- Calculate Per-Language and Overall Metrics ---\n",
    "languages = sorted(dev_df_eval['language'].unique())\n",
    "per_language_metrics = {}\n",
    "language_f1_scores = []\n",
    "all_true_labels_eval = []\n",
    "all_pred_labels_eval = []\n",
    "\n",
    "print(\"\\n--- Detailed Evaluation on Development Set ---\")\n",
    "wandb_logs = {} # Collect logs for wandb\n",
    "\n",
    "for lang in languages:\n",
    "    if lang == \"unknown\": continue # Skip if language couldn't be extracted\n",
    "    lang_mask = dev_df_eval['language'] == lang\n",
    "    y_true_lang = dev_df_eval.loc[lang_mask, 'label']\n",
    "    y_pred_lang = dev_df_eval.loc[lang_mask, 'predicted_label']\n",
    "\n",
    "    if len(y_true_lang) == 0: continue # Skip if no data for this language\n",
    "\n",
    "    all_true_labels_eval.extend(y_true_lang.tolist())\n",
    "    all_pred_labels_eval.extend(y_pred_lang.tolist())\n",
    "\n",
    "    # Utilisation de precision_recall_fscore_support (qui est maintenant importé)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true_lang, y_pred_lang, average=None, labels=[0, 1], zero_division=0)\n",
    "    accuracy_lang = accuracy_score(y_true_lang, y_pred_lang) # Renommé pour éviter conflit avec la fonction accuracy_score\n",
    "\n",
    "    per_language_metrics[lang] = {'precision': precision[1], 'recall': recall[1], 'f1': f1[1], 'accuracy': accuracy_lang}\n",
    "    language_f1_scores.append(f1[1]) # On stocke le F1 de la classe positive (1)\n",
    "\n",
    "    print(f\"\\nMetrics for language: {lang.upper()}\")\n",
    "    print(f\"  Precision-{lang} (Pos): {precision[1]:.4f}\")\n",
    "    print(f\"  Recall-{lang}    (Pos): {recall[1]:.4f}\")\n",
    "    print(f\"  F1-{lang}        (Pos): {f1[1]:.4f}\")\n",
    "    print(f\"  Accuracy-{lang}:        {accuracy_lang:.4f}\")\n",
    "\n",
    "    # Prepare logs for wandb\n",
    "    wandb_logs[f\"{lang}/precision_pos\"] = precision[1]\n",
    "    wandb_logs[f\"{lang}/recall_pos\"] = recall[1]\n",
    "    wandb_logs[f\"{lang}/f1_pos\"] = f1[1]\n",
    "    wandb_logs[f\"{lang}/accuracy\"] = accuracy_lang\n",
    "\n",
    "\n",
    "# Calculate Overall Metrics (using the full dev set lists)\n",
    "cm_overall = confusion_matrix(all_true_labels_eval, all_pred_labels_eval, labels=[0, 1])\n",
    "tn, fp, fn, tp = cm_overall.ravel() if cm_overall.size == 4 else (0, 0, 0, 0) # Handle cases with missing classes\n",
    "\n",
    "overall_precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "overall_recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "# Overall F1 (Primary Metric for Positive Class)\n",
    "overall_f1_pos = 2 * (overall_precision_pos * overall_recall_pos) / (overall_precision_pos + overall_recall_pos) if (overall_precision_pos + overall_recall_pos) > 0 else 0\n",
    "# Macro F1 (Average of per-language F1s for Positive Class)\n",
    "macro_f1_pos = np.mean(language_f1_scores) if language_f1_scores else 0\n",
    "# Overall Accuracy\n",
    "overall_accuracy = accuracy_score(all_true_labels_eval, all_pred_labels_eval)\n",
    "\n",
    "print(\"\\n--- Overall Evaluation Summary (Positive Class Focus) ---\")\n",
    "print(f\"F1-score across all languages (Positive Class): {overall_f1_pos:.4f}  <-- Primary Metric\")\n",
    "print(f\"Macro F1-score across all languages (Pos Class):{macro_f1_pos:.4f}\")\n",
    "print(f\"Overall Precision (Positive Class):             {overall_precision_pos:.4f}\")\n",
    "print(f\"Overall Recall (Positive Class):                {overall_recall_pos:.4f}\")\n",
    "print(f\"Overall Accuracy across all languages:          {overall_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nOverall Confusion Matrix (All Languages):\")\n",
    "print(f\"[[TN={tn}  FP={fp}]\")\n",
    "print(f\" [FN={fn}  TP={tp}]]\")\n",
    "\n",
    "# Add overall metrics to wandb logs\n",
    "wandb_logs[\"overall/f1_pos\"] = overall_f1_pos\n",
    "wandb_logs[\"overall/macro_f1_pos\"] = macro_f1_pos\n",
    "wandb_logs[\"overall/precision_pos\"] = overall_precision_pos\n",
    "wandb_logs[\"overall/recall_pos\"] = overall_recall_pos\n",
    "wandb_logs[\"overall/accuracy\"] = overall_accuracy\n",
    "wandb_logs[\"overall/TP\"] = tp\n",
    "wandb_logs[\"overall/FP\"] = fp\n",
    "wandb_logs[\"overall/FN\"] = fn\n",
    "wandb_logs[\"overall/TN\"] = tn\n",
    "\n",
    "# Log Confusion Matrix to wandb (optional)\n",
    "if \"wandb\" in locals() and tp+fp+fn+tn > 0:\n",
    "     try:\n",
    "        wandb_logs[\"confusion_matrix\"] = wandb.plot.confusion_matrix(\n",
    "             probs=None,\n",
    "             y_true=all_true_labels_eval,\n",
    "             preds=all_pred_labels_eval,\n",
    "             class_names=[\"Negative (0)\", \"Positive (1)\"]\n",
    "         )\n",
    "     except Exception as e:\n",
    "         print(f\"Could not log confusion matrix to wandb: {e}\")\n",
    "\n",
    "\n",
    "# Log all collected metrics to wandb (if initialized)\n",
    "if \"wandb\" in locals():\n",
    "    try:\n",
    "        wandb.log(wandb_logs)\n",
    "        print(\"Metrics logged to WandB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not log metrics to wandb: {e}\")\n",
    "\n",
    "\n",
    "# --- 10. Save Submission File ---\n",
    "print(\"\\nSaving predictions for submission...\")\n",
    "# Ensure results directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Prepare submission dataframe\n",
    "submission_df = dev_df_eval[['id', 'predicted_label']]\n",
    "\n",
    "# Define CSV and ZIP paths\n",
    "csv_filename = \"predictions_task1.csv\"\n",
    "zip_filename = \"submission_task1.zip\"\n",
    "csv_path = os.path.join(OUTPUT_DIR, csv_filename)\n",
    "zip_path = os.path.join(OUTPUT_DIR, zip_filename)\n",
    "\n",
    "# Save CSV\n",
    "submission_df.to_csv(csv_path, index=False)\n",
    "print(f\"Predictions saved to {csv_path}\")\n",
    "\n",
    "# Zip the CSV file\n",
    "with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(csv_path, arcname=csv_filename)\n",
    "print(f\"{csv_filename} has been zipped into {zip_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Data with LLM traduction + paraphrase + SIMSCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- Initial Data Loading and Cleaning ---\n",
      "Loaded 33482 train and 4625 dev examples.\n",
      "Text cleaning complete.\n",
      "\n",
      "--- Phase 1: Starting SimCSE Pre-training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: caron-olivier-80 (caron-olivier-80-universit-paris-dauphine-psl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250405_163054-u04yrotd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/u04yrotd' target=\"_blank\">simcse_meanpool_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/u04yrotd' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/u04yrotd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created SimCSE dataset with 38107 examples.\n",
      "Loading tokenizer xlm-roberta-base for SimCSE phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251c2f519647445c9e319c0db2117d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE dataset tokenized.\n",
      "SimCSE base model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_7652\\3583386714.py:100: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimCSETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SimCSE training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4764' max='4764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4764/4764 16:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE training finished.\n",
      "SimCSE pre-trained model and tokenizer saved to results_LLMTRADPARAPHRASE_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▆▇█████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3838151985260544.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>4764</td></tr><tr><td>train/grad_norm</td><td>0.01793</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0</td></tr><tr><td>train_loss</td><td>0.03691</td></tr><tr><td>train_runtime</td><td>974.7083</td></tr><tr><td>train_samples_per_second</td><td>39.096</td></tr><tr><td>train_steps_per_second</td><td>4.888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">simcse_meanpool_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/u04yrotd' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/u04yrotd</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250405_163054-u04yrotd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: SimCSE Pre-training Complete ---\n",
      "\n",
      "--- Phase 2: Starting Classification Fine-tuning ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Olivier\\Documents\\GitHub\\ssmh4\\task1\\wandb\\run-20250405_164719-1tfjx9zg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/1tfjx9zg' target=\"_blank\">classify_ft_on_simcse_xlm-roberta-base</a></strong> to <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/1tfjx9zg' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/1tfjx9zg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets created.\n",
      "Loading tokenizer for classification phase from: results_LLMTRADPARAPHRASE_simcse_xlmr_base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8058a3b65d347d1b9d62aa7c9ed84af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a4561bd6894487abe110e42a097d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification datasets tokenized.\n",
      "Computing class weights for classification...\n",
      "Detected 2 distinct labels in training data: [0 1]\n",
      "Class Weights (for classes [0 1]): [0.5825793 3.5273914]\n",
      "Loading model for classification from: results_LLMTRADPARAPHRASE_simcse_xlmr_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at results_LLMTRADPARAPHRASE_simcse_xlmr_base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivier\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_7652\\3583386714.py:314: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedClassificationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Trainer configured.\n",
      "Starting classification fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6276' max='8368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6276/8368 50:25 < 16:48, 2.07 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Pos</th>\n",
       "      <th>Precision Pos</th>\n",
       "      <th>Recall Pos</th>\n",
       "      <th>F1 Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.293364</td>\n",
       "      <td>0.914595</td>\n",
       "      <td>0.596527</td>\n",
       "      <td>0.502582</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.952243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.484181</td>\n",
       "      <td>0.939459</td>\n",
       "      <td>0.559748</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.967495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>0.932973</td>\n",
       "      <td>0.640371</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.963042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.675381</td>\n",
       "      <td>0.938162</td>\n",
       "      <td>0.619681</td>\n",
       "      <td>0.658192</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.966345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.764224</td>\n",
       "      <td>0.940108</td>\n",
       "      <td>0.628188</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.967431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.905898</td>\n",
       "      <td>0.943351</td>\n",
       "      <td>0.633053</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.567839</td>\n",
       "      <td>0.969306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification fine-tuning finished.\n",
      "Best classification model and tokenizer saved to results_augmented_data_classifier_finetuned_on_simcse\\best_model\n",
      "\n",
      "--- Detailed Evaluation and Submission File Generation ---\n",
      "\n",
      "Generating predictions for Threshold Adjustment and Detailed Metrics...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best threshold on validation set based on Overall F1-Positive...\n",
      "\n",
      "Best threshold found: 0.74 with Overall F1-Pos: 0.6591\n",
      "\n",
      "--- Detailed Evaluation on Development Set (Final Predictions) ---\n",
      "--- (Using Threshold = 0.74) ---\n",
      "\n",
      "Metrics for language: DE (Support: {0: 599, 1: 35})\n",
      "  Precision (Pos/1): 0.4043\n",
      "  Recall    (Pos/1): 0.5429\n",
      "  F1        (Pos/1): 0.4634\n",
      "  Accuracy:          0.9306\n",
      "\n",
      "Metrics for language: EN (Support: {0: 841, 1: 61})\n",
      "  Precision (Pos/1): 0.7925\n",
      "  Recall    (Pos/1): 0.6885\n",
      "  F1        (Pos/1): 0.7368\n",
      "  Accuracy:          0.9667\n",
      "\n",
      "Metrics for language: FR (Support: {0: 389, 1: 30})\n",
      "  Precision (Pos/1): 0.5000\n",
      "  Recall    (Pos/1): 0.7000\n",
      "  F1        (Pos/1): 0.5833\n",
      "  Accuracy:          0.9284\n",
      "\n",
      "Metrics for language: RU (Support: {0: 2398, 1: 272})\n",
      "  Precision (Pos/1): 0.7016\n",
      "  Recall    (Pos/1): 0.6654\n",
      "  F1        (Pos/1): 0.6830\n",
      "  Accuracy:          0.9371\n",
      "\n",
      "--- Overall Evaluation Summary (Final Predictions) ---\n",
      "Overall F1-score (Positive Class): 0.6591  <-- Primary Metric\n",
      "Macro F1-score (Pos Class / Lang): 0.6167\n",
      "Overall Precision (Positive Class):0.6575\n",
      "Overall Recall (Positive Class):   0.6608\n",
      "Overall Accuracy:                  0.9412\n",
      "\n",
      "Overall Confusion Matrix (Final):\n",
      "Predicted Labels: [0 1]\n",
      "True Labels\n",
      "[[4090  137]\n",
      " [ 135  263]]\n",
      "\n",
      "Saving predictions for submission...\n",
      "Predictions saved to results_augmented_data_classifier_finetuned_on_simcse\\predictions_task1_simcse_finetuned_thresh0.74.csv\n",
      "predictions_task1_simcse_finetuned_thresh0.74.csv has been zipped into results_augmented_data_classifier_finetuned_on_simcse\\submission_task1_simcse_finetuned_thresh0.74.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▅▇▇█</td></tr><tr><td>eval/best_threshold</td><td>▁</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>▁</td></tr><tr><td>eval/de/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/f1_neg</td><td>▁▇▅▇▇█</td></tr><tr><td>eval/f1_pos</td><td>▄▁█▆▇▇</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁▃▂▅▆█</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>▁</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/precision_pos</td><td>▁█▄▅▆▇</td></tr><tr><td>eval/recall_pos</td><td>█▁▇▄▄▄</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>▁</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>▁</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁█▁▆▂█</td></tr><tr><td>eval/samples_per_second</td><td>█▁█▂▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁█▂▇▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1_neg</td><td>▁</td></tr><tr><td>test/f1_pos</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision_pos</td><td>▁</td></tr><tr><td>test/recall_pos</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▂▂▂▂▁▂▂▄▂▄▁▂▄▂█▁▁▃▁▁▁▁▁▂▁▁▁▁▁▁▁▁▄▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▆▇██▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▅▅▄▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.94335</td></tr><tr><td>eval/best_threshold</td><td>0.74</td></tr><tr><td>eval/best_val_f1_at_threshold</td><td>0.65915</td></tr><tr><td>eval/de/thresh/accuracy</td><td>0.9306</td></tr><tr><td>eval/de/thresh/f1_pos</td><td>0.46341</td></tr><tr><td>eval/de/thresh/precision_pos</td><td>0.40426</td></tr><tr><td>eval/de/thresh/recall_pos</td><td>0.54286</td></tr><tr><td>eval/en/thresh/accuracy</td><td>0.96674</td></tr><tr><td>eval/en/thresh/f1_pos</td><td>0.73684</td></tr><tr><td>eval/en/thresh/precision_pos</td><td>0.79245</td></tr><tr><td>eval/en/thresh/recall_pos</td><td>0.68852</td></tr><tr><td>eval/f1_neg</td><td>0.96931</td></tr><tr><td>eval/f1_pos</td><td>0.63305</td></tr><tr><td>eval/fr/thresh/accuracy</td><td>0.9284</td></tr><tr><td>eval/fr/thresh/f1_pos</td><td>0.58333</td></tr><tr><td>eval/fr/thresh/precision_pos</td><td>0.5</td></tr><tr><td>eval/fr/thresh/recall_pos</td><td>0.7</td></tr><tr><td>eval/loss</td><td>0.9059</td></tr><tr><td>eval/overall/thresh/accuracy</td><td>0.94119</td></tr><tr><td>eval/overall/thresh/f1_pos</td><td>0.65915</td></tr><tr><td>eval/overall/thresh/macro_f1_pos_lang</td><td>0.61665</td></tr><tr><td>eval/overall/thresh/precision_pos</td><td>0.6575</td></tr><tr><td>eval/overall/thresh/recall_pos</td><td>0.6608</td></tr><tr><td>eval/precision_pos</td><td>0.71519</td></tr><tr><td>eval/recall_pos</td><td>0.56784</td></tr><tr><td>eval/ru/thresh/accuracy</td><td>0.93708</td></tr><tr><td>eval/ru/thresh/f1_pos</td><td>0.68302</td></tr><tr><td>eval/ru/thresh/precision_pos</td><td>0.70155</td></tr><tr><td>eval/ru/thresh/recall_pos</td><td>0.66544</td></tr><tr><td>eval/runtime</td><td>12.8498</td></tr><tr><td>eval/samples_per_second</td><td>359.928</td></tr><tr><td>eval/steps_per_second</td><td>45.059</td></tr><tr><td>test/accuracy</td><td>0.93297</td></tr><tr><td>test/f1_neg</td><td>0.96304</td></tr><tr><td>test/f1_pos</td><td>0.64037</td></tr><tr><td>test/loss</td><td>0.34985</td></tr><tr><td>test/precision_pos</td><td>0.59483</td></tr><tr><td>test/recall_pos</td><td>0.69347</td></tr><tr><td>test/runtime</td><td>13.1408</td></tr><tr><td>test/samples_per_second</td><td>351.956</td></tr><tr><td>test/steps_per_second</td><td>44.061</td></tr><tr><td>total_flos</td><td>2.02330757127744e+16</td></tr><tr><td>train/epoch</td><td>5.99964</td></tr><tr><td>train/global_step</td><td>6276</td></tr><tr><td>train/grad_norm</td><td>0.04747</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0485</td></tr><tr><td>train_loss</td><td>0.16198</td></tr><tr><td>train_runtime</td><td>3026.5104</td></tr><tr><td>train_samples_per_second</td><td>88.503</td></tr><tr><td>train_steps_per_second</td><td>2.765</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classify_ft_on_simcse_xlm-roberta-base</strong> at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/1tfjx9zg' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune/runs/1tfjx9zg</a><br> View project at: <a href='https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune' target=\"_blank\">https://wandb.ai/caron-olivier-80-universit-paris-dauphine-psl/ade-classification-LLMaugmented-simcse-finetune</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250405_164719-1tfjx9zg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "import math\n",
    "import gc\n",
    "\n",
    "# --- Configuration Générale ---\n",
    "BASE_MODEL_NAME = \"xlm-roberta-base\"\n",
    "TRAIN_CSV = \"data/train_data_augmented_strict_prompt.csv\" # Nouveau fichier d'entraînement\n",
    "DEV_CSV = \"data/dev_data_SMM4H_2025_Task_1.csv\"\n",
    "# ATTENTION: max_length=256 peut être gourmand en VRAM (8Go limite). Réduire à 192 ou 128 si OOM.\n",
    "MAX_LENGTH = 196 # Longueur max pour le tokenization (réduit pour éviter OOM)  \n",
    "\n",
    "# --- Configuration Phase 1: SimCSE Pré-entraînement ---\n",
    "DO_SIMCSE_PRETRAINING = True\n",
    "SIMCSE_OUTPUT_DIR = \"results_LLMTRADPARAPHRASE_simcse_xlmr_base\"\n",
    "SIMCSE_NUM_EPOCHS = 1\n",
    "# ATTENTION: batch_size=16 double en mémoire (2 passes SimCSE). Réduire à 12 ou 8 si OOM sur 8Go VRAM.\n",
    "SIMCSE_BATCH_SIZE = 8\n",
    "SIMCSE_LEARNING_RATE = 3e-5\n",
    "SIMCSE_TEMP = 0.05\n",
    "SIMCSE_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Option pour le pooling SimCSE\n",
    "SIMCSE_USE_MEAN_POOLING = True # Mettre à False pour utiliser le CLS token pooling\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "SIMCSE_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Configuration Phase 2: Classification Fine-tuning ---\n",
    "CLASSIFICATION_OUTPUT_DIR = \"results_augmented_data_classifier_finetuned_on_simcse\"\n",
    "CLASSIFICATION_NUM_EPOCHS = 8\n",
    "# ATTENTION: batch_size=8 * grad_accum=4 => effectif 32. Peut être lourd. Réduire si OOM.\n",
    "CLASSIFICATION_BATCH_SIZE = 4\n",
    "CLASSIFICATION_GRAD_ACCUM_STEPS = 8\n",
    "CLASSIFICATION_LEARNING_RATE = 2e-5\n",
    "CLASSIFICATION_EARLY_STOPPING_PATIENCE = 3\n",
    "CLASSIFICATION_LOGGING_STEPS = 50\n",
    "# NOUVEAU: Ratio de warmup pour le learning rate\n",
    "CLASSIFICATION_WARMUP_RATIO = 0.06 # ~6% des steps totaux\n",
    "\n",
    "# --- Initialisation WandB Globale ---\n",
    "WANDB_PROJECT_NAME = \"ade-classification-LLMaugmented-simcse-finetune\"\n",
    "\n",
    "# --- Fonction de Nettoyage de Texte (inchangée) ---\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'@[\\w_]+', '[USER_MENTION]', text)\n",
    "    text = text.replace('<user>', '[USER_MENTION]')\n",
    "    text = text.replace('<tuser>', '[USER_MENTION]')\n",
    "    text = text.replace('<url>', '[URL]')\n",
    "    text = text.replace('<email>', '[EMAIL]')\n",
    "    text = text.replace('HTTPURL________________', '[URL]')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# --- Fonction Mean Pooling (pour SimCSE optionnel) ---\n",
    "def mean_pooling(hidden_state, attention_mask):\n",
    "    \"\"\"Applique le mean pooling en ignorant les tokens de padding.\"\"\"\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
    "    sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9) # Évite division par zéro\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# --- 1. Chargement et Préparation Initiale des Données ---\n",
    "print(\"--- Initial Data Loading and Cleaning ---\")\n",
    "try:\n",
    "    train_df_full = pd.read_csv(TRAIN_CSV).dropna(subset=['text'])\n",
    "    dev_df_full = pd.read_csv(DEV_CSV).dropna(subset=['text'])\n",
    "    print(f\"Loaded {len(train_df_full)} train and {len(dev_df_full)} dev examples.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    exit()\n",
    "\n",
    "train_df_full['text'] = train_df_full['text'].apply(clean_text)\n",
    "dev_df_full['text'] = dev_df_full['text'].apply(clean_text)\n",
    "print(\"Text cleaning complete.\")\n",
    "\n",
    "# --- PHASE 1: SIMCSE PRE-TRAINING ---\n",
    "\n",
    "# Définition du Trainer Personnalisé pour SimCSE (modifié)\n",
    "class SimCSETrainer(Trainer):\n",
    "    def __init__(self, *args, temperature=0.05, use_mean_pooling=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.use_mean_pooling = use_mean_pooling # Stocker l'option de pooling\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        attention_mask = inputs.get(\"attention_mask\")\n",
    "\n",
    "        # Deux passes avec dropout (implicite dans le modèle en mode train)\n",
    "        outputs1 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        outputs2 = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\n",
    "        # --- MODIFIÉ: Choix entre Mean Pooling et CLS Pooling ---\n",
    "        if self.use_mean_pooling:\n",
    "            pooler_output1 = mean_pooling(outputs1.last_hidden_state, attention_mask)\n",
    "            pooler_output2 = mean_pooling(outputs2.last_hidden_state, attention_mask)\n",
    "        else: # Utiliser CLS token\n",
    "            pooler_output1 = outputs1.last_hidden_state[:, 0]\n",
    "            pooler_output2 = outputs2.last_hidden_state[:, 0]\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        # Concaténer et normaliser les embeddings\n",
    "        embeddings = torch.cat([pooler_output1, pooler_output2], dim=0)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1) # L2 Normalization\n",
    "\n",
    "        # Calculer la similarité cosinus\n",
    "        cos_sim = torch.mm(embeddings, embeddings.t()) # Shape: (2*batch_size, 2*batch_size)\n",
    "\n",
    "        # Masquer la diagonale (chaque embedding avec lui-même)\n",
    "        batch_size = pooler_output1.size(0)\n",
    "        mask_diag = torch.eye(2 * batch_size, device=embeddings.device, dtype=torch.bool)\n",
    "        cos_sim = cos_sim.masked_fill(mask_diag, -9e15) # Remplacer par un très petit nombre\n",
    "\n",
    "        # Appliquer la température\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # Créer les labels pour InfoNCE loss\n",
    "        labels = torch.arange(batch_size, device=embeddings.device)\n",
    "        labels_z1 = labels + batch_size # Indices des z2 correspondants\n",
    "        labels_z2 = labels             # Indices des z1 correspondants\n",
    "\n",
    "        # Extraire les logits pour chaque partie\n",
    "        logits_z1 = cos_sim[:batch_size, :] # Logits pour les embeddings de la 1ère passe\n",
    "        logits_z2 = cos_sim[batch_size:, :] # Logits pour les embeddings de la 2ème passe\n",
    "\n",
    "        # Calculer la perte CrossEntropy\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss_z1 = loss_fct(logits_z1, labels_z1)\n",
    "        loss_z2 = loss_fct(logits_z2, labels_z2)\n",
    "\n",
    "        # Perte finale = moyenne des deux\n",
    "        loss = (loss_z1 + loss_z2) / 2\n",
    "\n",
    "        return (loss, {\"embeddings1\": pooler_output1, \"embeddings2\": pooler_output2}) if return_outputs else loss\n",
    "\n",
    "model_load_path = BASE_MODEL_NAME # Default path if SimCSE is skipped\n",
    "\n",
    "if DO_SIMCSE_PRETRAINING:\n",
    "    print(\"\\n--- Phase 1: Starting SimCSE Pre-training ---\")\n",
    "    run_name_simcse = f\"simcse_{'meanpool_' if SIMCSE_USE_MEAN_POOLING else 'cls_'}{BASE_MODEL_NAME}\"\n",
    "    try:\n",
    "        wandb.init(project=WANDB_PROJECT_NAME, name=run_name_simcse, reinit=True)\n",
    "        wandb.config.update({ # Log config SimCSE\n",
    "            \"simcse_model\": BASE_MODEL_NAME,\n",
    "            \"simcse_epochs\": SIMCSE_NUM_EPOCHS,\n",
    "            \"simcse_batch_size\": SIMCSE_BATCH_SIZE,\n",
    "            \"simcse_lr\": SIMCSE_LEARNING_RATE,\n",
    "            \"simcse_temp\": SIMCSE_TEMP,\n",
    "            \"simcse_pooling\": \"mean\" if SIMCSE_USE_MEAN_POOLING else \"cls\",\n",
    "            \"simcse_warmup_ratio\": SIMCSE_WARMUP_RATIO,\n",
    "            \"max_length\": MAX_LENGTH\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"WandB initialization failed for SimCSE phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "    # Préparer le dataset SimCSE (train + dev)\n",
    "    all_texts_df = pd.concat([train_df_full[['text']], dev_df_full[['text']]], ignore_index=True)\n",
    "    simcse_dataset = Dataset.from_pandas(all_texts_df)\n",
    "    print(f\"Created SimCSE dataset with {len(simcse_dataset)} examples.\")\n",
    "\n",
    "    # Tokenizer (Charger ici pour la phase 1)\n",
    "    print(f\"Loading tokenizer {BASE_MODEL_NAME} for SimCSE phase...\")\n",
    "    tokenizer_simcse = AutoTokenizer.from_pretrained(BASE_MODEL_NAME) # Utiliser une variable spécifique\n",
    "\n",
    "    def tokenize_simcse(examples):\n",
    "        # Utiliser tokenizer_simcse défini dans cette portée\n",
    "        return tokenizer_simcse(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    tokenized_simcse_dataset = simcse_dataset.map(tokenize_simcse, batched=True, remove_columns=[\"text\"], num_proc=1) # Utiliser plus de procs si possible\n",
    "    tokenized_simcse_dataset.set_format(\"torch\")\n",
    "    print(\"SimCSE dataset tokenized.\")\n",
    "\n",
    "    # Charger le modèle AutoModel (sans tête)\n",
    "    simcse_model = AutoModel.from_pretrained(BASE_MODEL_NAME)\n",
    "    print(\"SimCSE base model loaded.\")\n",
    "\n",
    "    # Arguments d'entraînement SimCSE (avec warmup)\n",
    "    simcse_training_args = TrainingArguments(\n",
    "        output_dir=SIMCSE_OUTPUT_DIR,\n",
    "        num_train_epochs=SIMCSE_NUM_EPOCHS,\n",
    "        per_device_train_batch_size=SIMCSE_BATCH_SIZE,\n",
    "        learning_rate=SIMCSE_LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{SIMCSE_OUTPUT_DIR}/logs',\n",
    "        logging_steps=SIMCSE_LOGGING_STEPS,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "        fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "        warmup_ratio=SIMCSE_WARMUP_RATIO, # NOUVEAU: Ajout du warmup\n",
    "    )\n",
    "\n",
    "    # Instancier le SimCSE Trainer (avec l'option pooling)\n",
    "    simcse_trainer = SimCSETrainer(\n",
    "        model=simcse_model,\n",
    "        args=simcse_training_args,\n",
    "        train_dataset=tokenized_simcse_dataset,\n",
    "        tokenizer=tokenizer_simcse, # Passer le tokenizer spécifique\n",
    "        temperature=SIMCSE_TEMP,\n",
    "        use_mean_pooling=SIMCSE_USE_MEAN_POOLING # NOUVEAU: Passer l'option\n",
    "    )\n",
    "\n",
    "    # Lancer l'entraînement\n",
    "    print(\"Starting SimCSE training...\")\n",
    "    simcse_trainer.train()\n",
    "    print(\"SimCSE training finished.\")\n",
    "\n",
    "    # Sauvegarder\n",
    "    simcse_trainer.save_model(SIMCSE_OUTPUT_DIR)\n",
    "    tokenizer_simcse.save_pretrained(SIMCSE_OUTPUT_DIR) # Sauver le tokenizer utilisé\n",
    "    print(f\"SimCSE pre-trained model and tokenizer saved to {SIMCSE_OUTPUT_DIR}\")\n",
    "\n",
    "    # Nettoyer\n",
    "    model_load_path = SIMCSE_OUTPUT_DIR # Mettre à jour le chemin pour la phase 2\n",
    "    del simcse_model, simcse_trainer, tokenized_simcse_dataset, simcse_dataset, all_texts_df, tokenizer_simcse\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    print(\"--- Phase 1: SimCSE Pre-training Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Phase 1: Skipping SimCSE Pre-training ---\")\n",
    "    # model_load_path reste BASE_MODEL_NAME (défini plus haut)\n",
    "\n",
    "\n",
    "# --- PHASE 2: CLASSIFICATION FINE-TUNING ---\n",
    "print(\"\\n--- Phase 2: Starting Classification Fine-tuning ---\")\n",
    "run_name_classify = f\"classify_ft_on_{'simcse' if DO_SIMCSE_PRETRAINING else 'base'}_{BASE_MODEL_NAME}\"\n",
    "try:\n",
    "    wandb.init(project=WANDB_PROJECT_NAME, name=run_name_classify, reinit=True)\n",
    "    wandb.config.update({ # Log config Classification\n",
    "        \"base_model_for_ft\": model_load_path,\n",
    "        \"classify_epochs\": CLASSIFICATION_NUM_EPOCHS,\n",
    "        \"classify_batch_size\": CLASSIFICATION_BATCH_SIZE,\n",
    "        \"classify_grad_accum\": CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_effective_batch\": CLASSIFICATION_BATCH_SIZE * CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "        \"classify_lr\": CLASSIFICATION_LEARNING_RATE,\n",
    "        \"classify_warmup_ratio\": CLASSIFICATION_WARMUP_RATIO,\n",
    "        \"classify_early_stopping\": CLASSIFICATION_EARLY_STOPPING_PATIENCE,\n",
    "        \"max_length\": MAX_LENGTH\n",
    "    })\n",
    "except Exception as e:\n",
    "        print(f\"WandB initialization failed for Classification phase: {e}\")\n",
    "        print(\"Proceeding without WandB logging for this phase.\")\n",
    "\n",
    "\n",
    "# Préparer les datasets classification\n",
    "train_dataset_cls = Dataset.from_pandas(train_df_full)\n",
    "dev_dataset_cls = Dataset.from_pandas(dev_df_full)\n",
    "dataset_dict_cls = DatasetDict({'train': train_dataset_cls, 'validation': dev_dataset_cls})\n",
    "print(\"Classification datasets created.\")\n",
    "\n",
    "# --- CORRECTIF: Charger systématiquement le tokenizer pour la Phase 2 ---\n",
    "# Charger le tokenizer correspondant au modèle que nous allons fine-tuner\n",
    "# (soit celui de SimCSE si Phase 1 a tourné, soit celui du modèle de base)\n",
    "print(f\"Loading tokenizer for classification phase from: {model_load_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_load_path)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def tokenize_classification(examples):\n",
    "    # Utilise le 'tokenizer' défini juste au-dessus\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "tokenized_datasets_cls = dataset_dict_cls.map(tokenize_classification, batched=True, remove_columns=[\"text\", \"id\", \"file_name\", \"origin\", \"language\", \"split\", \"type\"], num_proc=1)\n",
    "tokenized_datasets_cls.set_format(\"torch\")\n",
    "tokenized_datasets_cls = tokenized_datasets_cls.rename_column(\"label\", \"labels\")\n",
    "print(\"Classification datasets tokenized.\")\n",
    "\n",
    "# Calculer poids de classe\n",
    "print(\"Computing class weights for classification...\")\n",
    "labels_train_cls = train_df_full['label'].values\n",
    "class_weights_tensor_cls = None\n",
    "unique_labels_cls = np.unique(labels_train_cls)\n",
    "num_distinct_labels = len(unique_labels_cls)\n",
    "print(f\"Detected {num_distinct_labels} distinct labels in training data: {unique_labels_cls}\")\n",
    "\n",
    "if num_distinct_labels > 1:\n",
    "    class_weights_cls = compute_class_weight(class_weight='balanced', classes=unique_labels_cls, y=labels_train_cls)\n",
    "    # Ensure weights are ordered according to label index (0, 1, ...)\n",
    "    ordered_weights_dict = {label: weight for label, weight in zip(unique_labels_cls, class_weights_cls)}\n",
    "    # Utiliser num_distinct_labels pour déterminer la taille du tenseur\n",
    "    ordered_weights_cls = np.array([ordered_weights_dict.get(i, 0) for i in unique_labels_cls]) # Assigner poids aux labels existants\n",
    "\n",
    "    class_weights_tensor_cls = torch.tensor(ordered_weights_cls, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Class Weights (for classes {unique_labels_cls}): {class_weights_tensor_cls.cpu().numpy()}\")\n",
    "    if wandb.run: wandb.config.update({\"class_weights\": class_weights_tensor_cls.cpu().numpy().tolist()})\n",
    "else:\n",
    "    print(\"Warning: Only one class found in training data. Cannot compute class weights.\")\n",
    "\n",
    "\n",
    "# Trainer Personnalisé Classification avec Poids\n",
    "class WeightedClassificationTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "         super().__init__(*args, **kwargs)\n",
    "         # Déplacer les poids sur le bon device une seule fois si possible\n",
    "         self.class_weights = class_weights.to(self.args.device) if class_weights is not None else None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Utiliser les poids stockés et déjà sur le bon device\n",
    "        if self.class_weights is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss() # No weights\n",
    "\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Charger le modèle pour Classification\n",
    "print(f\"Loading model for classification from: {model_load_path}\")\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_load_path,\n",
    "    num_labels=num_distinct_labels, # Utiliser le nombre détecté\n",
    "    ignore_mismatched_sizes=True # Crucial si chargement depuis AutoModel (SimCSE)\n",
    ")\n",
    "print(\"Classification model loaded.\")\n",
    "\n",
    "# Fonction compute_metrics\n",
    "def compute_metrics_cls(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    metric_labels = unique_labels_cls # Utiliser les labels détectés\n",
    "    if num_distinct_labels == 2:\n",
    "        # Calcul spécifique pour binaire (Pos = 1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0, 1], zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_pos': f1[1] if len(f1) > 1 else 0,\n",
    "            'precision_pos': precision[1] if len(precision) > 1 else 0,\n",
    "            'recall_pos': recall[1] if len(recall) > 1 else 0,\n",
    "            'f1_neg': f1[0] if len(f1) > 0 else 0,\n",
    "        }\n",
    "    else:\n",
    "        # Calcul macro/weighted pour multiclasse\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', labels=metric_labels, zero_division=0)\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(labels, preds, average='weighted', labels=metric_labels, zero_division=0)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        metrics = {\n",
    "            'accuracy': acc,\n",
    "            'f1_macro': f1_macro,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "        }\n",
    "        # Optionnel: ajouter f1 par classe si besoin\n",
    "        # _, _, f1_per_class, _ = precision_recall_fscore_support(labels, preds, average=None, labels=metric_labels, zero_division=0)\n",
    "        # for i, label in enumerate(metric_labels):\n",
    "        #     metrics[f'f1_class_{label}'] = f1_per_class[i]\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Arguments d'entraînement Classification (avec warmup)\n",
    "classification_training_args = TrainingArguments(\n",
    "    output_dir=CLASSIFICATION_OUTPUT_DIR,\n",
    "    num_train_epochs=CLASSIFICATION_NUM_EPOCHS,\n",
    "    per_device_train_batch_size=CLASSIFICATION_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=CLASSIFICATION_BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=CLASSIFICATION_GRAD_ACCUM_STEPS,\n",
    "    learning_rate=CLASSIFICATION_LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Choisir la métrique pertinente pour load_best_model_at_end\n",
    "    metric_for_best_model=\"f1_pos\" if num_distinct_labels == 2 else \"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=f'{CLASSIFICATION_OUTPUT_DIR}/logs',\n",
    "    logging_steps=CLASSIFICATION_LOGGING_STEPS,\n",
    "    report_to=\"wandb\" if wandb.run is not None else \"none\", # Conditionner le report\n",
    "    fp16=torch.cuda.is_available(), # INDISPENSABLE sur 8Go VRAM\n",
    "    warmup_ratio=CLASSIFICATION_WARMUP_RATIO,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Instancier le Trainer Classification (passer les poids ici)\n",
    "classification_trainer = WeightedClassificationTrainer(\n",
    "    model=classification_model,\n",
    "    args=classification_training_args,\n",
    "    train_dataset=tokenized_datasets_cls[\"train\"],\n",
    "    eval_dataset=tokenized_datasets_cls[\"validation\"],\n",
    "    tokenizer=tokenizer, # Utiliser le tokenizer chargé pour la phase 2\n",
    "    compute_metrics=compute_metrics_cls,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=CLASSIFICATION_EARLY_STOPPING_PATIENCE)],\n",
    "    class_weights=class_weights_tensor_cls # Passer le tenseur de poids\n",
    ")\n",
    "print(\"Classification Trainer configured.\")\n",
    "\n",
    "# Lancer le fine-tuning\n",
    "print(\"Starting classification fine-tuning...\")\n",
    "classification_trainer.train()\n",
    "print(\"Classification fine-tuning finished.\")\n",
    "\n",
    "# Sauvegarder le meilleur modèle explicitement\n",
    "best_model_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, \"best_model\")\n",
    "classification_trainer.save_model(best_model_path)\n",
    "tokenizer.save_pretrained(best_model_path) # Sauver le tokenizer avec le meilleur modèle\n",
    "print(f\"Best classification model and tokenizer saved to {best_model_path}\")\n",
    "\n",
    "# --- Évaluation Détaillée et Soumission (Utilise le meilleur modèle chargé) ---\n",
    "print(\"\\n--- Detailed Evaluation and Submission File Generation ---\")\n",
    "print(\"\\nGenerating predictions for Threshold Adjustment and Detailed Metrics...\")\n",
    "\n",
    "predictions_output = classification_trainer.predict(tokenized_datasets_cls[\"validation\"])\n",
    "logits = predictions_output.predictions\n",
    "true_labels = predictions_output.label_ids\n",
    "\n",
    "if logits.shape[-1] != num_distinct_labels:\n",
    "    print(f\"Error: Logits shape {logits.shape} unexpected for {num_distinct_labels} labels.\")\n",
    "    exit()\n",
    "\n",
    "probabilities = None\n",
    "predicted_labels_final = None\n",
    "best_threshold = None\n",
    "\n",
    "if num_distinct_labels == 2:\n",
    "    probabilities = softmax(logits, axis=-1)[:, 1] # Proba classe positive (index 1)\n",
    "    print(\"\\nFinding best threshold on validation set based on Overall F1-Positive...\")\n",
    "    best_f1 = -1\n",
    "    best_threshold = 0.5 # Default\n",
    "    thresholds = np.arange(0.1, 0.91, 0.01)\n",
    "    f1_scores_thresh = []\n",
    "    for threshold in thresholds:\n",
    "        predicted_labels_thresh = (probabilities >= threshold).astype(int)\n",
    "        precision_thresh, recall_thresh, f1_thresh, _ = precision_recall_fscore_support(\n",
    "            true_labels, predicted_labels_thresh, average='binary', pos_label=1, zero_division=0)\n",
    "        f1_scores_thresh.append(f1_thresh)\n",
    "        if f1_thresh > best_f1:\n",
    "            best_f1 = f1_thresh\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"\\nBest threshold found: {best_threshold:.2f} with Overall F1-Pos: {best_f1:.4f}\")\n",
    "    if wandb.run: wandb.log({\"eval/best_threshold\": best_threshold, \"eval/best_val_f1_at_threshold\": best_f1})\n",
    "    predicted_labels_final = (probabilities >= best_threshold).astype(int)\n",
    "else:\n",
    "    print(\"Multi-class classification detected (>2). Using argmax for final predictions.\")\n",
    "    predicted_labels_final = logits.argmax(-1)\n",
    "    # best_threshold reste None\n",
    "\n",
    "# Préparer le DataFrame pour l'évaluation détaillée\n",
    "dev_df_eval = dev_df_full.reset_index(drop=True)\n",
    "if len(dev_df_eval) == len(predicted_labels_final):\n",
    "    dev_df_eval['predicted_label'] = predicted_labels_final\n",
    "    if probabilities is not None:\n",
    "         dev_df_eval['probability_positive'] = probabilities\n",
    "else:\n",
    "    print(f\"Error: Length mismatch between dev_df {len(dev_df_eval)} and predictions {len(predicted_labels_final)}!\")\n",
    "    exit()\n",
    "\n",
    "dev_df_eval[\"language\"] = dev_df_full[\"id\"].apply(lambda x: str(x).split(\"_\")[0] if isinstance(x, str) and \"_\" in x else \"unknown\")\n",
    "\n",
    "languages = sorted(dev_df_eval['language'].unique())\n",
    "language_f1_scores_pos = [] # Pour Macro F1 binaire\n",
    "wandb_logs_eval = {}\n",
    "print(f\"\\n--- Detailed Evaluation on Development Set (Final Predictions) ---\")\n",
    "if best_threshold is not None:\n",
    "     print(f\"--- (Using Threshold = {best_threshold:.2f}) ---\")\n",
    "\n",
    "for lang in languages:\n",
    "    if lang == \"unknown\": continue\n",
    "    lang_mask = dev_df_eval['language'] == lang\n",
    "    y_true_lang = dev_df_eval.loc[lang_mask, 'label'].tolist()\n",
    "    y_pred_lang_final = dev_df_eval.loc[lang_mask, 'predicted_label'].tolist()\n",
    "    if len(y_true_lang) == 0: continue\n",
    "\n",
    "    # Utiliser les labels détectés pour le calcul des métriques\n",
    "    metric_labels = unique_labels_cls\n",
    "    precision_lang, recall_lang, f1_lang, support_lang = precision_recall_fscore_support(\n",
    "        y_true_lang, y_pred_lang_final, average=None, labels=metric_labels, zero_division=0)\n",
    "    accuracy_lang = accuracy_score(y_true_lang, y_pred_lang_final)\n",
    "\n",
    "    print(f\"\\nMetrics for language: {lang.upper()} (Support: {dict(zip(metric_labels, support_lang))})\")\n",
    "    # Clé WandB dynamique basée sur seuil/argmax\n",
    "    wandb_key_prefix = f\"eval/{lang}\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "    if num_distinct_labels == 2:\n",
    "        f1_pos_lang = f1_lang[1] # Index 1 correspond au label 1 (Positif)\n",
    "        language_f1_scores_pos.append(f1_pos_lang)\n",
    "        print(f\"  Precision (Pos/1): {precision_lang[1]:.4f}\")\n",
    "        print(f\"  Recall    (Pos/1): {recall_lang[1]:.4f}\")\n",
    "        print(f\"  F1        (Pos/1): {f1_pos_lang:.4f}\")\n",
    "        print(f\"  Accuracy:          {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/precision_pos\"] = precision_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/recall_pos\"] = recall_lang[1]\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_pos\"] = f1_pos_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "    else:\n",
    "        f1_macro_lang = np.mean(f1_lang) # F1 macro simple\n",
    "        print(f\"  F1-Macro:         {f1_macro_lang:.4f}\")\n",
    "        print(f\"  Accuracy:         {accuracy_lang:.4f}\")\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/f1_macro\"] = f1_macro_lang\n",
    "        wandb_logs_eval[f\"{wandb_key_prefix}/accuracy\"] = accuracy_lang\n",
    "        # Logguer F1 par classe si besoin\n",
    "        for i, label in enumerate(metric_labels):\n",
    "             wandb_logs_eval[f\"{wandb_key_prefix}/f1_class_{label}\"] = f1_lang[i]\n",
    "\n",
    "\n",
    "# Calcul des métriques globales finales\n",
    "cm_overall_final = confusion_matrix(true_labels, predicted_labels_final, labels=unique_labels_cls)\n",
    "overall_accuracy_final = accuracy_score(true_labels, predicted_labels_final)\n",
    "wandb_key_prefix_overall = \"eval/overall\" + (\"/thresh\" if best_threshold is not None else \"/argmax\")\n",
    "\n",
    "print(f\"\\n--- Overall Evaluation Summary (Final Predictions) ---\")\n",
    "if num_distinct_labels == 2:\n",
    "    # Assurer que cm a bien 4 éléments (cas binaire)\n",
    "    if cm_overall_final.size == 4:\n",
    "      tn, fp, fn, tp = cm_overall_final.ravel()\n",
    "    else: # Gérer cas où une classe n'est pas prédite/présente dans l'éval\n",
    "      tn, fp, fn, tp = 0, 0, 0, 0\n",
    "      print(\"Warning: Confusion matrix size indicates potential missing classes in evaluation.\")\n",
    "      # Logique pour reconstruire TN/FP/FN/TP si nécessaire basée sur les labels uniques\n",
    "      if 0 in unique_labels_cls and 1 in unique_labels_cls:\n",
    "          tn = cm_overall_final[0, 0]\n",
    "          fp = cm_overall_final[0, 1]\n",
    "          fn = cm_overall_final[1, 0]\n",
    "          tp = cm_overall_final[1, 1]\n",
    "\n",
    "    overall_precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    overall_recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    overall_f1_pos = 2 * (overall_precision_pos * overall_recall_pos) / (overall_precision_pos + overall_recall_pos) if (overall_precision_pos + overall_recall_pos) > 0 else 0\n",
    "    macro_f1_pos = np.mean(language_f1_scores_pos) if language_f1_scores_pos else 0 # Moyenne des F1-pos par langue\n",
    "\n",
    "    print(f\"Overall F1-score (Positive Class): {overall_f1_pos:.4f}  <-- Primary Metric\")\n",
    "    print(f\"Macro F1-score (Pos Class / Lang): {macro_f1_pos:.4f}\")\n",
    "    print(f\"Overall Precision (Positive Class):{overall_precision_pos:.4f}\")\n",
    "    print(f\"Overall Recall (Positive Class):   {overall_recall_pos:.4f}\")\n",
    "    print(f\"Overall Accuracy:                  {overall_accuracy_final:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_pos\"] = overall_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/macro_f1_pos_lang\"] = macro_f1_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/precision_pos\"] = overall_precision_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/recall_pos\"] = overall_recall_pos\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "else: # Métriques globales pour multiclasse\n",
    "    overall_prec_macro, overall_recall_macro, overall_f1_macro, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='macro', labels=unique_labels_cls, zero_division=0)\n",
    "    overall_prec_weighted, overall_recall_weighted, overall_f1_weighted, _ = precision_recall_fscore_support(true_labels, predicted_labels_final, average='weighted', labels=unique_labels_cls, zero_division=0)\n",
    "    print(f\"Overall Accuracy:     {overall_accuracy_final:.4f}\")\n",
    "    print(f\"Overall F1 (Macro):   {overall_f1_macro:.4f}\")\n",
    "    print(f\"Overall F1 (Weighted):{overall_f1_weighted:.4f}\")\n",
    "    print(\"\\nOverall Confusion Matrix (Final):\")\n",
    "    print(f\"Predicted Labels: {unique_labels_cls}\")\n",
    "    print(f\"True Labels\")\n",
    "    print(cm_overall_final)\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/accuracy\"] = overall_accuracy_final\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_macro\"] = overall_f1_macro\n",
    "    wandb_logs_eval[f\"{wandb_key_prefix_overall}/f1_weighted\"] = overall_f1_weighted\n",
    "    if wandb.run: wandb_logs_eval[f\"{wandb_key_prefix_overall}/conf_matrix\"] = wandb.Table(data=cm_overall_final.tolist(), columns=[f\"Pred_{l}\" for l in unique_labels_cls], rows=[f\"True_{l}\" for l in unique_labels_cls])\n",
    "\n",
    "# Log all detailed eval metrics\n",
    "if wandb.run: wandb.log(wandb_logs_eval)\n",
    "\n",
    "# --- Sauvegarde du fichier de soumission ---\n",
    "print(\"\\nSaving predictions for submission...\")\n",
    "os.makedirs(CLASSIFICATION_OUTPUT_DIR, exist_ok=True)\n",
    "submission_df = dev_df_eval[['id', 'predicted_label']]\n",
    "suffix = \"simcse_finetuned\" if DO_SIMCSE_PRETRAINING else \"base_finetuned\"\n",
    "thresh_suffix = f\"_thresh{best_threshold:.2f}\" if best_threshold is not None else \"_argmax\"\n",
    "csv_filename = f\"predictions_task1_{suffix}{thresh_suffix}.csv\"\n",
    "zip_filename = f\"submission_task1_{suffix}{thresh_suffix}.zip\"\n",
    "csv_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, csv_filename)\n",
    "zip_path = os.path.join(CLASSIFICATION_OUTPUT_DIR, zip_filename)\n",
    "\n",
    "submission_df.to_csv(csv_path, index=False)\n",
    "print(f\"Predictions saved to {csv_path}\")\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.write(csv_path, arcname=csv_filename)\n",
    "    print(f\"{csv_filename} has been zipped into {zip_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error zipping the file: {e}\")\n",
    "\n",
    "\n",
    "if wandb.run is not None and wandb.run.step > 0: # Check if wandb was used and logged something\n",
    "    wandb.finish()\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
